{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "\n",
    "import gzip #for parsing gz files\n",
    "import pandas as pd\n",
    "import re \n",
    "#import inflect #numeric/cardinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirPath = r\"/data\"\n",
    "reviewPath = r\"reviews_Tools_and_Home_Improvement_5.json.gz\"\n",
    "#reviewPath = r\"reviews_Musical_Instruments_5.json.gz\"\n",
    "\n",
    "path = dirPath + \"/\" + reviewPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/tone/Study/NLP/data/reviews_Tools_and_Home_Improvement_5.json.gz'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "current = os.getcwd()\n",
    "current\n",
    "path = current + path\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFile = gzip.open(path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need this function because large amount of data we are going to load up\n",
    "\n",
    "# http://jmcauley.ucsd.edu/data/amazon/index.html\n",
    "# eval function allows text to be parsed as python code\n",
    "# parse function is a generator with yield\n",
    "# yield when we want to iterate over a sequence, but don't want to store the entire sequence in memory\n",
    "def parse(dataFile):\n",
    "    for each in dataFile:\n",
    "        yield eval(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each review for a product in dataFile maps dict[nth] = review (nth)\n",
    "# enumerate can't be used on a generator\n",
    "count = 0\n",
    "productReviews = {}\n",
    "for eachReview in parse(dataFile):\n",
    "    productReviews[count] = eachReview\n",
    "    count = count + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134476"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(productReviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#productReviews[101718]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "productsReviewData = pd.DataFrame.from_dict(productReviews, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A4IL0CLL27Q33</td>\n",
       "      <td>104800001X</td>\n",
       "      <td>D. Brennan</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>I hate it when my shirt collars, not otherwise...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Perfect for collar stay management</td>\n",
       "      <td>1390953600</td>\n",
       "      <td>01 29, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3Q5W5E7TDVLJF</td>\n",
       "      <td>104800001X</td>\n",
       "      <td>funnyc130</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>These little magnets are really powerful for t...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Neat</td>\n",
       "      <td>1369958400</td>\n",
       "      <td>05 31, 2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin reviewerName helpful  \\\n",
       "0   A4IL0CLL27Q33  104800001X   D. Brennan  [0, 1]   \n",
       "1  A3Q5W5E7TDVLJF  104800001X    funnyc130  [0, 0]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  I hate it when my shirt collars, not otherwise...      5.0   \n",
       "1  These little magnets are really powerful for t...      5.0   \n",
       "\n",
       "                              summary  unixReviewTime   reviewTime  \n",
       "0  Perfect for collar stay management      1390953600  01 29, 2014  \n",
       "1                                Neat      1369958400  05 31, 2013  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "productsReviewData.shape\n",
    "productsReviewData.columns\n",
    "productsReviewData.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduceData = productsReviewData.loc[:, ['asin', 'reviewerName', 'reviewText', 'helpful', 'overall']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduceData = reduceData.loc[reduceData['overall']!=3.0, ['asin', 'reviewerName', 'reviewText', 'helpful', 'overall']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = lambda x: 1 if x > 2.0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>helpful</th>\n",
       "      <th>overall</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>134322</th>\n",
       "      <td>Amazing that they designed this thing without ...</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55236</th>\n",
       "      <td>I was ready to pick up one of these at a woodw...</td>\n",
       "      <td>[30, 38]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55234</th>\n",
       "      <td>I bought this set from amazon but is not like ...</td>\n",
       "      <td>[8, 15]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105852</th>\n",
       "      <td>Horrible.Not one blade runs true.  Some are as...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55216</th>\n",
       "      <td>This product is almost a joke.  The case is to...</td>\n",
       "      <td>[4, 9]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reviewText   helpful  overall  \\\n",
       "134322  Amazing that they designed this thing without ...    [2, 2]      1.0   \n",
       "55236   I was ready to pick up one of these at a woodw...  [30, 38]      1.0   \n",
       "55234   I bought this set from amazon but is not like ...   [8, 15]      1.0   \n",
       "105852  Horrible.Not one blade runs true.  Some are as...    [0, 0]      1.0   \n",
       "55216   This product is almost a joke.  The case is to...    [4, 9]      1.0   \n",
       "\n",
       "        rating  \n",
       "134322       0  \n",
       "55236        0  \n",
       "55234        0  \n",
       "105852       0  \n",
       "55216        0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduceData['rating'] = reduceData['overall'].apply(rating)\n",
    "unfavorableReviews = list(reduceData.loc[ reduceData['rating'] == 0, \n",
    "                                         ['reviewText', 'helpful', 'overall', 'rating']].sort_values(by='overall').index)\n",
    "#unfavorableReviews\n",
    "reduceData.loc[ reduceData['rating'] == 0, ['reviewText', 'helpful', 'overall', 'rating']].sort_values(by='overall').head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewTextProcessing = pd.DataFrame(reduceData.reviewText.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewTextProcessing['rating'] = reduceData['rating']\n",
    "reviewTextProcessing['overall'] = reduceData['overall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123707, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "productsReviewData.dtypes\n",
    "len(productsReviewData)\n",
    "# reviewText, rating, overall\n",
    "reviewTextProcessing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reviewTextProcessing.loc[reviewTextProcessing['rating']==0, ['rating', 'overall', 'Processed', 'SentimentModel']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python\n",
    "import Contractions_Words as contractions\n",
    "import importlib\n",
    "importlib.reload(contractions)\n",
    "\n",
    "contractions_dict = contractions.contractions_dict\n",
    "\n",
    "#print(contractions_dict.keys())\n",
    "#print(contractions_dict[\"s***\"])\n",
    "\n",
    "pattern = '%s' % '|'.join(contractions_dict.keys())\n",
    "#pattern = r\"%s\" % pattern\n",
    "#print(pattern)\n",
    "contractions_re = re.compile(pattern)\n",
    "def expand_contractions(s, contractions_dict=contractions_dict):\n",
    "    #edit for special case like s*** etc\n",
    "    s = re.sub(\"\\*\", \"#\", s)\n",
    "    def replace(match):\n",
    "        #print(type(match), match)\n",
    "        return contractions_dict[match.group(0)]\n",
    "    return contractions_re.sub(replace, s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s###\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'shit'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample1 = \"s***\"\n",
    "print(re.sub(\"\\*\", \"#\", sample1))\n",
    "\n",
    "sample = \"I don\\'t know what to say nay. I haven\\'t. s###\"\n",
    "expand_contractions(sample)\n",
    "expand_contractions(sample1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import string\n",
    "\n",
    "# return both wholeText, paragraph Text\n",
    "def singleReviewCleanUp(sample):\n",
    "    #print(sample)\n",
    "    #sample = sample.decode(\"utf-8\")\n",
    "    sample = expand_contractions(sample)\n",
    "    sample = sample.lower()\n",
    "    \n",
    "    #for word in sample:\n",
    "    #    print(lemmatizer.lemmatize(word, wordnet.VERB))\n",
    "    \n",
    "    review = sent_tokenize(sample)\n",
    "    #print(review)\n",
    "    for count, eachSent in enumerate(review):\n",
    "        #remove numbers\n",
    "        eachSent = re.sub(\"r'\\d+/\\d+|\\d+|\\$\\d+.\\d+\", \" \", eachSent)\n",
    "        #remove string\n",
    "        eachSent = re.sub('[%s]' % re.escape(string.punctuation), ' ', eachSent)\n",
    "        #word tokens\n",
    "        #print([lemmatizer.lemmatize(text, wordnet.VERB) for text in eachSent.split()])\n",
    "        eachSent = word_tokenize(eachSent)\n",
    "        review[count] = eachSent\n",
    "        # lemmatize and remove stopWords\n",
    "        #eachSent = [word for word in eachSent if not word in stopWords]\n",
    "        #eachSent = [lemmatizer.lemmatize(word, wordnet.VERB) for word in eachSent]\n",
    "        #eachSent = [lemmatizer.lemmatize(word, wordnet.VERB) for word in eachSent if not word in stopWords]\n",
    "        review[count] = \" \".join(eachSent)\n",
    "    wholeText = [\" \".join(review) ]\n",
    "    paragraphText = review\n",
    "    #return wholeText\n",
    "    #return paragraphText\n",
    "    return paragraphText, wholeText\n",
    "\n",
    "#paragraphText, wholeText = singleReviewCleanUp(sample)\n",
    "#wholeText, paragraphText\n",
    "#paragraphText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Give me back text in a paragraph sentence forms. They do have more values than a clobbed of text based on Polarity Check.\n",
    "cleanUpTextParagraph = lambda text: singleReviewCleanUp(text)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 46s, sys: 326 ms, total: 1min 46s\n",
      "Wall time: 1min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reviewTextProcessing['Processed'] = reviewTextProcessing.reviewText.apply(cleanUpTextParagraph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample = \" I don't know what to do. I need to test through tough. Do you have any suggestions\"\n",
    "#result = cleanUpTextParagraph(sample)\n",
    "#result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# need to do a data check first\n",
    "def getPolaritySubjectivity(data):\n",
    "    #print(data)\n",
    "    paragraphText = data\n",
    "    sumPolarity = []\n",
    "    sumSubjectivity = []\n",
    "    for each in paragraphText:\n",
    "        sumPolarity.append(TextBlob(each).sentiment.polarity)\n",
    "        sumSubjectivity.append(TextBlob(each).sentiment.subjectivity)\n",
    "    #print(\"sumPol\", sumPolarity)\n",
    "    return sumPolarity, sumSubjectivity\n",
    "    #return sum(sumPolarity), sum(sumSubjectivity)\n",
    "\n",
    "    #print(each, TextBlob(each).sentiment.polarity, TextBlob(each).sentiment.subjectivity)\n",
    "#(sample2, TextBlob(sample2).sentiment.polarity, TextBlob(sample2).sentiment.subjectivity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return the sume of polarity in a paragraph sentence when give a text in a list form of sentence\n",
    "\n",
    "getPolarityFromText = lambda text: getPolaritySubjectivity(text)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each in sampleText:\n",
    "#    sample = cleanUpTextParagraph(each)\n",
    "#    print(sample, getPolarityFromText(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentiment = lambda text: TextBlob(text).sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjustSentimentModel = lambda x: [sum(x), 0.0] if sum(x) < 0 else [sum(x), 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 35s, sys: 424 ms, total: 3min 36s\n",
      "Wall time: 3min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reviewTextProcessing['Sentiment']= reviewTextProcessing.Processed.apply(getPolarityFromText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 60 ms, sys: 14.3 ms, total: 74.4 ms\n",
      "Wall time: 73.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reviewTextProcessing['SentimentModel']= reviewTextProcessing.Sentiment.apply(adjustSentimentModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reviewTextProcessing.loc[unfavorableReviews, ['Processed', 'Sentiment', 'SentimentModel']]\n",
    "#reviewTextProcessing.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewTextProcessing['CleanedJoin'] = reviewTextProcessing['Processed'].apply(', '.join)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['reviewText', 'rating', 'overall', 'Processed', 'Sentiment',\n",
       "       'SentimentModel', 'CleanedJoin'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewTextProcessing.shape\n",
    "reviewTextProcessing.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from gensim import corpora\n",
    "#dictionary = corpora.Dictionary(T)\n",
    "#print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    i hate it when my shirt collars not otherwise ...\n",
       "1    these little magnets are really powerful for t...\n",
       "2    i wanted something this small to mount on the ...\n",
       "3    i use these to magnetize my warhammer k miniat...\n",
       "4    they are soo freaking annoying, why, you spend...\n",
       "Name: CleanedJoin, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewTextProcessing['CleanedJoin'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewTextProcessing.sort_values(by='rating', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>rating</th>\n",
       "      <th>overall</th>\n",
       "      <th>Processed</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentModel</th>\n",
       "      <th>CleanedJoin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99410</th>\n",
       "      <td>Bought one and loved it! Ordered another two.O...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[bought one and loved it, ordered another two ...</td>\n",
       "      <td>[0.7, 0.2857142857142857, 3.700743415417188e-1...</td>\n",
       "      <td>[0.9857142857142857, 1.0]</td>\n",
       "      <td>bought one and loved it, ordered another two o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79663</th>\n",
       "      <td>What a waste of money.  Brand new and worse th...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[what a waste of money, brand new and worse th...</td>\n",
       "      <td>[-0.2, 0.03712121212121211, 0.0, 0.31785714285...</td>\n",
       "      <td>[0.36709956709956704, 1.0]</td>\n",
       "      <td>what a waste of money, brand new and worse tha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              reviewText  rating  overall  \\\n",
       "99410  Bought one and loved it! Ordered another two.O...       0      1.0   \n",
       "79663  What a waste of money.  Brand new and worse th...       0      1.0   \n",
       "\n",
       "                                               Processed  \\\n",
       "99410  [bought one and loved it, ordered another two ...   \n",
       "79663  [what a waste of money, brand new and worse th...   \n",
       "\n",
       "                                               Sentiment  \\\n",
       "99410  [0.7, 0.2857142857142857, 3.700743415417188e-1...   \n",
       "79663  [-0.2, 0.03712121212121211, 0.0, 0.31785714285...   \n",
       "\n",
       "                   SentimentModel  \\\n",
       "99410   [0.9857142857142857, 1.0]   \n",
       "79663  [0.36709956709956704, 1.0]   \n",
       "\n",
       "                                             CleanedJoin  \n",
       "99410  bought one and loved it, ordered another two o...  \n",
       "79663  what a waste of money, brand new and worse tha...  "
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewTextProcessing.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10105"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = reviewTextProcessing.loc[reviewTextProcessing['rating'] == 0, :].shape[0]\n",
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewTextProcessing = reviewTextProcessing.iloc[0:size*5, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>rating</th>\n",
       "      <th>overall</th>\n",
       "      <th>Processed</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentModel</th>\n",
       "      <th>CleanedJoin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99410</th>\n",
       "      <td>Bought one and loved it! Ordered another two.O...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[bought one and loved it, ordered another two ...</td>\n",
       "      <td>[0.7, 0.2857142857142857, 3.700743415417188e-1...</td>\n",
       "      <td>[0.9857142857142857, 1.0]</td>\n",
       "      <td>bought one and loved it, ordered another two o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79663</th>\n",
       "      <td>What a waste of money.  Brand new and worse th...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[what a waste of money, brand new and worse th...</td>\n",
       "      <td>[-0.2, 0.03712121212121211, 0.0, 0.31785714285...</td>\n",
       "      <td>[0.36709956709956704, 1.0]</td>\n",
       "      <td>what a waste of money, brand new and worse tha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              reviewText  rating  overall  \\\n",
       "99410  Bought one and loved it! Ordered another two.O...       0      1.0   \n",
       "79663  What a waste of money.  Brand new and worse th...       0      1.0   \n",
       "\n",
       "                                               Processed  \\\n",
       "99410  [bought one and loved it, ordered another two ...   \n",
       "79663  [what a waste of money, brand new and worse th...   \n",
       "\n",
       "                                               Sentiment  \\\n",
       "99410  [0.7, 0.2857142857142857, 3.700743415417188e-1...   \n",
       "79663  [-0.2, 0.03712121212121211, 0.0, 0.31785714285...   \n",
       "\n",
       "                   SentimentModel  \\\n",
       "99410   [0.9857142857142857, 1.0]   \n",
       "79663  [0.36709956709956704, 1.0]   \n",
       "\n",
       "                                             CleanedJoin  \n",
       "99410  bought one and loved it, ordered another two o...  \n",
       "79663  what a waste of money, brand new and worse tha...  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "additionalNegatives = reviewTextProcessing.iloc[0:size, :].copy()\n",
    "additionalNegatives.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>rating</th>\n",
       "      <th>overall</th>\n",
       "      <th>Processed</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentModel</th>\n",
       "      <th>CleanedJoin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99410</th>\n",
       "      <td>Bought one and loved it! Ordered another two.O...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[bought one and loved it, ordered another two ...</td>\n",
       "      <td>[0.7, 0.2857142857142857, 3.700743415417188e-1...</td>\n",
       "      <td>[0.9857142857142857, 1.0]</td>\n",
       "      <td>bought one and loved it, ordered another two o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              reviewText  rating  overall  \\\n",
       "99410  Bought one and loved it! Ordered another two.O...       0      1.0   \n",
       "\n",
       "                                               Processed  \\\n",
       "99410  [bought one and loved it, ordered another two ...   \n",
       "\n",
       "                                               Sentiment  \\\n",
       "99410  [0.7, 0.2857142857142857, 3.700743415417188e-1...   \n",
       "\n",
       "                  SentimentModel  \\\n",
       "99410  [0.9857142857142857, 1.0]   \n",
       "\n",
       "                                             CleanedJoin  \n",
       "99410  bought one and loved it, ordered another two o...  "
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pad more negative reviews for better training purposes\n",
    "testSample = pd.concat([reviewTextProcessing, additionalNegatives])\n",
    "#testSample.reset_index(drop=True, inplace=True)\n",
    "testSample.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60630"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import itertools\n",
    "\n",
    "largeText = testSample.CleanedJoin.to_list()\n",
    "#largeText = reviewTextProcessing.reviewText.to_list() # Not too good accuracy around 116 missed with %86.94\n",
    "\n",
    "len(largeText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentiment = reviewTextProcessing['SentimentModel'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "num_words = 15000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=num_words)\n",
    "tokenizer.fit_on_texts(largeText)\n",
    "#tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = largeText\n",
    "y = testSample['rating']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, random_state=310)\n",
    "\n",
    "x_train_text = X_train\n",
    "x_test_text = X_test\n",
    "\n",
    "x_train_tokens = tokenizer.texts_to_sequences(x_train_text)\n",
    "x_test_tokens = tokenizer.texts_to_sequences(x_test_text)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#  not very good way to arrange the samples \n",
    "size = int(len(largeText)*.75)\n",
    "x_train_text = largeText[:size]\n",
    "x_test_text = largeText[size:]\n",
    "\n",
    "y_train =  reviewTextProcessing['rating'][:size]\n",
    "y_test = reviewTextProcessing['rating'][size:]\n",
    "x_train_tokens = tokenizer.texts_to_sequences(x_train_text)\n",
    "x_test_tokens = tokenizer.texts_to_sequences(x_test_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45472, 15158, 45472, 15158)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train), len(y_test), len(x_train_text), len(x_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train_tokens[1], x_train_text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_train_text[1]\n",
    "np.array(x_train_tokens[1])\n",
    "num_tokens = [len(tokens) for tokens in x_train_tokens + x_test_tokens]\n",
    "num_tokens = np.array(num_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122.61286491835725, 4925)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(num_tokens), np.max(num_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143.06143605914914"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "408"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "max_tokens = int(max_tokens) \n",
    "max_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9587168068612898"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(num_tokens < max_tokens) / len(num_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((45472, 408), (15158, 408))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad = 'pre'\n",
    "#pad = 'post'\n",
    "x_train_pad = pad_sequences(x_train_tokens, maxlen=max_tokens, padding=pad, truncating=pad)\n",
    "x_test_pad = pad_sequences(x_test_tokens, maxlen=max_tokens, padding=pad, truncating=pad)\n",
    "x_train_pad.shape, x_test_pad.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3065    15     1   139    26     4   260  4527    19     4    25     4\n",
      "     7     3  3209  4644    45   321   482  2861     1  8293   482  4727\n",
      "    46     1   575    49   542  3065    12   399     1  5710   353    31\n",
      "    10  9121   289   282     3  2687    85     8    13  6322   482     4\n",
      "    25     6   139    38    81   358   793   259    64   100    26    28\n",
      "    37    10   210    43    48    54     3   473    49   282     8   563\n",
      "     6    13    25    13     7    85    28  9001  7978    40    38    81\n",
      "   358     1   358    20    10    50    10   669   100    19    28    20\n",
      "    10    50    10  1044    45     1   769   358     8     1   575  7020\n",
      "    14    31  1347    38   358   139   913     1  5710   528     8     1\n",
      "  5910  7020    66    16   105   139   913   113     1   575  5910  1404\n",
      "    49 11914    46  1443     5    52    39     4   271     5   139   913\n",
      "     9   247    24  8522     5   455    19    32    14    74    10    45\n",
      "  9209    58  1681   461    28    20   100  1219   461 10712  5168     1\n",
      "  5910  1404  5030    41   404     6    23  3033 10712  5168   146     1\n",
      "  5710   528  4874    11   382     6  6688   343     1  5362  3916     2\n",
      "   199     2    29   254   705  2510     1 10375   523     3    83  3148\n",
      "    54     1  5030  2705   246    45     1    34     8   382    11     1\n",
      " 10712    85     4  1160  6798   113    46     1  3462    99     1  6688\n",
      "     6     4   260  3380  5910  1404    41     3  4397     5    37     1\n",
      "   138    19     1    34     8    81   208  3946     8     1   138   262\n",
      "    51  1793  3448    60    20  6146   381     1   575  5910  1404  7020\n",
      "     6     1  5710   353     5   123    19     1   375     8     1  4672\n",
      "     7     1   575   154   581  7020    22     3   105   234  5910  1404\n",
      "    22   469     3   826    98   883   234   356    13   274   182  3497\n",
      "     1   209    15  7083    45   470  1435   298   834  6326   479  1512\n",
      "  7913   343     8   225     6   482    62    19    14    41    14    33\n",
      "    53   172    21  1044    21    88    64   234    17     1   138   461\n",
      "    21    64  1008    10   837  5910  1404  1407   171    14    31    10\n",
      "  2621    32    14    16     3  4225     8  2066    13   116    39     1\n",
      "  3715   448    11    27  1631   139   830    32    14    16   188    41\n",
      "    47   575  5910   154   581  1404  7020    14   247    45     9   234\n",
      "    19     4    78    66    10  1420     1  2906    13   575    41    12\n",
      "    88   115   469    85     4    25     4     7    10     1   138   234]\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 1):\n",
    "    print(x_train_pad[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_string(tokens):\n",
    "    # Map from tokens back to words.\n",
    "    words = [inverse_map[token] for token in tokens if token != 0]\n",
    "    \n",
    "    # Concatenate all words.\n",
    "    text = \" \".join(words)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = tokenizer.word_index\n",
    "inverse_map = dict(zip(idx.values(), idx.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i bought the toto toilet toto seat along with this seal, the seal did not fit my plumbing toilet connection, i did not use this seal, it is in the garage in the box'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_text[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i bought the toto toilet toto seat along with this seal the seal did not fit my plumbing toilet connection i did not use this seal it is in the garage in the box'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_to_string(x_train_tokens[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/ba/2d058dcf1b85b9c212cc58264c98a4a7dd92c989b798823cc5690d062bb2/Keras-2.2.5-py2.py3-none-any.whl (336kB)\n",
      "\u001b[K     |████████████████████████████████| 337kB 4.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /home/tone/anaconda3/lib/python3.7/site-packages (from keras) (1.12.0)\n",
      "Requirement already satisfied: pyyaml in /home/tone/anaconda3/lib/python3.7/site-packages (from keras) (5.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /home/tone/anaconda3/lib/python3.7/site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: h5py in /home/tone/anaconda3/lib/python3.7/site-packages (from keras) (2.9.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /home/tone/anaconda3/lib/python3.7/site-packages (from keras) (1.2.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /home/tone/anaconda3/lib/python3.7/site-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/tone/anaconda3/lib/python3.7/site-packages (from keras) (1.16.2)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.2.5\n"
     ]
    }
   ],
   "source": [
    "#!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense, Embedding, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0823 21:41:26.307747 139999309981504 deprecation_wrapper.py:119] From /home/tone/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0823 21:41:26.313521 139999309981504 deprecation_wrapper.py:119] From /home/tone/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0823 21:41:26.318373 139999309981504 deprecation_wrapper.py:119] From /home/tone/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0823 21:41:26.381014 139999309981504 deprecation_wrapper.py:119] From /home/tone/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0823 21:41:26.385502 139999309981504 deprecation_wrapper.py:119] From /home/tone/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0823 21:41:26.388785 139999309981504 deprecation.py:323] From /home/tone/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 408, 200)          3000000   \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 407, 100)          40100     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 3,066,213\n",
      "Trainable params: 3,066,213\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_cnn = Sequential()\n",
    "parameters = Embedding(num_words, 200, input_length=max_tokens)\n",
    "model_cnn.add(parameters)\n",
    "model_cnn.add(Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
    "model_cnn.add(GlobalMaxPooling1D())\n",
    "model_cnn.add(Dense(256, activation='relu'))\n",
    "model_cnn.add(Dense(1, activation='sigmoid'))\n",
    "model_cnn.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "model_cnn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45472"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = len(x_train_pad)\n",
    "index\n",
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 43198 samples, validate on 2274 samples\n",
      "Epoch 1/3\n",
      "43198/43198 [==============================] - 49s 1ms/step - loss: 0.0570 - acc: 0.9784 - val_loss: 0.2200 - val_acc: 0.9384\n",
      "Epoch 2/3\n",
      "43198/43198 [==============================] - 49s 1ms/step - loss: 0.0221 - acc: 0.9925 - val_loss: 0.2816 - val_acc: 0.9305\n",
      "Epoch 3/3\n",
      "43198/43198 [==============================] - 50s 1ms/step - loss: 0.0156 - acc: 0.9943 - val_loss: 0.3298 - val_acc: 0.9296\n",
      "CPU times: user 15min 19s, sys: 26.1 s, total: 15min 45s\n",
      "Wall time: 2min 28s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f53b40e9650>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_cnn.fit(x_train_pad, y_train, validation_split=0.05, epochs=3, batch_size=36)\n",
    "#model.fit(x_train_pad, y_train,validation_split=0.05, epochs=3, batch_size=74)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#more negative training\n",
    "#model_cnn.fit(x_negative_pad, y_negative, validation_split=0.05, epochs=3, batch_size=36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15158/15158 [==============================] - 3s 175us/step\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "result = model_cnn.evaluate(x_test_pad, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.96%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {0:.2%}\".format(result[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#y_pred = model_cnn_02.predict(x=x_test_pad[0:1000])\n",
    "y_pred = model_cnn.predict(x=x_test_pad)\n",
    "y_pred = y_pred.T[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15158.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.632692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.468342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.999588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "count  15158.000000\n",
       "mean       0.632692\n",
       "std        0.468342\n",
       "min        0.000000\n",
       "25%        0.000425\n",
       "50%        0.999588\n",
       "75%        1.000000\n",
       "max        1.000000"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_pred).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = y_pred.T[0]\n",
    "#list(np.where(y_pred.T[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15158,)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_pred = np.array([1.0 if p>0.5 else 0.0 for p in y_pred])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15158,)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cls_pred),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9296081277213353"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = (cls_pred==y_test).mean()\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15158"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = len(cls_pred)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4772, 286, 781, 9319)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Duplicate has been \n",
    "tn, fp, fn, tp = confusion_matrix(y_test, cls_pred).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5058, 10100)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.where(y_test==0)[0]),len(np.where(y_test==1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15152, 30320)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.where(y_train==0)[0]),len(np.where(y_train==1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_true = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.index\n",
    "y_test.values\n",
    "indexTable = pd.DataFrame()\n",
    "indexTable['Index'] = y_test.index\n",
    "indexTable['TrueRating'] = y_test.values\n",
    "indexTable['CNNRating'] = cls_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15158, 3)"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexTable.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14531, 3)"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare = indexTable.drop_duplicates(subset=\"Index\")\n",
    "compare.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14531, 5)"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = testSample.loc[compare.Index.to_list(), :]\n",
    "df = df.reset_index()\n",
    "#A.drop_duplicates()\n",
    "df= df.drop_duplicates(subset=\"index\")\n",
    "df.rename(columns={\"index\": \"Index\"}, inplace=True)\n",
    "df = df.loc[:, ['Index', 'reviewText', 'overall', 'SentimentModel']]\n",
    "\n",
    "textBlobRating = lambda result: result[1]\n",
    "df['textBlobRating'] = df.SentimentModel.apply(textBlobRating)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14531, 3), Index(['Index', 'TrueRating', 'CNNRating'], dtype='object'))"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = indexTable.drop_duplicates(subset=\"Index\")\n",
    "#result.sort_values(by=\"Index\")\n",
    "result.shape, result.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Index', 'reviewText', 'overall', 'SentimentModel', 'textBlobRating',\n",
       "       'TrueRating', 'CNNRating'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here is the result of comparison between TextBlob and CNN\n",
    "# Merged based On Index\n",
    "CNNResult = pd.merge(df, result, on=\"Index\", how=\"inner\")\n",
    "#CNNresult['CNNRating'].astype(int)\n",
    "CNNResult.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNNResult.CNNRating = CNNResult.CNNRating.astype(int)\n",
    "CNNResult.textBlobRating = CNNResult.textBlobRating.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Index', 'reviewText', 'overall', 'SentimentModel', 'textBlobRating',\n",
       "       'TrueRating', 'CNNRating'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNNResult.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = CNNResult.TrueRating.to_list()\n",
    "cnn_pred = CNNResult.CNNRating.to_list()\n",
    "textBlob_pred = CNNResult.textBlobRating.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4269, 162, 781, 9319)"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_true, cnn_pred).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1303, 3128, 622, 9478)"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_true, textBlob_pred).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14531"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 500\n",
    "\n",
    "#productsReviewData.cleanedText.head(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
