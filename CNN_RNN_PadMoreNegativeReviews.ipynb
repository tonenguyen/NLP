{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirPath = r\"\\data\"\n",
    "reviewPath = r\"reviews_Tools_and_Home_Improvement_5.json.gz\"\n",
    "#reviewPath = r\"reviews_Musical_Instruments_5.json.gz\"\n",
    "reviewPath = r\"cleanData_reviews_Musical_Instruments_5.json.gz\"\n",
    "path = dirPath + \"\\\\\" + reviewPath\n",
    "path = \"preprocessed_reviews_Musical_Instruments_5.pkl.gz\"\n",
    "path = \"preprocessed_reviews_Tools_and_Home_Improvement_5.pkl.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123707, 7)"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle(path)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10105"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negativeReviews = data.loc[data['trueRating'] == 0, :]\n",
    "negativeReviews.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data.iloc[0:size*5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>masterIndex</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>helpful</th>\n",
       "      <th>overall</th>\n",
       "      <th>trueRating</th>\n",
       "      <th>CleanedJoin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>123477</th>\n",
       "      <td>134239</td>\n",
       "      <td>B00JPBDL9W</td>\n",
       "      <td>I have converted three-quarters of my home to ...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>i have convert three quarter of my home to lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123556</th>\n",
       "      <td>134322</td>\n",
       "      <td>B00JXSASK2</td>\n",
       "      <td>Amazing that they designed this thing without ...</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>amaze that they design this thing without real...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        masterIndex        asin  \\\n",
       "123477       134239  B00JPBDL9W   \n",
       "123556       134322  B00JXSASK2   \n",
       "\n",
       "                                               reviewText helpful  overall  \\\n",
       "123477  I have converted three-quarters of my home to ...  [0, 0]      2.0   \n",
       "123556  Amazing that they designed this thing without ...  [2, 2]      1.0   \n",
       "\n",
       "        trueRating                                        CleanedJoin  \n",
       "123477         0.0  i have convert three quarter of my home to lea...  \n",
       "123556         0.0  amaze that they design this thing without real...  "
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negativeReviews.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>masterIndex</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>helpful</th>\n",
       "      <th>overall</th>\n",
       "      <th>trueRating</th>\n",
       "      <th>CleanedJoin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>123556</th>\n",
       "      <td>134322</td>\n",
       "      <td>B00JXSASK2</td>\n",
       "      <td>Amazing that they designed this thing without ...</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>amaze that they design this thing without real...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        masterIndex        asin  \\\n",
       "123556       134322  B00JXSASK2   \n",
       "\n",
       "                                               reviewText helpful  overall  \\\n",
       "123556  Amazing that they designed this thing without ...  [2, 2]      1.0   \n",
       "\n",
       "        trueRating                                        CleanedJoin  \n",
       "123556         0.0  amaze that they design this thing without real...  "
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pad more negative reviews for better training purposes\n",
    "testSample = pd.concat([data, negativeReviews])\n",
    "#testSample = data\n",
    "#testSample.reset_index(drop=True, inplace=True)\n",
    "testSample.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133812"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "largeText = testSample.CleanedJoin.to_list()\n",
    "#largeText = reviewTextProcessing.reviewText.to_list() # Not too good accuracy around 116 missed with %86.94\n",
    "\n",
    "len(largeText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 15000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=num_words)\n",
    "tokenizer.fit_on_texts(largeText)\n",
    "#tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = largeText\n",
    "y = testSample['trueRating']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, random_state=310)\n",
    "\n",
    "x_train_text = X_train\n",
    "x_test_text = X_test\n",
    "\n",
    "x_train_tokens = tokenizer.texts_to_sequences(x_train_text)\n",
    "x_test_tokens = tokenizer.texts_to_sequences(x_test_text)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#  not very good way to arrange the samples \n",
    "size = int(len(largeText)*.75)\n",
    "x_train_text = largeText[:size]\n",
    "x_test_text = largeText[size:]\n",
    "\n",
    "y_train =  reviewTextProcessing['rating'][:size]\n",
    "y_test = reviewTextProcessing['rating'][size:]\n",
    "x_train_tokens = tokenizer.texts_to_sequences(x_train_text)\n",
    "x_test_tokens = tokenizer.texts_to_sequences(x_test_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100359, 33453, 100359, 33453)"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train), len(y_test), len(x_train_text), len(x_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train_tokens[1], x_train_text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_train_text[1]\n",
    "np.array(x_train_tokens[1])\n",
    "num_tokens = [len(tokens) for tokens in x_train_tokens + x_test_tokens]\n",
    "num_tokens = np.array(num_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111.61465339431442, 4959)"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(num_tokens), np.max(num_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133.85901020345165"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "379"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "max_tokens = int(max_tokens) \n",
    "max_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9588078797118346"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(num_tokens < max_tokens) / len(num_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100359, 379), (33453, 379))"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad = 'pre'\n",
    "#pad = 'post'\n",
    "x_train_pad = pad_sequences(x_train_tokens, maxlen=max_tokens, padding=pad, truncating=pad)\n",
    "x_test_pad = pad_sequences(x_test_tokens, maxlen=max_tokens, padding=pad, truncating=pad)\n",
    "x_train_pad.shape, x_test_pad.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0   28\n",
      "  248  706   10   11    1   79    8 1209    1 1466   12   49  846  861\n",
      "   53   40    6   52  177    1   47 1209    4    2   59    6   45  166\n",
      "   23    3   44    8   12    8   89  531   16    1   53  373  324    5\n",
      "    2   32  302    6   19    1 1391   22   18   75   26    2  602    6\n",
      "   18]\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 4):\n",
    "    print(x_train_pad[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_string(tokens):\n",
    "    # Map from tokens back to words.\n",
    "    words = [inverse_map[token] for token in tokens if token != 0]\n",
    "    \n",
    "    # Concatenate all words.\n",
    "    text = \" \".join(words)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = tokenizer.word_index\n",
    "inverse_map = dict(zip(idx.values(), idx.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'work awesome'"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'work awesome'"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_to_string(x_train_tokens[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.2'"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'modelCNNImplementation' from 'C:\\\\Study\\\\Projects\\\\NLP\\\\modelCNNImplementation.py'>"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#abstract CNN\n",
    "import modelCNNImplementation as modelCNN\n",
    "import importlib\n",
    "importlib.reload(modelCNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 379, 200)          3000000   \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 378, 100)          40100     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_5 (Glob (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 3,066,213\n",
      "Trainable params: 3,066,213\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_cnn = modelCNN.compileCNNModel(max_tokens=max_tokens)\n",
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'modelRNNImplementation' from 'C:\\\\Study\\\\Projects\\\\NLP\\\\modelRNNImplementation.py'>"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import modelRNNImplementation as modelRNN\n",
    "import importlib\n",
    "importlib.reload(modelRNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer_embedding (Embedding)  (None, 379, 24)           360000    \n",
      "_________________________________________________________________\n",
      "gru_7 (GRU)                  (None, 379, 16)           1968      \n",
      "_________________________________________________________________\n",
      "gru_8 (GRU)                  (None, 379, 8)            600       \n",
      "_________________________________________________________________\n",
      "gru_9 (GRU)                  (None, 4)                 156       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 362,729\n",
      "Trainable params: 362,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_rnn = modelRNN.compileRNNModel(max_tokens=max_tokens)\n",
    "model_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100359, 33453, 133812)"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = len(x_train_pad)\n",
    "index\n",
    "len(y_train), len(y_test), len(y_train) + len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 95341 samples, validate on 5018 samples\n",
      "Epoch 1/3\n",
      "26064/95341 [=======>......................] - ETA: 7:07 - loss: 0.2813 - acc: 0.8878"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_cnn.fit(x_train_pad, y_train, validation_split=0.05, epochs=3, batch_size=36)\n",
    "#model.fit(x_train_pad, y_train,validation_split=0.05, epochs=3, batch_size=74)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_rnn.fit(x_train_pad, y_train, validation_split=0.05, epochs=3, batch_size=36)\n",
    "#model.fit(x_train_pad, y_train,validation_split=0.05, epochs=3, batch_size=74)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "result = model_cnn.evaluate(x_test_pad, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "rnn_result = model_rnn.evaluate(x_test_pad, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: {0:.2%}\".format(rnn_result[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: {0:.2%}\".format(result[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "y_pred = model_cnn.predict(x=x_test_pad)\n",
    "#y_pred = model_rnn.predict(x=x_test_pad)\n",
    "y_pred = y_pred.T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_pred).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_pred = np.array([1.0 if p>0.5 else 0.0 for p in y_pred])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cls_pred),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (cls_pred==y_test).mean()\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = len(cls_pred)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Duplicate has been \n",
    "tn, fp, fn, tp = confusion_matrix(y_test, cls_pred).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.where(y_test==0)[0]),len(np.where(y_test==1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.where(y_train==0)[0]),len(np.where(y_train==1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_true = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.index\n",
    "y_test.values\n",
    "result = pd.DataFrame()\n",
    "result['Index'] = y_test.index\n",
    "result['TrueRating'] = y_test.values\n",
    "result['RNNRating'] = cls_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to drop the duplicates due to negative padding\n",
    "result.drop_duplicates(subset=\"Index\", inplace=True)\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = testSample.loc[result.Index.to_list(), :]\n",
    "df = df.reset_index()\n",
    "#A.drop_duplicates()\n",
    "df= df.drop_duplicates(subset=\"index\")\n",
    "df.rename(columns={\"index\": \"Index\"}, inplace=True)\n",
    "df.shape, df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelResult = pd.merge(df, result, on=\"Index\", how=\"inner\")\n",
    "modelResult.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TextBlobImplementation as TextBlob\n",
    "import importlib\n",
    "importlib.reload(TextBlob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSample = modelResult.iloc[3, :]['CleanedJoin']\n",
    "\n",
    "TextBlob.getPolarityFromText(testSample.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelResult['textBlobRating'] = modelResult.CleanedJoin.str.split(',')\n",
    "modelResult['textBlobRating'] = modelResult.textBlobRating.apply(TextBlob.getPolarityFromText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelResult.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = modelResult.TrueRating.to_list()\n",
    "cnn_pred = modelResult.CNNRating.to_list()\n",
    "textBlob_pred = modelResult.textBlobRating.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = modelResult.TrueRating.to_list()\n",
    "rnn_pred = modelResult.RNNRating.to_list()\n",
    "textBlob_pred = modelResult.textBlobRating.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 78, 37, 2227)"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_true, cnn_pred).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113, 88, 34, 2224)"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_true, rnn_pred).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 151, 112, 2146)"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_true, textBlob_pred).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 50\n",
    "\n",
    "#productsReviewData.cleanedText.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10K review comparison\n",
    "\n",
    "## padding extra negative reviews\n",
    "\n",
    "##### we pick up two unique negative extras with the sampling when we padded\n",
    "\n",
    "tn, fp, fn, tp\n",
    "\n",
    "(174, 27, 44, 2214) CNN for negative reviews padding \n",
    "(113, 88, 34, 2224)  RNN with negative review padding\n",
    "(50, 151, 112, 2146) textBlob with negative padding \n",
    "\n",
    "## no padding extra negative reviews\n",
    "\n",
    "tn, fp, fn, tp\n",
    "\n",
    "(31, 78, 37, 2227)  CNN without negative reviews padding\n",
    "(3, 106, 2, 2262)   RNN without negative reviews padding\n",
    "(27, 82, 106, 2158) textBlob without negative reviews padding\n",
    "\n",
    "\n",
    "## Multinomial Naive Bayes no padding extra negative reviews\n",
    "\n",
    "tn, fp, fn, tp\n",
    "\n",
    "(12, 97, 232, 2032) Multinomial Naive Bayes # n-gram (1,2), num_words = 10000\n",
    "(26, 83, 393, 1871) Multinomial Naive Bayes # n-gram (1,1), num_words = 3000\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
