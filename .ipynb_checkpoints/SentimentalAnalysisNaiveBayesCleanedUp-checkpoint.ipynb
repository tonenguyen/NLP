{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "\n",
    "import gzip #for parsing gz files\n",
    "import pandas as pd\n",
    "import re \n",
    "import inflect #numeric/cardinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirPath = r\"C:\\Study\\Projects\\NLP\\data\"\n",
    "reviewPath = r\"reviews_Tools_and_Home_Improvement_5.json.gz\"\n",
    "#reviewPath = r\"reviews_Musical_Instruments_5.json.gz\"\n",
    "qaPath = r\"C:\\Study\\Projects\\NLP\\data\" \n",
    "path = dirPath + \"\\\\\" + reviewPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFile = gzip.open(path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need this function because large amount of data we are going to load up\n",
    "\n",
    "# http://jmcauley.ucsd.edu/data/amazon/index.html\n",
    "# eval function allows text to be parsed as python code\n",
    "# parse function is a generator with yield\n",
    "# yield when we want to iterate over a sequence, but don't want to store the entire sequence in memory\n",
    "def parse(dataFile):\n",
    "    for each in dataFile:\n",
    "        yield eval(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each review for a product in dataFile maps dict[nth] = review (nth)\n",
    "# enumerate can't be used on a generator\n",
    "count = 0\n",
    "productReviews = {}\n",
    "for eachReview in parse(dataFile):\n",
    "    productReviews[count] = eachReview\n",
    "    count = count + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134476"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(productReviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "#productReviews[101718]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "productsReviewData = pd.DataFrame.from_dict(productReviews, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A4IL0CLL27Q33</td>\n",
       "      <td>104800001X</td>\n",
       "      <td>D. Brennan</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>I hate it when my shirt collars, not otherwise...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Perfect for collar stay management</td>\n",
       "      <td>1390953600</td>\n",
       "      <td>01 29, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3Q5W5E7TDVLJF</td>\n",
       "      <td>104800001X</td>\n",
       "      <td>funnyc130</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>These little magnets are really powerful for t...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Neat</td>\n",
       "      <td>1369958400</td>\n",
       "      <td>05 31, 2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin reviewerName helpful  \\\n",
       "0   A4IL0CLL27Q33  104800001X   D. Brennan  [0, 1]   \n",
       "1  A3Q5W5E7TDVLJF  104800001X    funnyc130  [0, 0]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  I hate it when my shirt collars, not otherwise...      5.0   \n",
       "1  These little magnets are really powerful for t...      5.0   \n",
       "\n",
       "                              summary  unixReviewTime   reviewTime  \n",
       "0  Perfect for collar stay management      1390953600  01 29, 2014  \n",
       "1                                Neat      1369958400  05 31, 2013  "
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "productsReviewData.shape\n",
    "productsReviewData.columns\n",
    "productsReviewData.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduceData = productsReviewData.loc[:, ['asin', 'reviewerName', 'reviewText', 'helpful', 'overall']]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduceData = reduceData.loc[reduceData['overall']!=3.0, ['asin', 'reviewerName', 'reviewText', 'helpful', 'overall']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = lambda x: 1 if x > 2.0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>helpful</th>\n",
       "      <th>overall</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>134322</th>\n",
       "      <td>Amazing that they designed this thing without ...</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55236</th>\n",
       "      <td>I was ready to pick up one of these at a woodw...</td>\n",
       "      <td>[30, 38]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55234</th>\n",
       "      <td>I bought this set from amazon but is not like ...</td>\n",
       "      <td>[8, 15]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105852</th>\n",
       "      <td>Horrible.Not one blade runs true.  Some are as...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reviewText   helpful  overall  \\\n",
       "134322  Amazing that they designed this thing without ...    [2, 2]      1.0   \n",
       "55236   I was ready to pick up one of these at a woodw...  [30, 38]      1.0   \n",
       "55234   I bought this set from amazon but is not like ...   [8, 15]      1.0   \n",
       "105852  Horrible.Not one blade runs true.  Some are as...    [0, 0]      1.0   \n",
       "\n",
       "        rating  \n",
       "134322       0  \n",
       "55236        0  \n",
       "55234        0  \n",
       "105852       0  "
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduceData['rating'] = reduceData['overall'].apply(rating)\n",
    "unfavorableReviews = list(reduceData.loc[ reduceData['rating'] == 0, \n",
    "                                         ['reviewText', 'helpful', 'overall', 'rating']].sort_values(by='overall').index)\n",
    "#unfavorableReviews\n",
    "reduceData.loc[ reduceData['rating'] == 0, ['reviewText', 'helpful', 'overall', 'rating']].sort_values(by='overall').head(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewTextProcessing = pd.DataFrame(reduceData.reviewText.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewTextProcessing['rating'] = reduceData['rating']\n",
    "reviewTextProcessing['overall'] = reduceData['overall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123707, 3)"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "productsReviewData.dtypes\n",
    "len(productsReviewData)\n",
    "# reviewText, rating, overall\n",
    "reviewTextProcessing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reviewTextProcessing.loc[reviewTextProcessing['rating']==0, ['rating', 'overall', 'Processed', 'SentimentModel']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([\"ain't\", \"aren't\", \"can't\", \"can't've\", \"'cause\", \"could've\", \"couldn't\", \"couldn't've\", \"didn't\", \"doesn't\", \"don't\", \"hadn't\", \"hadn't've\", \"hasn't\", \"haven't\", \"he'd\", \"he'd've\", \"he'll\", \"he'll've\", \"he's\", \"how'd\", \"how'd'y\", \"how'll\", \"how's\", \"I'd\", \"I'd've\", \"I'll\", \"I'll've\", \"I'm\", \"I've\", \"isn't\", \"it'd\", \"it'd've\", \"it'll\", \"it'll've\", \"it's\", \"let's\", \"ma'am\", \"mayn't\", \"might've\", \"mightn't\", \"mightn't've\", \"must've\", \"mustn't\", \"mustn't've\", \"needn't\", \"needn't've\", \"o'clock\", \"oughtn't\", \"oughtn't've\", \"shan't\", \"sha'n't\", \"shan't've\", \"she'd\", \"she'd've\", \"she'll\", \"she'll've\", \"she's\", 's###', \"should've\", \"shouldn't\", \"shouldn't've\", \"so've\", \"so's\", \"that'd\", \"that'd've\", \"that's\", \"there'd\", \"there'd've\", \"there's\", \"they'd\", \"they'd've\", \"they'll\", \"they'll've\", \"they're\", \"they've\", \"to've\", \"wasn't\", \"we'd\", \"we'd've\", \"we'll\", \"we'll've\", \"we're\", \"we've\", \"weren't\", \"what'll\", \"what'll've\", \"what're\", \"what's\", \"what've\", \"when's\", \"when've\", \"where'd\", \"where's\", \"where've\", \"who'll\", \"who'll've\", \"who's\", \"who've\", \"why's\", \"why've\", \"will've\", \"won't\", \"won't've\", \"would've\", \"wouldn't\", \"wouldn't've\", \"y'all\", \"y'all'd\", \"y'all'd've\", \"y'all're\", \"y'all've\", \"you'd\", \"you'd've\", \"you'll\", \"you'll've\", \"you're\", \"you've\"])\n"
     ]
    }
   ],
   "source": [
    "#https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python\n",
    "import Contractions_Words as contractions\n",
    "import importlib\n",
    "importlib.reload(contractions)\n",
    "\n",
    "contractions_dict = contractions.contractions_dict\n",
    "\n",
    "print(contractions_dict.keys())\n",
    "#print(contractions_dict[\"s***\"])\n",
    "\n",
    "pattern = '%s' % '|'.join(contractions_dict.keys())\n",
    "#pattern = r\"%s\" % pattern\n",
    "#print(pattern)\n",
    "contractions_re = re.compile(pattern)\n",
    "def expand_contractions(s, contractions_dict=contractions_dict):\n",
    "    #edit for special case like s*** etc\n",
    "    s = re.sub(\"\\*\", \"#\", s)\n",
    "    def replace(match):\n",
    "        #print(type(match), match)\n",
    "        return contractions_dict[match.group(0)]\n",
    "    return contractions_re.sub(replace, s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s###\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'shit'"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample1 = \"s***\"\n",
    "print(re.sub(\"\\*\", \"#\", sample1))\n",
    "\n",
    "sample = \"I don\\'t know what to say nay. I haven\\'t. s###\"\n",
    "expand_contractions(sample)\n",
    "expand_contractions(sample1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import string\n",
    "\n",
    "# return both wholeText, paragraph Text\n",
    "def singleReviewCleanUp(sample):\n",
    "    #print(sample)\n",
    "    #sample = sample.decode(\"utf-8\")\n",
    "    sample = expand_contractions(sample)\n",
    "    sample = sample.lower()\n",
    "    \n",
    "    #for word in sample:\n",
    "    #    print(lemmatizer.lemmatize(word, wordnet.VERB))\n",
    "    \n",
    "    review = sent_tokenize(sample)\n",
    "    #print(review)\n",
    "    for count, eachSent in enumerate(review):\n",
    "        #remove numbers\n",
    "        eachSent = re.sub(\"r'\\d+/\\d+|\\d+|\\$\\d+.\\d+\", \" \", eachSent)\n",
    "        #remove string\n",
    "        eachSent = re.sub('[%s]' % re.escape(string.punctuation), ' ', eachSent)\n",
    "        #word tokens\n",
    "        #print([lemmatizer.lemmatize(text, wordnet.VERB) for text in eachSent.split()])\n",
    "        eachSent = word_tokenize(eachSent)\n",
    "        review[count] = eachSent\n",
    "        # lemmatize and remove stopWords\n",
    "        #eachSent = [word for word in eachSent if not word in stopWords]\n",
    "        #eachSent = [lemmatizer.lemmatize(word, wordnet.VERB) for word in eachSent]\n",
    "        #eachSent = [lemmatizer.lemmatize(word, wordnet.VERB) for word in eachSent if not word in stopWords]\n",
    "        review[count] = \" \".join(eachSent)\n",
    "    wholeText = [\" \".join(review) ]\n",
    "    paragraphText = review\n",
    "    #return wholeText\n",
    "    #return paragraphText\n",
    "    return paragraphText, wholeText\n",
    "\n",
    "#paragraphText, wholeText = singleReviewCleanUp(sample)\n",
    "#wholeText, paragraphText\n",
    "#paragraphText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Give me back text in a paragraph sentence forms. They do have more values than a clobbed of text based on Polarity Check.\n",
    "cleanUpTextParagraph = lambda text: singleReviewCleanUp(text)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reviewTextProcessing['Processed'] = reviewTextProcessing.reviewText.apply(cleanUpTextParagraph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewTextProcessing['CleanedJoin'] = reviewTextProcessing['Processed'].apply(', '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['reviewText', 'rating', 'overall', 'Processed', 'CleanedJoin'], dtype='object')"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewTextProcessing.shape\n",
    "reviewTextProcessing.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123707"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import itertools\n",
    "\n",
    "largeText = reviewTextProcessing.CleanedJoin.to_list()\n",
    "#largeText = reviewTextProcessing.reviewText.to_list() # Not too good accuracy around 116 missed with %86.94\n",
    "\n",
    "len(largeText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "#largeText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=num_words)\n",
    "tokenizer.fit_on_texts(largeText)\n",
    "#tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = int(len(largeText)*.75)\n",
    "x_train_text = largeText[:size]\n",
    "x_test_text = largeText[size:]\n",
    "\n",
    "y_train =  reviewTextProcessing['rating'][:size]\n",
    "y_test = reviewTextProcessing['rating'][size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92780, 30927, 92780, 30927)"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train), len(y_test), len(x_train_text), len(x_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "top_num_of_words = 15000\n",
    "#vect = TfidfVectorizer(max_features=top_num_of_words, stop_words = 'english')\n",
    "vect = TfidfVectorizer(max_features=top_num_of_words, stop_words = 'english', ngram_range=(1, 3), max_df=0.9, min_df=2, use_idf=True, sublinear_tf=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "text = x_train_text\n",
    "vect.fit(text)\n",
    "tfidf_train = vect.transform(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = LogisticRegression(C=0.2, dual=True)\n",
    "#(0, 2418, 0, 31201) nooo negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100857"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = len(x_train_text)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 114 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(tfidf_train, y_train)\n",
    "#model.fit(x_train_pad, y_train,validation_split=0.05, epochs=3, batch_size=74)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 28.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vect.fit(x_test_text)\n",
    "tfidf_test = vect.transform(x_test_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<30927x15000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1631192 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(tfidf_test)\n",
    "accuracy = (preds==y_test).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.49%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {0:.2%}\".format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(195, 2232, 2255, 26245)"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "count  1000.0\n",
       "mean      1.0\n",
       "std       0.0\n",
       "min       1.0\n",
       "25%       1.0\n",
       "50%       1.0\n",
       "75%       1.0\n",
       "max       1.0"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_pred).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = y_pred.T[0]\n",
    "#list(np.where(y_pred.T[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3,   5,  20,  23,  26,  36,  37,  40,  41,  42,  43,  54,  55,\n",
       "        57,  58,  60,  61,  65,  67,  70,  72,  73,  75,  76,  79,  83,\n",
       "        85,  86,  87,  88,  89,  90,  91,  92,  93,  97, 100, 101, 106,\n",
       "       107, 116, 124, 129, 130, 133, 134, 138, 143, 151, 153, 154, 155,\n",
       "       156, 160, 165, 166, 168, 171, 175, 185, 190, 195, 196, 200, 201,\n",
       "       205, 206, 207, 211, 214, 216, 217, 218, 219, 229, 232, 234, 235,\n",
       "       237, 241, 243, 244, 247, 248, 249, 250, 257, 260, 266, 268, 271,\n",
       "       272, 276, 280, 283, 287, 288, 290, 292, 294, 295, 296, 297, 299,\n",
       "       301, 302, 306, 308, 309, 311, 312, 313, 314, 315, 317, 321, 323,\n",
       "       326, 328, 333, 334, 335, 341, 342, 345, 348, 351, 352, 353, 354,\n",
       "       359, 360, 361, 363, 367, 371, 372, 375, 376, 381, 382, 383, 387,\n",
       "       388, 392, 394, 395, 396, 400, 401, 402, 407, 408, 411, 414, 415,\n",
       "       416, 418, 426, 431, 432, 435, 441, 443, 444, 446, 447, 449, 451,\n",
       "       452, 454, 459, 463, 464, 466, 468, 475, 477, 484, 488, 490, 491,\n",
       "       492, 493, 496, 497, 499, 501, 502, 508, 509, 510, 511, 517, 520,\n",
       "       521, 522, 523, 524, 528, 530, 536, 540, 541, 542, 548, 552, 553,\n",
       "       559, 560, 562, 563, 566, 568, 569, 572, 578, 580, 583, 588, 596,\n",
       "       599, 600, 602, 605, 607, 611, 615, 616, 619, 622, 624, 625, 628,\n",
       "       631, 634, 637, 638, 641, 646, 648, 649, 653, 655, 657, 658, 660,\n",
       "       662, 665, 671, 673, 676, 678, 682, 684, 687, 689, 690, 692, 694,\n",
       "       697, 698, 703, 704, 705, 707, 708, 713, 715, 716, 717, 718, 720,\n",
       "       722, 728, 733, 735, 736, 738, 745, 746, 752, 753, 754, 756, 757,\n",
       "       758, 759, 760, 763, 764, 766, 771, 772, 774, 778, 781, 784, 787,\n",
       "       790, 798, 804, 806, 813, 817, 818, 819, 820, 821, 822, 823, 824,\n",
       "       825, 826, 827, 828, 833, 834, 837, 840, 842, 843, 845, 846, 848,\n",
       "       851, 853, 855, 856, 858, 859, 860, 863, 865, 867, 870, 874, 876,\n",
       "       884, 886, 887, 892, 893, 895, 896, 898, 899, 900, 901, 902, 904,\n",
       "       906, 907, 908, 909, 910, 916, 919, 922, 924, 925, 928, 932, 934,\n",
       "       936, 939, 942, 944, 946, 947, 948, 949, 950, 951, 953, 954, 955,\n",
       "       957, 958, 960, 964, 965, 966, 968, 970, 974, 976, 986, 990, 992,\n",
       "       994, 996, 997, 998], dtype=int64)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect = np.where(cls_pred != cls_true)\n",
    "incorrect = incorrect[0]\n",
    "incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   4,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
       "        15,  16,  17,  18,  19,  21,  22,  24,  25,  27,  28,  29,  30,\n",
       "        31,  32,  33,  34,  35,  38,  39,  44,  45,  46,  47,  48,  49,\n",
       "        50,  51,  52,  53,  56,  59,  62,  63,  64,  66,  68,  69,  71,\n",
       "        74,  77,  78,  80,  81,  82,  84,  94,  95,  96,  98,  99, 102,\n",
       "       103, 104, 105, 108, 109, 110, 111, 112, 113, 114, 115, 117, 118,\n",
       "       119, 120, 121, 122, 123, 125, 126, 127, 128, 131, 132, 135, 136,\n",
       "       137, 139, 140, 141, 142, 144, 145, 146, 147, 148, 149, 150, 152,\n",
       "       157, 158, 159, 161, 162, 163, 164, 167, 169, 170, 172, 173, 174,\n",
       "       176, 177, 178, 179, 180, 181, 182, 183, 184, 186, 187, 188, 189,\n",
       "       191, 192, 193, 194, 197, 198, 199, 202, 203, 204, 208, 209, 210,\n",
       "       212, 213, 215, 220, 221, 222, 223, 224, 225, 226, 227, 228, 230,\n",
       "       231, 233, 236, 238, 239, 240, 242, 245, 246, 251, 252, 253, 254,\n",
       "       255, 256, 258, 259, 261, 262, 263, 264, 265, 267, 269, 270, 273,\n",
       "       274, 275, 277, 278, 279, 281, 282, 284, 285, 286, 289, 291, 293,\n",
       "       298, 300, 303, 304, 305, 307, 310, 316, 318, 319, 320, 322, 324,\n",
       "       325, 327, 329, 330, 331, 332, 336, 337, 338, 339, 340, 343, 344,\n",
       "       346, 347, 349, 350, 355, 356, 357, 358, 362, 364, 365, 366, 368,\n",
       "       369, 370, 373, 374, 377, 378, 379, 380, 384, 385, 386, 389, 390,\n",
       "       391, 393, 397, 398, 399, 403, 404, 405, 406, 409, 410, 412, 413,\n",
       "       417, 419, 420, 421, 422, 423, 424, 425, 427, 428, 429, 430, 433,\n",
       "       434, 436, 437, 438, 439, 440, 442, 445, 448, 450, 453, 455, 456,\n",
       "       457, 458, 460, 461, 462, 465, 467, 469, 470, 471, 472, 473, 474,\n",
       "       476, 478, 479, 480, 481, 482, 483, 485, 486, 487, 489, 494, 495,\n",
       "       498, 500, 503, 504, 505, 506, 507, 512, 513, 514, 515, 516, 518,\n",
       "       519, 525, 526, 527, 529, 531, 532, 533, 534, 535, 537, 538, 539,\n",
       "       543, 544, 545, 546, 547, 549, 550, 551, 554, 555, 556, 557, 558,\n",
       "       561, 564, 565, 567, 570, 571, 573, 574, 575, 576, 577, 579, 581,\n",
       "       582, 584, 585, 586, 587, 589, 590, 591, 592, 593, 594, 595, 597,\n",
       "       598, 601, 603, 604, 606, 608, 609, 610, 612, 613, 614, 617, 618,\n",
       "       620, 621, 623, 626, 627, 629, 630, 632, 633, 635, 636, 639, 640,\n",
       "       642, 643, 644, 645, 647, 650, 651, 652, 654, 656, 659, 661, 663,\n",
       "       664, 666, 667, 668, 669, 670, 672, 674, 675, 677, 679, 680, 681,\n",
       "       683, 685, 686, 688, 691, 693, 695, 696, 699, 700, 701, 702, 706,\n",
       "       709, 710, 711, 712, 714, 719, 721, 723, 724, 725, 726, 727, 729,\n",
       "       730, 731, 732, 734, 737, 739, 740, 741, 742, 743, 744, 747, 748,\n",
       "       749, 750, 751, 755, 761, 762, 765, 767, 768, 769, 770, 773, 775,\n",
       "       776, 777, 779, 780, 782, 783, 785, 786, 788, 789, 791, 792, 793,\n",
       "       794, 795, 796, 797, 799, 800, 801, 802, 803, 805, 807, 808, 809,\n",
       "       810, 811, 812, 814, 815, 816, 829, 830, 831, 832, 835, 836, 838,\n",
       "       839, 841, 844, 847, 849, 850, 852, 854, 857, 861, 862, 864, 866,\n",
       "       868, 869, 871, 872, 873, 875, 877, 878, 879, 880, 881, 882, 883,\n",
       "       885, 888, 889, 890, 891, 894, 897, 903, 905, 911, 912, 913, 914,\n",
       "       915, 917, 918, 920, 921, 923, 926, 927, 929, 930, 931, 933, 935,\n",
       "       937, 938, 940, 941, 943, 945, 952, 956, 959, 961, 962, 963, 967,\n",
       "       969, 971, 972, 973, 975, 977, 978, 979, 980, 981, 982, 983, 984,\n",
       "       985, 987, 988, 989, 991, 993, 995, 999], dtype=int64)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = np.where(cls_pred == cls_true)\n",
    "correct = correct[0]\n",
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (374,) (626,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-141-c95a1e1d5016>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mincorrect\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[0mincorrect\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (374,) (626,) "
     ]
    }
   ],
   "source": [
    "len(incorrect), len(correct)\n",
    "(incorrect) (correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_location = np.where(cls_pred.T)[0] + index\n",
    "len(result_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 5)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "NBresult = reviewTextProcessing.loc[list(result_location),  ['reviewText', 'overall', 'rating', 'Sentiment' , 'SentimentModel']]\n",
    "#CNNresult.head(2)\n",
    "#CNNresult.shape\n",
    "#result_location\n",
    "#result_location\n",
    "NBresult.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBresult['NB_Sentiment'] =  list(y_pred.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumSentiment = lambda x: x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = NBresult.rating.to_list()\n",
    "NB_pred = NBresult.NB_Sentiment.to_list()\n",
    "textBlob_pred = NBresult.TextBlob_Sentiment.to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#textBlob_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 22, 352, 606)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_true, NB_pred).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 28, 57, 901)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_true, textBlob_pred).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 500\n",
    "\n",
    "#productsReviewData.cleanedText.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
