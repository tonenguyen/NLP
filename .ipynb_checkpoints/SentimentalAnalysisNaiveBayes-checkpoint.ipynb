{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "\n",
    "import gzip #for parsing gz files\n",
    "import pandas as pd\n",
    "import re \n",
    "import inflect #numeric/cardinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirPath = r\"C:\\Study\\Projects\\NLP\\data\"\n",
    "#reviewPath = r\"reviews_Tools_and_Home_Improvement_5.json.gz\"\n",
    "reviewPath = r\"reviews_Musical_Instruments_5.json.gz\"\n",
    "qaPath = r\"C:\\Study\\Projects\\NLP\\data\" \n",
    "path = dirPath + \"\\\\\" + reviewPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFile = gzip.open(path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need this function because large amount of data we are going to load up\n",
    "\n",
    "# http://jmcauley.ucsd.edu/data/amazon/index.html\n",
    "# eval function allows text to be parsed as python code\n",
    "# parse function is a generator with yield\n",
    "# yield when we want to iterate over a sequence, but don't want to store the entire sequence in memory\n",
    "def parse(dataFile):\n",
    "    for each in dataFile:\n",
    "        yield eval(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each review for a product in dataFile maps dict[nth] = review (nth)\n",
    "# enumerate can't be used on a generator\n",
    "count = 0\n",
    "productReviews = {}\n",
    "for eachReview in parse(dataFile):\n",
    "    productReviews[count] = eachReview\n",
    "    count = count + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10261"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(productReviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#productReviews[101718]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "productsReviewData = pd.DataFrame.from_dict(productReviews, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2IBPI20UZIR0U</td>\n",
       "      <td>1384719342</td>\n",
       "      <td>cassandra tu \"Yeah, well, that's just like, u...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Not much to write about here, but it does exac...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>good</td>\n",
       "      <td>1393545600</td>\n",
       "      <td>02 28, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A14VAT5EAX3D9S</td>\n",
       "      <td>1384719342</td>\n",
       "      <td>Jake</td>\n",
       "      <td>[13, 14]</td>\n",
       "      <td>The product does exactly as it should and is q...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Jake</td>\n",
       "      <td>1363392000</td>\n",
       "      <td>03 16, 2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin  \\\n",
       "0  A2IBPI20UZIR0U  1384719342   \n",
       "1  A14VAT5EAX3D9S  1384719342   \n",
       "\n",
       "                                       reviewerName   helpful  \\\n",
       "0  cassandra tu \"Yeah, well, that's just like, u...    [0, 0]   \n",
       "1                                              Jake  [13, 14]   \n",
       "\n",
       "                                          reviewText  overall summary  \\\n",
       "0  Not much to write about here, but it does exac...      5.0    good   \n",
       "1  The product does exactly as it should and is q...      5.0    Jake   \n",
       "\n",
       "   unixReviewTime   reviewTime  \n",
       "0      1393545600  02 28, 2014  \n",
       "1      1363392000  03 16, 2013  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "productsReviewData.shape\n",
    "productsReviewData.columns\n",
    "productsReviewData.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduceData = productsReviewData.loc[:, ['asin', 'reviewerName', 'reviewText', 'helpful', 'overall']]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = lambda x: 1 if x > 2.0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>helpful</th>\n",
       "      <th>overall</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5906</th>\n",
       "      <td>i got this despite the warnings about it being...</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4405</th>\n",
       "      <td>This thing is useless. Good idea, but way too ...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4415</th>\n",
       "      <td>I've had it for about a month now and it hasn'...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4437</th>\n",
       "      <td>It's really not a 200w system.  The booklet ev...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4475</th>\n",
       "      <td>I have had this tuner for about half a year an...</td>\n",
       "      <td>[5, 7]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4481</th>\n",
       "      <td>This tuner works fine for the flute and clarin...</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4482</th>\n",
       "      <td>I've been very disappointed with this tuner. W...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4488</th>\n",
       "      <td>There are better tuners out there. Far better....</td>\n",
       "      <td>[6, 11]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4562</th>\n",
       "      <td>This would have been a nice slide if I could g...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4615</th>\n",
       "      <td>Lets face it, in general string winders are pr...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4618</th>\n",
       "      <td>Ok its cheap. You knew that when you bought it...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4678</th>\n",
       "      <td>This strap is uncomfortable and too flimsy to ...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4694</th>\n",
       "      <td>Sorry Fender...this one is just a waste of mon...</td>\n",
       "      <td>[1, 3]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8555</th>\n",
       "      <td>Really wanted to like this one, because I love...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8553</th>\n",
       "      <td>A dull, inept version of a TubeScreamer. Just ...</td>\n",
       "      <td>[2, 17]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8520</th>\n",
       "      <td>This unit might be great if you have child han...</td>\n",
       "      <td>[0, 5]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8518</th>\n",
       "      <td>Works as advertised but the keys are stiff. Pa...</td>\n",
       "      <td>[2, 4]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4873</th>\n",
       "      <td>This pedal, in short, sucks.  There's no point...</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4910</th>\n",
       "      <td>It's a decent unit, but stopped working comple...</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4928</th>\n",
       "      <td>Behringer pedals are really cheaply made and t...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8493</th>\n",
       "      <td>My review(s) for this have changed a few times...</td>\n",
       "      <td>[5, 30]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4943</th>\n",
       "      <td>Bought this because of all the great reviews, ...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4970</th>\n",
       "      <td>Ok I understand it now - I use Abelton Live 8 ...</td>\n",
       "      <td>[2, 4]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5035</th>\n",
       "      <td>Not very bright. Not very flexible. Too big. C...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8408</th>\n",
       "      <td>...what is the sound in the background of the ...</td>\n",
       "      <td>[2, 4]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5206</th>\n",
       "      <td>They say 2-4 months, I've never come close to ...</td>\n",
       "      <td>[0, 2]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5239</th>\n",
       "      <td>I bought this pedal new, hoping to get an elec...</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5248</th>\n",
       "      <td>I bought this pedal as a companion to my Rolan...</td>\n",
       "      <td>[2, 4]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8594</th>\n",
       "      <td>I honestly don't see the purpose.  It doesn't ...</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4357</th>\n",
       "      <td>The sheets seem to work fine to polish the fre...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4253</th>\n",
       "      <td>I ordered one of these because I like my other...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4241</th>\n",
       "      <td>The only instrument this works well on is my Y...</td>\n",
       "      <td>[2, 3]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4167</th>\n",
       "      <td>Dampit was recommended to me by a guitar instr...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4107</th>\n",
       "      <td>I have other harmonica's but thought I'd like ...</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3994</th>\n",
       "      <td>This is my first guitar belt, it is not a good...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3951</th>\n",
       "      <td>I purchased this as my first guitar slide. I l...</td>\n",
       "      <td>[0, 10]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3941</th>\n",
       "      <td>The only reason I'm not giving this one star i...</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4255</th>\n",
       "      <td>It is inexpensive but is difficult to use  any...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4929</th>\n",
       "      <td>if you go very high with the boost in frequenc...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5052</th>\n",
       "      <td>soi f you want to turn Distor t off,u cannot.d...</td>\n",
       "      <td>[1, 12]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5068</th>\n",
       "      <td>While the product came as described, the build...</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5678</th>\n",
       "      <td>These cans were decent, back when they were ju...</td>\n",
       "      <td>[9, 14]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5625</th>\n",
       "      <td>To heavy....it doesn't stay where you need it....</td>\n",
       "      <td>[2, 4]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5621</th>\n",
       "      <td>My hopes for this pad was that it would be sof...</td>\n",
       "      <td>[10, 15]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5595</th>\n",
       "      <td>I am a tone freak. I bought this pedal a while...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5587</th>\n",
       "      <td>I bought this unit for a friend, and I could c...</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5576</th>\n",
       "      <td>In my experience these cables were not great. ...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5479</th>\n",
       "      <td>I heard great things about the S6 and so, bein...</td>\n",
       "      <td>[3, 5]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5441</th>\n",
       "      <td>It's a good ideal but the big problem I have i...</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5405</th>\n",
       "      <td>The Good:This is a good tool to practice guita...</td>\n",
       "      <td>[3, 5]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5345</th>\n",
       "      <td>In fact, I don't think this Hosa GTR215R cord ...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5307</th>\n",
       "      <td>..it works.But expect some flaws.First,finding...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5291</th>\n",
       "      <td>Disapointed. The sensors are not providing a c...</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5271</th>\n",
       "      <td>When I purchased this I'd seriously hoped that...</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5244</th>\n",
       "      <td>SummaryAcoustic sounds &amp;#34;ok&amp;#34;, but noisy...</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5150</th>\n",
       "      <td>Pros:-Price point-Good, clean audio quality wh...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5101</th>\n",
       "      <td>Strings rust very easily, yield fairly poor to...</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5086</th>\n",
       "      <td>I picked one of these up when they were being ...</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5758</th>\n",
       "      <td>I have finally learned my lesson.I have purcha...</td>\n",
       "      <td>[3, 4]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10247</th>\n",
       "      <td>I was looking forward to trying these, as I've...</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>467 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              reviewText   helpful  overall  \\\n",
       "5906   i got this despite the warnings about it being...    [2, 2]      1.0   \n",
       "4405   This thing is useless. Good idea, but way too ...    [0, 0]      1.0   \n",
       "4415   I've had it for about a month now and it hasn'...    [0, 0]      1.0   \n",
       "4437   It's really not a 200w system.  The booklet ev...    [0, 0]      1.0   \n",
       "4475   I have had this tuner for about half a year an...    [5, 7]      1.0   \n",
       "4481   This tuner works fine for the flute and clarin...    [1, 1]      1.0   \n",
       "4482   I've been very disappointed with this tuner. W...    [0, 0]      1.0   \n",
       "4488   There are better tuners out there. Far better....   [6, 11]      1.0   \n",
       "4562   This would have been a nice slide if I could g...    [0, 0]      1.0   \n",
       "4615   Lets face it, in general string winders are pr...    [0, 0]      1.0   \n",
       "4618   Ok its cheap. You knew that when you bought it...    [0, 0]      1.0   \n",
       "4678   This strap is uncomfortable and too flimsy to ...    [0, 0]      1.0   \n",
       "4694   Sorry Fender...this one is just a waste of mon...    [1, 3]      1.0   \n",
       "8555   Really wanted to like this one, because I love...    [0, 0]      1.0   \n",
       "8553   A dull, inept version of a TubeScreamer. Just ...   [2, 17]      1.0   \n",
       "8520   This unit might be great if you have child han...    [0, 5]      1.0   \n",
       "8518   Works as advertised but the keys are stiff. Pa...    [2, 4]      1.0   \n",
       "4873   This pedal, in short, sucks.  There's no point...    [2, 2]      1.0   \n",
       "4910   It's a decent unit, but stopped working comple...    [1, 1]      1.0   \n",
       "4928   Behringer pedals are really cheaply made and t...    [0, 0]      1.0   \n",
       "8493   My review(s) for this have changed a few times...   [5, 30]      1.0   \n",
       "4943   Bought this because of all the great reviews, ...    [0, 0]      1.0   \n",
       "4970   Ok I understand it now - I use Abelton Live 8 ...    [2, 4]      1.0   \n",
       "5035   Not very bright. Not very flexible. Too big. C...    [0, 0]      1.0   \n",
       "8408   ...what is the sound in the background of the ...    [2, 4]      1.0   \n",
       "5206   They say 2-4 months, I've never come close to ...    [0, 2]      1.0   \n",
       "5239   I bought this pedal new, hoping to get an elec...    [3, 3]      1.0   \n",
       "5248   I bought this pedal as a companion to my Rolan...    [2, 4]      1.0   \n",
       "8594   I honestly don't see the purpose.  It doesn't ...    [1, 1]      1.0   \n",
       "4357   The sheets seem to work fine to polish the fre...    [0, 0]      1.0   \n",
       "...                                                  ...       ...      ...   \n",
       "4253   I ordered one of these because I like my other...    [0, 0]      2.0   \n",
       "4241   The only instrument this works well on is my Y...    [2, 3]      2.0   \n",
       "4167   Dampit was recommended to me by a guitar instr...    [0, 0]      2.0   \n",
       "4107   I have other harmonica's but thought I'd like ...    [2, 2]      2.0   \n",
       "3994   This is my first guitar belt, it is not a good...    [0, 0]      2.0   \n",
       "3951   I purchased this as my first guitar slide. I l...   [0, 10]      2.0   \n",
       "3941   The only reason I'm not giving this one star i...    [0, 1]      2.0   \n",
       "4255   It is inexpensive but is difficult to use  any...    [0, 0]      2.0   \n",
       "4929   if you go very high with the boost in frequenc...    [0, 0]      2.0   \n",
       "5052   soi f you want to turn Distor t off,u cannot.d...   [1, 12]      2.0   \n",
       "5068   While the product came as described, the build...    [1, 1]      2.0   \n",
       "5678   These cans were decent, back when they were ju...   [9, 14]      2.0   \n",
       "5625   To heavy....it doesn't stay where you need it....    [2, 4]      2.0   \n",
       "5621   My hopes for this pad was that it would be sof...  [10, 15]      2.0   \n",
       "5595   I am a tone freak. I bought this pedal a while...    [0, 0]      2.0   \n",
       "5587   I bought this unit for a friend, and I could c...    [0, 1]      2.0   \n",
       "5576   In my experience these cables were not great. ...    [0, 0]      2.0   \n",
       "5479   I heard great things about the S6 and so, bein...    [3, 5]      2.0   \n",
       "5441   It's a good ideal but the big problem I have i...    [0, 1]      2.0   \n",
       "5405   The Good:This is a good tool to practice guita...    [3, 5]      2.0   \n",
       "5345   In fact, I don't think this Hosa GTR215R cord ...    [0, 0]      2.0   \n",
       "5307   ..it works.But expect some flaws.First,finding...    [0, 0]      2.0   \n",
       "5291   Disapointed. The sensors are not providing a c...    [0, 1]      2.0   \n",
       "5271   When I purchased this I'd seriously hoped that...    [0, 1]      2.0   \n",
       "5244   SummaryAcoustic sounds &#34;ok&#34;, but noisy...    [1, 1]      2.0   \n",
       "5150   Pros:-Price point-Good, clean audio quality wh...    [0, 0]      2.0   \n",
       "5101   Strings rust very easily, yield fairly poor to...    [0, 1]      2.0   \n",
       "5086   I picked one of these up when they were being ...    [1, 1]      2.0   \n",
       "5758   I have finally learned my lesson.I have purcha...    [3, 4]      2.0   \n",
       "10247  I was looking forward to trying these, as I've...    [2, 2]      2.0   \n",
       "\n",
       "       rating  \n",
       "5906        0  \n",
       "4405        0  \n",
       "4415        0  \n",
       "4437        0  \n",
       "4475        0  \n",
       "4481        0  \n",
       "4482        0  \n",
       "4488        0  \n",
       "4562        0  \n",
       "4615        0  \n",
       "4618        0  \n",
       "4678        0  \n",
       "4694        0  \n",
       "8555        0  \n",
       "8553        0  \n",
       "8520        0  \n",
       "8518        0  \n",
       "4873        0  \n",
       "4910        0  \n",
       "4928        0  \n",
       "8493        0  \n",
       "4943        0  \n",
       "4970        0  \n",
       "5035        0  \n",
       "8408        0  \n",
       "5206        0  \n",
       "5239        0  \n",
       "5248        0  \n",
       "8594        0  \n",
       "4357        0  \n",
       "...       ...  \n",
       "4253        0  \n",
       "4241        0  \n",
       "4167        0  \n",
       "4107        0  \n",
       "3994        0  \n",
       "3951        0  \n",
       "3941        0  \n",
       "4255        0  \n",
       "4929        0  \n",
       "5052        0  \n",
       "5068        0  \n",
       "5678        0  \n",
       "5625        0  \n",
       "5621        0  \n",
       "5595        0  \n",
       "5587        0  \n",
       "5576        0  \n",
       "5479        0  \n",
       "5441        0  \n",
       "5405        0  \n",
       "5345        0  \n",
       "5307        0  \n",
       "5291        0  \n",
       "5271        0  \n",
       "5244        0  \n",
       "5150        0  \n",
       "5101        0  \n",
       "5086        0  \n",
       "5758        0  \n",
       "10247       0  \n",
       "\n",
       "[467 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduceData['rating'] = reduceData['overall'].apply(rating)\n",
    "unfavorableReviews = list(reduceData.loc[ reduceData['rating'] == 0, \n",
    "                                         ['reviewText', 'helpful', 'overall', 'rating']].sort_values(by='overall').index)\n",
    "#unfavorableReviews\n",
    "reduceData.loc[ reduceData['rating'] == 0, ['reviewText', 'helpful', 'overall', 'rating']].sort_values(by='overall')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewTextProcessing = pd.DataFrame(reduceData.reviewText.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewTextProcessing['rating'] = reduceData['rating']\n",
    "reviewTextProcessing['overall'] = reduceData['overall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10261, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "productsReviewData.dtypes\n",
    "len(productsReviewData)\n",
    "# reviewText, rating, overall\n",
    "reviewTextProcessing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reviewTextProcessing.loc[reviewTextProcessing['rating']==0, ['rating', 'overall', 'Processed', 'SentimentModel']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([\"ain't\", \"aren't\", \"can't\", \"can't've\", \"'cause\", \"could've\", \"couldn't\", \"couldn't've\", \"didn't\", \"doesn't\", \"don't\", \"hadn't\", \"hadn't've\", \"hasn't\", \"haven't\", \"he'd\", \"he'd've\", \"he'll\", \"he'll've\", \"he's\", \"how'd\", \"how'd'y\", \"how'll\", \"how's\", \"I'd\", \"I'd've\", \"I'll\", \"I'll've\", \"I'm\", \"I've\", \"isn't\", \"it'd\", \"it'd've\", \"it'll\", \"it'll've\", \"it's\", \"let's\", \"ma'am\", \"mayn't\", \"might've\", \"mightn't\", \"mightn't've\", \"must've\", \"mustn't\", \"mustn't've\", \"needn't\", \"needn't've\", \"o'clock\", \"oughtn't\", \"oughtn't've\", \"shan't\", \"sha'n't\", \"shan't've\", \"she'd\", \"she'd've\", \"she'll\", \"she'll've\", \"she's\", 's###', \"should've\", \"shouldn't\", \"shouldn't've\", \"so've\", \"so's\", \"that'd\", \"that'd've\", \"that's\", \"there'd\", \"there'd've\", \"there's\", \"they'd\", \"they'd've\", \"they'll\", \"they'll've\", \"they're\", \"they've\", \"to've\", \"wasn't\", \"we'd\", \"we'd've\", \"we'll\", \"we'll've\", \"we're\", \"we've\", \"weren't\", \"what'll\", \"what'll've\", \"what're\", \"what's\", \"what've\", \"when's\", \"when've\", \"where'd\", \"where's\", \"where've\", \"who'll\", \"who'll've\", \"who's\", \"who've\", \"why's\", \"why've\", \"will've\", \"won't\", \"won't've\", \"would've\", \"wouldn't\", \"wouldn't've\", \"y'all\", \"y'all'd\", \"y'all'd've\", \"y'all're\", \"y'all've\", \"you'd\", \"you'd've\", \"you'll\", \"you'll've\", \"you're\", \"you've\"])\n"
     ]
    }
   ],
   "source": [
    "#https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python\n",
    "import Contractions_Words as contractions\n",
    "import importlib\n",
    "importlib.reload(contractions)\n",
    "\n",
    "contractions_dict = contractions.contractions_dict\n",
    "\n",
    "print(contractions_dict.keys())\n",
    "#print(contractions_dict[\"s***\"])\n",
    "\n",
    "pattern = '%s' % '|'.join(contractions_dict.keys())\n",
    "#pattern = r\"%s\" % pattern\n",
    "#print(pattern)\n",
    "contractions_re = re.compile(pattern)\n",
    "def expand_contractions(s, contractions_dict=contractions_dict):\n",
    "    #edit for special case like s*** etc\n",
    "    s = re.sub(\"\\*\", \"#\", s)\n",
    "    def replace(match):\n",
    "        #print(type(match), match)\n",
    "        return contractions_dict[match.group(0)]\n",
    "    return contractions_re.sub(replace, s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s###\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'shit'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample1 = \"s***\"\n",
    "print(re.sub(\"\\*\", \"#\", sample1))\n",
    "\n",
    "sample = \"I don\\'t know what to say nay. I haven\\'t. s###\"\n",
    "expand_contractions(sample)\n",
    "expand_contractions(sample1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import string\n",
    "\n",
    "# return both wholeText, paragraph Text\n",
    "def singleReviewCleanUp(sample):\n",
    "    #print(sample)\n",
    "    #sample = sample.decode(\"utf-8\")\n",
    "    sample = expand_contractions(sample)\n",
    "    sample = sample.lower()\n",
    "    \n",
    "    #for word in sample:\n",
    "    #    print(lemmatizer.lemmatize(word, wordnet.VERB))\n",
    "    \n",
    "    review = sent_tokenize(sample)\n",
    "    #print(review)\n",
    "    for count, eachSent in enumerate(review):\n",
    "        #remove numbers\n",
    "        eachSent = re.sub(\"r'\\d+/\\d+|\\d+|\\$\\d+.\\d+\", \" \", eachSent)\n",
    "        #remove string\n",
    "        eachSent = re.sub('[%s]' % re.escape(string.punctuation), ' ', eachSent)\n",
    "        #word tokens\n",
    "        #print([lemmatizer.lemmatize(text, wordnet.VERB) for text in eachSent.split()])\n",
    "        eachSent = word_tokenize(eachSent)\n",
    "        review[count] = eachSent\n",
    "        # lemmatize and remove stopWords\n",
    "        #eachSent = [word for word in eachSent if not word in stopWords]\n",
    "        #eachSent = [lemmatizer.lemmatize(word, wordnet.VERB) for word in eachSent]\n",
    "        #eachSent = [lemmatizer.lemmatize(word, wordnet.VERB) for word in eachSent if not word in stopWords]\n",
    "        review[count] = \" \".join(eachSent)\n",
    "    wholeText = [\" \".join(review) ]\n",
    "    paragraphText = review\n",
    "    #return wholeText\n",
    "    #return paragraphText\n",
    "    return paragraphText, wholeText\n",
    "\n",
    "#paragraphText, wholeText = singleReviewCleanUp(sample)\n",
    "#wholeText, paragraphText\n",
    "#paragraphText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Give me back text in a paragraph sentence forms. They do have more values than a clobbed of text based on Polarity Check.\n",
    "cleanUpTextParagraph = lambda text: singleReviewCleanUp(text)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 12.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reviewTextProcessing['Processed'] = reviewTextProcessing.reviewText.apply(cleanUpTextParagraph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample = \" I don't know what to do. I need to test through tough. Do you have any suggestions\"\n",
    "#result = cleanUpTextParagraph(sample)\n",
    "#result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# need to do a data check first\n",
    "def getPolaritySubjectivity(data):\n",
    "    #print(data)\n",
    "    paragraphText = data\n",
    "    sumPolarity = []\n",
    "    sumSubjectivity = []\n",
    "    for each in paragraphText:\n",
    "        sumPolarity.append(TextBlob(each).sentiment.polarity)\n",
    "        sumSubjectivity.append(TextBlob(each).sentiment.subjectivity)\n",
    "    #print(\"sumPol\", sumPolarity)\n",
    "    return sumPolarity, sumSubjectivity\n",
    "    #return sum(sumPolarity), sum(sumSubjectivity)\n",
    "\n",
    "    #print(each, TextBlob(each).sentiment.polarity, TextBlob(each).sentiment.subjectivity)\n",
    "#(sample2, TextBlob(sample2).sentiment.polarity, TextBlob(sample2).sentiment.subjectivity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return the sume of polarity in a paragraph sentence when give a text in a list form of sentence\n",
    "\n",
    "getPolarityFromText = lambda text: getPolaritySubjectivity(text)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each in sampleText:\n",
    "#    sample = cleanUpTextParagraph(each)\n",
    "#    print(sample, getPolarityFromText(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentiment = lambda text: TextBlob(text).sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjustSentimentModel = lambda x: [sum(x), 0.0] if sum(x) < 0 else [sum(x), 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 25.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reviewTextProcessing['Sentiment']= reviewTextProcessing.Processed.apply(getPolarityFromText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reviewTextProcessing['SentimentModel']= reviewTextProcessing.Sentiment.apply(adjustSentimentModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reviewTextProcessing.loc[unfavorableReviews, ['Processed', 'Sentiment', 'SentimentModel']]\n",
    "#reviewTextProcessing.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewTextProcessing['CleanedJoin'] = reviewTextProcessing['Processed'].apply(', '.join)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['reviewText', 'rating', 'overall', 'Processed', 'Sentiment',\n",
       "       'SentimentModel', 'CleanedJoin'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewTextProcessing.shape\n",
    "reviewTextProcessing.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from gensim import corpora\n",
    "#dictionary = corpora.Dictionary(T)\n",
    "#print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    not much to write about here but it does exact...\n",
       "1    the product does exactly as it should and is q...\n",
       "2    the primary job of this device is to block the...\n",
       "3    nice windscreen protects my mxl mic and preven...\n",
       "4    this pop filter is great, it looks and perform...\n",
       "Name: CleanedJoin, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewTextProcessing['CleanedJoin'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10261"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import itertools\n",
    "\n",
    "largeText = reviewTextProcessing.CleanedJoin.to_list()\n",
    "#largeText = reviewTextProcessing.reviewText.to_list() # Not too good accuracy around 116 missed with %86.94\n",
    "\n",
    "len(largeText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = reviewTextProcessing['SentimentModel'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=num_words)\n",
    "tokenizer.fit_on_texts(largeText)\n",
    "#tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "size = int(len(largeText)*.75)\n",
    "x_train_text = largeText[:size]\n",
    "x_test_text = largeText[size:]\n",
    "\n",
    "y_train =  reviewTextProcessing['rating'][:size]\n",
    "y_test = reviewTextProcessing['rating'][size:]\n",
    "x_train_tokens = tokenizer.texts_to_sequences(x_train_text)\n",
    "x_test_tokens = tokenizer.texts_to_sequences(x_test_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7695, 2566, 7695, 2566)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train), len(y_test), len(x_train_text), len(x_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train_tokens[1], x_train_text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_train_text[1]\n",
    "np.array(x_train_tokens[1])\n",
    "num_tokens = [len(tokens) for tokens in x_train_tokens + x_test_tokens]\n",
    "num_tokens = np.array(num_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92.37939771952051, 2047)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(num_tokens), np.max(num_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114.14850119038401"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "320"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "max_tokens = int(max_tokens) \n",
    "max_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9582886658220446"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(num_tokens < max_tokens) / len(num_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Input',\n",
       " 'InputLayer',\n",
       " 'K',\n",
       " 'Model',\n",
       " 'Sequential',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " '_clone_functional_model',\n",
       " '_clone_sequential_model',\n",
       " 'absolute_import',\n",
       " 'clone_model',\n",
       " 'division',\n",
       " 'h5py',\n",
       " 'has_arg',\n",
       " 'load_model',\n",
       " 'model_from_config',\n",
       " 'model_from_json',\n",
       " 'model_from_yaml',\n",
       " 'print_function',\n",
       " 'save_model',\n",
       " 'to_list']"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#from keras.models import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.2'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "top_num_of_words = 10000\n",
    "vect = TfidfVectorizer(max_features=top_num_of_words, \n",
    "                       stop_words = 'english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect.fit(text)\n",
    "text_vector = vect.transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7695"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = len(x_train_pad)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 82 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(x_train_pad, y_train)\n",
    "#model.fit(x_train_pad, y_train,validation_split=0.05, epochs=3, batch_size=74)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1e+03 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#result = model.evaluate(x_test_pad, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-3ca54eb19f2d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy: {0:.2%}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {0:.2%}\".format(result[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = model.predict(x_test_pad[0:1000])\n",
    "len(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.62800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.48358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  1000.00000\n",
       "mean      0.62800\n",
       "std       0.48358\n",
       "min       0.00000\n",
       "25%       0.00000\n",
       "50%       1.00000\n",
       "75%       1.00000\n",
       "max       1.00000"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_pred).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = y_pred.T[0]\n",
    "#list(np.where(y_pred.T[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No need with cls_pred as it has already been sorted.\n",
    "cls_pred = np.array([1.0 if p > 0 else 0.1 for p in y_pred])\n",
    "len(cls_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_true = np.array(y_test[0:1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3,   5,  20,  23,  26,  36,  37,  40,  41,  42,  43,  54,  55,\n",
       "        57,  58,  60,  61,  65,  67,  70,  72,  73,  75,  76,  79,  83,\n",
       "        85,  86,  87,  88,  89,  90,  91,  92,  93,  97, 100, 101, 106,\n",
       "       107, 116, 124, 129, 130, 133, 134, 138, 143, 151, 153, 154, 155,\n",
       "       156, 160, 165, 166, 168, 171, 175, 185, 190, 195, 196, 200, 201,\n",
       "       205, 206, 207, 211, 214, 216, 217, 218, 219, 229, 232, 234, 235,\n",
       "       237, 241, 243, 244, 247, 248, 249, 250, 257, 260, 266, 268, 271,\n",
       "       272, 276, 280, 283, 287, 288, 290, 292, 294, 295, 296, 297, 299,\n",
       "       301, 302, 306, 308, 309, 311, 312, 313, 314, 315, 317, 321, 323,\n",
       "       326, 328, 333, 334, 335, 341, 342, 345, 348, 351, 352, 353, 354,\n",
       "       359, 360, 361, 363, 367, 371, 372, 375, 376, 381, 382, 383, 387,\n",
       "       388, 392, 394, 395, 396, 400, 401, 402, 407, 408, 411, 414, 415,\n",
       "       416, 418, 426, 431, 432, 435, 441, 443, 444, 446, 447, 449, 451,\n",
       "       452, 454, 459, 463, 464, 466, 468, 475, 477, 484, 488, 490, 491,\n",
       "       492, 493, 496, 497, 499, 501, 502, 508, 509, 510, 511, 517, 520,\n",
       "       521, 522, 523, 524, 528, 530, 536, 540, 541, 542, 548, 552, 553,\n",
       "       559, 560, 562, 563, 566, 568, 569, 572, 578, 580, 583, 588, 596,\n",
       "       599, 600, 602, 605, 607, 611, 615, 616, 619, 622, 624, 625, 628,\n",
       "       631, 634, 637, 638, 641, 646, 648, 649, 653, 655, 657, 658, 660,\n",
       "       662, 665, 671, 673, 676, 678, 682, 684, 687, 689, 690, 692, 694,\n",
       "       697, 698, 703, 704, 705, 707, 708, 713, 715, 716, 717, 718, 720,\n",
       "       722, 728, 733, 735, 736, 738, 745, 746, 752, 753, 754, 756, 757,\n",
       "       758, 759, 760, 763, 764, 766, 771, 772, 774, 778, 781, 784, 787,\n",
       "       790, 798, 804, 806, 813, 817, 818, 819, 820, 821, 822, 823, 824,\n",
       "       825, 826, 827, 828, 833, 834, 837, 840, 842, 843, 845, 846, 848,\n",
       "       851, 853, 855, 856, 858, 859, 860, 863, 865, 867, 870, 874, 876,\n",
       "       884, 886, 887, 892, 893, 895, 896, 898, 899, 900, 901, 902, 904,\n",
       "       906, 907, 908, 909, 910, 916, 919, 922, 924, 925, 928, 932, 934,\n",
       "       936, 939, 942, 944, 946, 947, 948, 949, 950, 951, 953, 954, 955,\n",
       "       957, 958, 960, 964, 965, 966, 968, 970, 974, 976, 986, 990, 992,\n",
       "       994, 996, 997, 998], dtype=int64)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect = np.where(cls_pred != cls_true)\n",
    "incorrect = incorrect[0]\n",
    "incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   4,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
       "        15,  16,  17,  18,  19,  21,  22,  24,  25,  27,  28,  29,  30,\n",
       "        31,  32,  33,  34,  35,  38,  39,  44,  45,  46,  47,  48,  49,\n",
       "        50,  51,  52,  53,  56,  59,  62,  63,  64,  66,  68,  69,  71,\n",
       "        74,  77,  78,  80,  81,  82,  84,  94,  95,  96,  98,  99, 102,\n",
       "       103, 104, 105, 108, 109, 110, 111, 112, 113, 114, 115, 117, 118,\n",
       "       119, 120, 121, 122, 123, 125, 126, 127, 128, 131, 132, 135, 136,\n",
       "       137, 139, 140, 141, 142, 144, 145, 146, 147, 148, 149, 150, 152,\n",
       "       157, 158, 159, 161, 162, 163, 164, 167, 169, 170, 172, 173, 174,\n",
       "       176, 177, 178, 179, 180, 181, 182, 183, 184, 186, 187, 188, 189,\n",
       "       191, 192, 193, 194, 197, 198, 199, 202, 203, 204, 208, 209, 210,\n",
       "       212, 213, 215, 220, 221, 222, 223, 224, 225, 226, 227, 228, 230,\n",
       "       231, 233, 236, 238, 239, 240, 242, 245, 246, 251, 252, 253, 254,\n",
       "       255, 256, 258, 259, 261, 262, 263, 264, 265, 267, 269, 270, 273,\n",
       "       274, 275, 277, 278, 279, 281, 282, 284, 285, 286, 289, 291, 293,\n",
       "       298, 300, 303, 304, 305, 307, 310, 316, 318, 319, 320, 322, 324,\n",
       "       325, 327, 329, 330, 331, 332, 336, 337, 338, 339, 340, 343, 344,\n",
       "       346, 347, 349, 350, 355, 356, 357, 358, 362, 364, 365, 366, 368,\n",
       "       369, 370, 373, 374, 377, 378, 379, 380, 384, 385, 386, 389, 390,\n",
       "       391, 393, 397, 398, 399, 403, 404, 405, 406, 409, 410, 412, 413,\n",
       "       417, 419, 420, 421, 422, 423, 424, 425, 427, 428, 429, 430, 433,\n",
       "       434, 436, 437, 438, 439, 440, 442, 445, 448, 450, 453, 455, 456,\n",
       "       457, 458, 460, 461, 462, 465, 467, 469, 470, 471, 472, 473, 474,\n",
       "       476, 478, 479, 480, 481, 482, 483, 485, 486, 487, 489, 494, 495,\n",
       "       498, 500, 503, 504, 505, 506, 507, 512, 513, 514, 515, 516, 518,\n",
       "       519, 525, 526, 527, 529, 531, 532, 533, 534, 535, 537, 538, 539,\n",
       "       543, 544, 545, 546, 547, 549, 550, 551, 554, 555, 556, 557, 558,\n",
       "       561, 564, 565, 567, 570, 571, 573, 574, 575, 576, 577, 579, 581,\n",
       "       582, 584, 585, 586, 587, 589, 590, 591, 592, 593, 594, 595, 597,\n",
       "       598, 601, 603, 604, 606, 608, 609, 610, 612, 613, 614, 617, 618,\n",
       "       620, 621, 623, 626, 627, 629, 630, 632, 633, 635, 636, 639, 640,\n",
       "       642, 643, 644, 645, 647, 650, 651, 652, 654, 656, 659, 661, 663,\n",
       "       664, 666, 667, 668, 669, 670, 672, 674, 675, 677, 679, 680, 681,\n",
       "       683, 685, 686, 688, 691, 693, 695, 696, 699, 700, 701, 702, 706,\n",
       "       709, 710, 711, 712, 714, 719, 721, 723, 724, 725, 726, 727, 729,\n",
       "       730, 731, 732, 734, 737, 739, 740, 741, 742, 743, 744, 747, 748,\n",
       "       749, 750, 751, 755, 761, 762, 765, 767, 768, 769, 770, 773, 775,\n",
       "       776, 777, 779, 780, 782, 783, 785, 786, 788, 789, 791, 792, 793,\n",
       "       794, 795, 796, 797, 799, 800, 801, 802, 803, 805, 807, 808, 809,\n",
       "       810, 811, 812, 814, 815, 816, 829, 830, 831, 832, 835, 836, 838,\n",
       "       839, 841, 844, 847, 849, 850, 852, 854, 857, 861, 862, 864, 866,\n",
       "       868, 869, 871, 872, 873, 875, 877, 878, 879, 880, 881, 882, 883,\n",
       "       885, 888, 889, 890, 891, 894, 897, 903, 905, 911, 912, 913, 914,\n",
       "       915, 917, 918, 920, 921, 923, 926, 927, 929, 930, 931, 933, 935,\n",
       "       937, 938, 940, 941, 943, 945, 952, 956, 959, 961, 962, 963, 967,\n",
       "       969, 971, 972, 973, 975, 977, 978, 979, 980, 981, 982, 983, 984,\n",
       "       985, 987, 988, 989, 991, 993, 995, 999], dtype=int64)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = np.where(cls_pred == cls_true)\n",
    "correct = correct[0]\n",
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (374,) (626,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-141-c95a1e1d5016>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mincorrect\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[0mincorrect\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (374,) (626,) "
     ]
    }
   ],
   "source": [
    "len(incorrect), len(correct)\n",
    "(incorrect) (correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_location = np.where(cls_pred.T)[0] + index\n",
    "len(result_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 5)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "NBresult = reviewTextProcessing.loc[list(result_location),  ['reviewText', 'overall', 'rating', 'Sentiment' , 'SentimentModel']]\n",
    "#CNNresult.head(2)\n",
    "#CNNresult.shape\n",
    "#result_location\n",
    "#result_location\n",
    "NBresult.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBresult['NB_Sentiment'] =  list(y_pred.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumSentiment = lambda x: x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBresult.columns = ['TextBlobAnalysis' if x=='Sentiment' else x for x in NBresult.columns]\n",
    "NBresult.columns = ['TextBlob_Sentiment' if x=='SentimentModel' else x for x in NBresult.columns]\n",
    "NBresult['TextBlob_Sentiment'] = NBresult['TextBlob_Sentiment'].apply(sumSentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBresult.NB_Sentiment = NBresult.NB_Sentiment.astype(int)\n",
    "NBresult.TextBlob_Sentiment = NBresult.TextBlob_Sentiment.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBresult.loc[NBresult.overall >= 3.0 , :].to_csv(\"Rating3.0above_NB.csv\")\n",
    "NBresult.loc[NBresult.overall < 3.0 , :].to_csv(\"RatingBelow3.0_NB.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = NBresult.rating.to_list()\n",
    "NB_pred = NBresult.NB_Sentiment.to_list()\n",
    "textBlob_pred = NBresult.TextBlob_Sentiment.to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#textBlob_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 22, 352, 606)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_true, NB_pred).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 28, 57, 901)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_true, textBlob_pred).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 500\n",
    "\n",
    "#productsReviewData.cleanedText.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
