{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "\n",
    "mport gzip #for parsing gz files\n",
    "import pandas as pd\n",
    "import re \n",
    "import inflect #numeric/cardinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirPath = r\"C:\\Study\\Projects\\NLP\\data\"\n",
    "reviewPath = r\"reviews_Tools_and_Home_Improvement_5.json.gz\"\n",
    "#reviewPath = r\"reviews_Musical_Instruments_5.json.gz\"\n",
    "qaPath = r\"C:\\Study\\Projects\\NLP\\data\" \n",
    "path = dirPath + \"\\\\\" + reviewPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFile = gzip.open(path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need this function because large amount of data we are going to load up\n",
    "\n",
    "# http://jmcauley.ucsd.edu/data/amazon/index.html\n",
    "# eval function allows text to be parsed as python code\n",
    "# parse function is a generator with yield\n",
    "# yield when we want to iterate over a sequence, but don't want to store the entire sequence in memory\n",
    "def parse(dataFile):\n",
    "    for each in dataFile:\n",
    "        yield eval(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each review for a product in dataFile maps dict[nth] = review (nth)\n",
    "# enumerate can't be used on a generator\n",
    "count = 0\n",
    "productReviews = {}\n",
    "for eachReview in parse(dataFile):\n",
    "    productReviews[count] = eachReview\n",
    "    count = count + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134476"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(productReviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#productReviews[101718]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "productsReviewData = pd.DataFrame.from_dict(productReviews, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A4IL0CLL27Q33</td>\n",
       "      <td>104800001X</td>\n",
       "      <td>D. Brennan</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>I hate it when my shirt collars, not otherwise...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Perfect for collar stay management</td>\n",
       "      <td>1390953600</td>\n",
       "      <td>01 29, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3Q5W5E7TDVLJF</td>\n",
       "      <td>104800001X</td>\n",
       "      <td>funnyc130</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>These little magnets are really powerful for t...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Neat</td>\n",
       "      <td>1369958400</td>\n",
       "      <td>05 31, 2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin reviewerName helpful  \\\n",
       "0   A4IL0CLL27Q33  104800001X   D. Brennan  [0, 1]   \n",
       "1  A3Q5W5E7TDVLJF  104800001X    funnyc130  [0, 0]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  I hate it when my shirt collars, not otherwise...      5.0   \n",
       "1  These little magnets are really powerful for t...      5.0   \n",
       "\n",
       "                              summary  unixReviewTime   reviewTime  \n",
       "0  Perfect for collar stay management      1390953600  01 29, 2014  \n",
       "1                                Neat      1369958400  05 31, 2013  "
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "productsReviewData.shape\n",
    "productsReviewData.columns\n",
    "productsReviewData.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduceData = productsReviewData.loc[:, ['asin', 'reviewerName', 'reviewText', 'helpful', 'overall']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduceData = reduceData.loc[reduceData['overall']!=3.0, ['asin', 'reviewerName', 'reviewText', 'helpful', 'overall']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = lambda x: 1 if x > 2.0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>helpful</th>\n",
       "      <th>overall</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>134322</th>\n",
       "      <td>Amazing that they designed this thing without ...</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55236</th>\n",
       "      <td>I was ready to pick up one of these at a woodw...</td>\n",
       "      <td>[30, 38]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55234</th>\n",
       "      <td>I bought this set from amazon but is not like ...</td>\n",
       "      <td>[8, 15]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105852</th>\n",
       "      <td>Horrible.Not one blade runs true.  Some are as...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55216</th>\n",
       "      <td>This product is almost a joke.  The case is to...</td>\n",
       "      <td>[4, 9]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reviewText   helpful  overall  \\\n",
       "134322  Amazing that they designed this thing without ...    [2, 2]      1.0   \n",
       "55236   I was ready to pick up one of these at a woodw...  [30, 38]      1.0   \n",
       "55234   I bought this set from amazon but is not like ...   [8, 15]      1.0   \n",
       "105852  Horrible.Not one blade runs true.  Some are as...    [0, 0]      1.0   \n",
       "55216   This product is almost a joke.  The case is to...    [4, 9]      1.0   \n",
       "\n",
       "        rating  \n",
       "134322       0  \n",
       "55236        0  \n",
       "55234        0  \n",
       "105852       0  \n",
       "55216        0  "
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduceData['rating'] = reduceData['overall'].apply(rating)\n",
    "unfavorableReviews = list(reduceData.loc[ reduceData['rating'] == 0, \n",
    "                                         ['reviewText', 'helpful', 'overall', 'rating']].sort_values(by='overall').index)\n",
    "#unfavorableReviews\n",
    "reduceData.loc[ reduceData['rating'] == 0, ['reviewText', 'helpful', 'overall', 'rating']].sort_values(by='overall').head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewTextProcessing = pd.DataFrame(reduceData.reviewText.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewTextProcessing['rating'] = reduceData['rating']\n",
    "reviewTextProcessing['overall'] = reduceData['overall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123707, 3)"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "productsReviewData.dtypes\n",
    "len(productsReviewData)\n",
    "# reviewText, rating, overall\n",
    "reviewTextProcessing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reviewTextProcessing.loc[reviewTextProcessing['rating']==0, ['rating', 'overall', 'Processed', 'SentimentModel']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python\n",
    "import Contractions_Words as contractions\n",
    "import importlib\n",
    "importlib.reload(contractions)\n",
    "\n",
    "contractions_dict = contractions.contractions_dict\n",
    "\n",
    "#print(contractions_dict.keys())\n",
    "#print(contractions_dict[\"s***\"])\n",
    "\n",
    "pattern = '%s' % '|'.join(contractions_dict.keys())\n",
    "#pattern = r\"%s\" % pattern\n",
    "#print(pattern)\n",
    "contractions_re = re.compile(pattern)\n",
    "def expand_contractions(s, contractions_dict=contractions_dict):\n",
    "    #edit for special case like s*** etc\n",
    "    s = re.sub(\"\\*\", \"#\", s)\n",
    "    def replace(match):\n",
    "        #print(type(match), match)\n",
    "        return contractions_dict[match.group(0)]\n",
    "    return contractions_re.sub(replace, s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s###\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'shit'"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample1 = \"s***\"\n",
    "print(re.sub(\"\\*\", \"#\", sample1))\n",
    "\n",
    "sample = \"I don\\'t know what to say nay. I haven\\'t. s###\"\n",
    "expand_contractions(sample)\n",
    "expand_contractions(sample1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import string\n",
    "\n",
    "# return both wholeText, paragraph Text\n",
    "def singleReviewCleanUp(sample):\n",
    "    #print(sample)\n",
    "    #sample = sample.decode(\"utf-8\")\n",
    "    sample = expand_contractions(sample)\n",
    "    sample = sample.lower()\n",
    "    \n",
    "    #for word in sample:\n",
    "    #    print(lemmatizer.lemmatize(word, wordnet.VERB))\n",
    "    \n",
    "    review = sent_tokenize(sample)\n",
    "    #print(review)\n",
    "    for count, eachSent in enumerate(review):\n",
    "        #remove numbers\n",
    "       eachSent = re.sub(\"r'\\d+/\\d+|\\d+|\\$\\d+.\\d+\", \" \", eachSent)\n",
    "        #remove string\n",
    "        eachSent = re.sub('[%s]' % re.escape(string.punctuation), ' ', eachSent)\n",
    "        #word tokens\n",
    "        #print([lemmatizer.lemmatize(text, wordnet.VERB) for text in eachSent.split()])\n",
    "        eachSent = word_tokenize(eachSent)\n",
    "        review[count] = eachSent\n",
    "        # lemmatize and remove stopWords\n",
    "        #eachSent = [word for word in eachSent if not word in stopWords]\n",
    "        #eachSent = [lemmatizer.lemmatize(word, wordnet.VERB) for word in eachSent]\n",
    "        #eachSent = [lemmatizer.lemmatize(word, wordnet.VERB) for word in eachSent if not word in stopWords]\n",
    "        review[count] = \" \".join(eachSent)\n",
    "    wholeText = [\" \".join(review) ]\n",
    "    paragraphText = review\n",
    "    #return wholeText\n",
    "    #return paragraphText\n",
    "    return paragraphText, wholeText\n",
    "\n",
    "#paragraphText, wholeText = singleReviewCleanUp(sample)\n",
    "#wholeText, paragraphText\n",
    "#paragraphText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Give me back text in a paragraph sentence forms. They do have more values than a clobbed of text based on Polarity Check.\n",
    "cleanUpTextParagraph = lambda text: singleReviewCleanUp(text)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reviewTextProcessing['Processed'] = reviewTextProcessing.reviewText.apply(cleanUpTextParagraph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample = \" I don't know what to do. I need to test through tough. Do you have any suggestions\"\n",
    "#result = cleanUpTextParagraph(sample)\n",
    "#result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# need to do a data check first\n",
    "def getPolaritySubjectivity(data):\n",
    "    #print(data)\n",
    "    paragraphText = data\n",
    "    sumPolarity = []\n",
    "    sumSubjectivity = []\n",
    "    for each in paragraphText:\n",
    "        sumPolarity.append(TextBlob(each).sentiment.polarity)\n",
    "        sumSubjectivity.append(TextBlob(each).sentiment.subjectivity)\n",
    "    #print(\"sumPol\", sumPolarity)\n",
    "    return sumPolarity, sumSubjectivity\n",
    "    #return sum(sumPolarity), sum(sumSubjectivity)\n",
    "\n",
    "    #print(each, TextBlob(each).sentiment.polarity, TextBlob(each).sentiment.subjectivity)\n",
    "#(sample2, TextBlob(sample2).sentiment.polarity, TextBlob(sample2).sentiment.subjectivity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return the sume of polarity in a paragraph sentence when give a text in a list form of sentence\n",
    "\n",
    "getPolarityFromText = lambda text: getPolaritySubjectivity(text)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each in sampleText:\n",
    "#    sample = cleanUpTextParagraph(each)\n",
    "#    print(sample, getPolarityFromText(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentiment = lambda text: TextBlob(text).sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjustSentimentModel = lambda x: [sum(x), 0.0] if sum(x) < 0 else [sum(x), 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reviewTextProcessing['Sentiment']= reviewTextProcessing.Processed.apply(getPolarityFromText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 400 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reviewTextProcessing['SentimentModel']= reviewTextProcessing.Sentiment.apply(adjustSentimentModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reviewTextProcessing.loc[unfavorableReviews, ['Processed', 'Sentiment', 'SentimentModel']]\n",
    "#reviewTextProcessing.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewTextProcessing['CleanedJoin'] = reviewTextProcessing['Processed'].apply(', '.join)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['reviewText', 'rating', 'overall', 'Processed', 'CleanedJoin'], dtype='object')"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewTextProcessing.shape\n",
    "reviewTextProcessing.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from gensim import corpora\n",
    "#dictionary = corpora.Dictionary(T)\n",
    "#print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    i hate it when my shirt collars not otherwise ...\n",
       "1    these little magnets are really powerful for t...\n",
       "2    i wanted something this small to mount on the ...\n",
       "3    i use these to magnetize my warhammer k miniat...\n",
       "4    they are soo freaking annoying, why, you spend...\n",
       "Name: CleanedJoin, dtype: object"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewTextProcessing['CleanedJoin'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewTextProcessing.sort_values(by='rating', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>rating</th>\n",
       "      <th>overall</th>\n",
       "      <th>Processed</th>\n",
       "      <th>CleanedJoin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99410</th>\n",
       "      <td>Bought one and loved it! Ordered another two.O...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[bought one and loved it, ordered another two ...</td>\n",
       "      <td>bought one and loved it, ordered another two o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110570</th>\n",
       "      <td>Not made in the usa.. I wouldn't dare use this...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[not made in the usa i would not dare use this...</td>\n",
       "      <td>not made in the usa i would not dare use this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55485</th>\n",
       "      <td>These are now made in China, not England.  The...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[these are now made in china not england, the ...</td>\n",
       "      <td>these are now made in china not england, the h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90164</th>\n",
       "      <td>Mine arrived with a bend in the bracket that s...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[mine arrived with a bend in the bracket that ...</td>\n",
       "      <td>mine arrived with a bend in the bracket that s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55476</th>\n",
       "      <td>The picture shows the Marples that used to be ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[the picture shows the marples that used to be...</td>\n",
       "      <td>the picture shows the marples that used to be ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reviewText  rating  overall  \\\n",
       "99410   Bought one and loved it! Ordered another two.O...       0      1.0   \n",
       "110570  Not made in the usa.. I wouldn't dare use this...       0      1.0   \n",
       "55485   These are now made in China, not England.  The...       0      2.0   \n",
       "90164   Mine arrived with a bend in the bracket that s...       0      1.0   \n",
       "55476   The picture shows the Marples that used to be ...       0      1.0   \n",
       "\n",
       "                                                Processed  \\\n",
       "99410   [bought one and loved it, ordered another two ...   \n",
       "110570  [not made in the usa i would not dare use this...   \n",
       "55485   [these are now made in china not england, the ...   \n",
       "90164   [mine arrived with a bend in the bracket that ...   \n",
       "55476   [the picture shows the marples that used to be...   \n",
       "\n",
       "                                              CleanedJoin  \n",
       "99410   bought one and loved it, ordered another two o...  \n",
       "110570  not made in the usa i would not dare use this ...  \n",
       "55485   these are now made in china not england, the h...  \n",
       "90164   mine arrived with a bend in the bracket that s...  \n",
       "55476   the picture shows the marples that used to be ...  "
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewTextProcessing.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10105"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = reviewTextProcessing.loc[reviewTextProcessing['rating'] == 0, :].shape[0]\n",
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewTextProcessing = reviewTextProcessing.iloc[0:size*5, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>rating</th>\n",
       "      <th>overall</th>\n",
       "      <th>Processed</th>\n",
       "      <th>CleanedJoin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99410</th>\n",
       "      <td>Bought one and loved it! Ordered another two.O...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[bought one and loved it, ordered another two ...</td>\n",
       "      <td>bought one and loved it, ordered another two o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110570</th>\n",
       "      <td>Not made in the usa.. I wouldn't dare use this...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[not made in the usa i would not dare use this...</td>\n",
       "      <td>not made in the usa i would not dare use this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55485</th>\n",
       "      <td>These are now made in China, not England.  The...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[these are now made in china not england, the ...</td>\n",
       "      <td>these are now made in china not england, the h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90164</th>\n",
       "      <td>Mine arrived with a bend in the bracket that s...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[mine arrived with a bend in the bracket that ...</td>\n",
       "      <td>mine arrived with a bend in the bracket that s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55476</th>\n",
       "      <td>The picture shows the Marples that used to be ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[the picture shows the marples that used to be...</td>\n",
       "      <td>the picture shows the marples that used to be ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reviewText  rating  overall  \\\n",
       "99410   Bought one and loved it! Ordered another two.O...       0      1.0   \n",
       "110570  Not made in the usa.. I wouldn't dare use this...       0      1.0   \n",
       "55485   These are now made in China, not England.  The...       0      2.0   \n",
       "90164   Mine arrived with a bend in the bracket that s...       0      1.0   \n",
       "55476   The picture shows the Marples that used to be ...       0      1.0   \n",
       "\n",
       "                                                Processed  \\\n",
       "99410   [bought one and loved it, ordered another two ...   \n",
       "110570  [not made in the usa i would not dare use this...   \n",
       "55485   [these are now made in china not england, the ...   \n",
       "90164   [mine arrived with a bend in the bracket that ...   \n",
       "55476   [the picture shows the marples that used to be...   \n",
       "\n",
       "                                              CleanedJoin  \n",
       "99410   bought one and loved it, ordered another two o...  \n",
       "110570  not made in the usa i would not dare use this ...  \n",
       "55485   these are now made in china not england, the h...  \n",
       "90164   mine arrived with a bend in the bracket that s...  \n",
       "55476   the picture shows the marples that used to be ...  "
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "additionalNegatives = reviewTextProcessing.iloc[0:size, :].copy()\n",
    "additionalNegatives.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSample = pd.concat([reviewTextProcessing, additionalNegatives])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60630"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import itertools\n",
    "\n",
    "largeText = testSample.CleanedJoin.to_list()\n",
    "#largeText = reviewTextProcessing.reviewText.to_list() # Not too good accuracy around 116 missed with %86.94\n",
    "\n",
    "len(largeText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'SentimentModel'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\Study\\Anaconda3v2\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2656\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2657\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'SentimentModel'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-273-87d6f237ffcc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msentiment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreviewTextProcessing\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SentimentModel'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Study\\Anaconda3v2\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2925\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2926\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2927\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2928\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Study\\Anaconda3v2\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2657\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2659\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2661\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'SentimentModel'"
     ]
    }
   ],
   "source": [
    "#sentiment = reviewTextProcessing['SentimentModel'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "num_words = 15000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=num_words)\n",
    "tokenizer.fit_on_texts(largeText)\n",
    "#tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = largeText\n",
    "y = testSample['rating']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, random_state=310)\n",
    "\n",
    "x_train_text = X_train\n",
    "x_test_text = X_test\n",
    "\n",
    "x_train_tokens = tokenizer.texts_to_sequences(x_train_text)\n",
    "x_test_tokens = tokenizer.texts_to_sequences(x_test_text)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#  not very good way to arrange the samples \n",
    "size = int(len(largeText)*.75)\n",
    "x_train_text = largeText[:size]\n",
    "x_test_text = largeText[size:]\n",
    "\n",
    "y_train =  reviewTextProcessing['rating'][:size]\n",
    "y_test = reviewTextProcessing['rating'][size:]\n",
    "x_train_tokens = tokenizer.texts_to_sequences(x_train_text)\n",
    "x_test_tokens = tokenizer.texts_to_sequences(x_test_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45472, 15158, 45472, 15158)"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train), len(y_test), len(x_train_text), len(x_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train_tokens[1], x_train_text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_train_text[1]\n",
    "np.array(x_train_tokens[1])\n",
    "num_tokens = [len(tokens) for tokens in x_train_tokens + x_test_tokens]\n",
    "num_tokens = np.array(num_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109.2761339270988, 3563)"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(num_tokens), np.max(num_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131.30618335778905"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "371"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "max_tokens = int(max_tokens) \n",
    "max_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9599373247567211"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(num_tokens < max_tokens) / len(num_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((45472, 371), (15158, 371))"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad = 'pre'\n",
    "#pad = 'post'\n",
    "x_train_pad = pad_sequences(x_train_tokens, maxlen=max_tokens, padding=pad, truncating=pad)\n",
    "x_test_pad = pad_sequences(x_test_tokens, maxlen=max_tokens, padding=pad, truncating=pad)\n",
    "x_train_pad.shape, x_test_pad.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0   689\n",
      "   455     7 13523  1350    22  1024    19     9     7    51  2292     1\n",
      "   864   663    13     9     7   689   455    19     1   704     7   266\n",
      "  2292   473    27    88   133    42   252     1  1179   704    12]\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 1):\n",
    "    print(x_train_pad[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_string(tokens):\n",
    "    # Map from tokens back to words.\n",
    "    words = [inverse_map[token] for token in tokens if token != 0]\n",
    "    \n",
    "    # Concatenate all words.\n",
    "    text = \" \".join(words)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = tokenizer.word_index\n",
    "inverse_map = dict(zip(idx.values(), idx.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'these little magnets are really powerful for there size, i am using them to make secret compartments in custom made boxes, each one hols about of a pound'"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_text[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'these little magnets are really powerful for there size i am using them to make secret compartments in custom made boxes each one about of a pound'"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_to_string(x_train_tokens[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense, Embedding, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.2'"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Study\\Anaconda3v2\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 371, 200)          3000000   \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 370, 100)          40100     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_7 (Glob (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 3,066,213\n",
      "Trainable params: 3,066,213\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_cnn = Sequential()\n",
    "parameters = Embedding(num_words, 200, input_length=max_tokens)\n",
    "model_cnn.add(parameters)\n",
    "model_cnn.add(Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
    "model_cnn.add(GlobalMaxPooling1D())\n",
    "model_cnn.add(Dense(256, activation='relu'))\n",
    "model_cnn.add(Dense(1, activation='sigmoid'))\n",
    "model_cnn.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "model_cnn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45472"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = len(x_train_pad)\n",
    "index\n",
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 43198 samples, validate on 2274 samples\n",
      "Epoch 1/5\n",
      "43198/43198 [==============================] - 205s 5ms/step - loss: 0.0085 - acc: 0.9982 - val_loss: 0.2812 - val_acc: 0.9371\n",
      "Epoch 2/5\n",
      "43198/43198 [==============================] - 195s 5ms/step - loss: 0.0038 - acc: 0.9994 - val_loss: 0.3095 - val_acc: 0.9362\n",
      "Epoch 3/5\n",
      "43198/43198 [==============================] - 204s 5ms/step - loss: 0.0030 - acc: 0.9995 - val_loss: 0.3362 - val_acc: 0.9340\n",
      "Epoch 4/5\n",
      "43198/43198 [==============================] - 209s 5ms/step - loss: 0.0034 - acc: 0.9993 - val_loss: 0.3726 - val_acc: 0.9252\n",
      "Epoch 5/5\n",
      "43198/43198 [==============================] - 203s 5ms/step - loss: 0.0034 - acc: 0.9991 - val_loss: 0.4185 - val_acc: 0.9292\n",
      "Wall time: 16min 55s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x94df2d30>"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_cnn.fit(x_train_pad, y_train, validation_split=0.05, epochs=5, batch_size=74)\n",
    "#model.fit(x_train_pad, y_train,validation_split=0.05, epochs=3, batch_size=74)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "#more negative training\n",
    "#model_cnn.fit(x_negative_pad, y_negative, validation_split=0.05, epochs=3, batch_size=36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15158/15158 [==============================] - 25s 2ms/step\n",
      "Wall time: 24.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = model_cnn.evaluate(x_test_pad, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 94.14%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {0:.2%}\".format(result[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 22.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#y_pred = model_cnn_02.predict(x=x_test_pad[0:1000])\n",
    "y_pred = model_cnn.predict(x=x_test_pad)\n",
    "y_pred = y_pred.T[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15158.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.668828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.459213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.001779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.999994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "count  15158.000000\n",
       "mean       0.668828\n",
       "std        0.459213\n",
       "min        0.000000\n",
       "25%        0.001779\n",
       "50%        0.999994\n",
       "75%        1.000000\n",
       "max        1.000000"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_pred).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = y_pred.T[0]\n",
    "#list(np.where(y_pred.T[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_pred = np.array([1.0 if p>0.5 else 0.0 for p in y_pred])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15158,)"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cls_pred),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9413511017284603"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = (cls_pred==y_test).mean()\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15158"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = len(cls_pred)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4597, 461, 428, 9672)"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, cls_pred).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5058, 10100)"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.where(y_test==0)[0]),len(np.where(y_test==1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.where(y_train==0)[0]),len(np.where(y_train==1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_true = np.array(y_test)\n",
    "#cls_true = np.where(y_test[0:1000])\n",
    "#cls_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect = np.where(cls_pred != cls_true)\n",
    "incorrect = incorrect[0]\n",
    "len(incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = np.where(cls_pred == cls_true)\n",
    "#correct[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(incorrect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.where(y_pred.T)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>rating</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentModel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7695</th>\n",
       "      <td>This is my first tube amp and after doing a TO...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.36481481481481476, 0.275, -0.16666666666666...</td>\n",
       "      <td>[1.4361772486772488, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7696</th>\n",
       "      <td>This is an amazing amp. It works great, a lot ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.6000000000000001, 0.10312500000000001, 0.58...</td>\n",
       "      <td>[2.092013888888889, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7697</th>\n",
       "      <td>I've had this for about 3 years and I agree wi...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.55, 0.6, 0.25, 0.0, 0.5, -0.05, 0.0, -0.125...</td>\n",
       "      <td>[5.091515151515152, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7698</th>\n",
       "      <td>At the $600 price point for an all tube amp PL...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[-1.0, 0.011388888888888888, -0.075, 0.0, 0.0]</td>\n",
       "      <td>[-1.063611111111111, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7699</th>\n",
       "      <td>I play in our band at church and as such, I've...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.25555555555555554, 0.0, -0.15, 0.2, 0....</td>\n",
       "      <td>[5.556873015873016, 1.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviewText  overall  rating  \\\n",
       "7695  This is my first tube amp and after doing a TO...      5.0       1   \n",
       "7696  This is an amazing amp. It works great, a lot ...      5.0       1   \n",
       "7697  I've had this for about 3 years and I agree wi...      4.0       1   \n",
       "7698  At the $600 price point for an all tube amp PL...      5.0       1   \n",
       "7699  I play in our band at church and as such, I've...      5.0       1   \n",
       "\n",
       "                                              Sentiment  \\\n",
       "7695  [0.36481481481481476, 0.275, -0.16666666666666...   \n",
       "7696  [0.6000000000000001, 0.10312500000000001, 0.58...   \n",
       "7697  [0.55, 0.6, 0.25, 0.0, 0.5, -0.05, 0.0, -0.125...   \n",
       "7698     [-1.0, 0.011388888888888888, -0.075, 0.0, 0.0]   \n",
       "7699  [0.0, 0.25555555555555554, 0.0, -0.15, 0.2, 0....   \n",
       "\n",
       "                 SentimentModel  \n",
       "7695  [1.4361772486772488, 1.0]  \n",
       "7696   [2.092013888888889, 1.0]  \n",
       "7697   [5.091515151515152, 1.0]  \n",
       "7698  [-1.063611111111111, 0.0]  \n",
       "7699   [5.556873015873016, 1.0]  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_location = np.where(y_pred.T)[0]  + index\n",
    "CNNresult = reviewTextProcessing.loc[list(result_location),  ['reviewText', 'overall', 'rating', 'Sentiment' , 'SentimentModel']]\n",
    "#CNNresult.head(2)\n",
    "#CNNresult.shape\n",
    "#result_location\n",
    "#result_location\n",
    "CNNresult.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNNresult['CNN_Sentiment'] = cls_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumSentiment = lambda x: x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNNresult.columns = ['TextBlobAnalysis' if x=='Sentiment' else x for x in CNNresult.columns]\n",
    "CNNresult.columns = ['TextBlob_Sentiment' if x=='SentimentModel' else x for x in CNNresult.columns]\n",
    "CNNresult['TextBlob_Sentiment'] = CNNresult['TextBlob_Sentiment'].apply(sumSentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNNresult.CNN_Sentiment = CNNresult.CNN_Sentiment.astype(int)\n",
    "CNNresult.TextBlob_Sentiment = CNNresult.TextBlob_Sentiment.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNNresult.loc[CNNresult.overall >= 3.0 , :].to_csv(\"Rating3.0above_CNN.csv\")\n",
    "CNNresult.loc[CNNresult.overall < 3.0 , :].to_csv(\"RatingBelow3.0_CNN.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = CNNresult.rating.to_list()\n",
    "cnn_pred = CNNresult.CNN_Sentiment.to_list()\n",
    "textBlob_pred = CNNresult.TextBlob_Sentiment.to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#textBlob_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 126, 5, 2432)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_true, cnn_pred).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 95, 139, 2298)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_true, textBlob_pred).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = incorrect[1]\n",
    "print(type(idx))\n",
    "for each in incorrect[:10]:\n",
    "    idx = each\n",
    "    text = x_test_text[idx]\n",
    "    print(idx, text, cls_pred[idx], cls_true[idx], \" BlobText \",\n",
    "         TextBlob(text).sentiment.polarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 500\n",
    "\n",
    "#productsReviewData.cleanedText.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
