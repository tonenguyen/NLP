{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "\n",
    "import gzip #for parsing gz files\n",
    "import pandas as pd\n",
    "import re \n",
    "import inflect #numeric/cardinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirPath = r\"C:\\Study\\Projects\\NLP\\data\"\n",
    "reviewPath = r\"reviews_Tools_and_Home_Improvement_5.json.gz\"\n",
    "#reviewPath = r\"reviews_Musical_Instruments_5.json.gz\"\n",
    "qaPath = r\"C:\\Study\\Projects\\NLP\\data\" \n",
    "path = dirPath + \"\\\\\" + reviewPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFile = gzip.open(path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need this function because large amount of data we are going to load up\n",
    "\n",
    "# http://jmcauley.ucsd.edu/data/amazon/index.html\n",
    "# eval function allows text to be parsed as python code\n",
    "# parse function is a generator with yield\n",
    "# yield when we want to iterate over a sequence, but don't want to store the entire sequence in memory\n",
    "def parse(dataFile):\n",
    "    for each in dataFile:\n",
    "        yield eval(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each review for a product in dataFile maps dict[nth] = review (nth)\n",
    "# enumerate can't be used on a generator\n",
    "count = 0\n",
    "productReviews = {}\n",
    "for eachReview in parse(dataFile):\n",
    "    productReviews[count] = eachReview\n",
    "    count = count + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134476"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(productReviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reviewerID': 'A1W7J7X96MP32U',\n",
       " 'asin': 'B004C29AFS',\n",
       " 'reviewerName': 'Rocco',\n",
       " 'helpful': [3, 3],\n",
       " 'reviewText': \"I rarely give negative reviews but this think just doesn't last long.  I even bought a second one to verify I just didn't get a bad one, and six months later and it's broken...  Again.  It just stops turning on.  The battery holder is weak and do much as touch the case and the unit shuts off.  I really wanted this product to work for me but after the 2nd one going bad I have to give upI decided to open it up and see what the problem was.  The solder connections look like a 3 year old did it. Cheap flimsy wire and secured poorly\",\n",
       " 'overall': 1.0,\n",
       " 'summary': 'This is a peice of junk',\n",
       " 'unixReviewTime': 1365465600,\n",
       " 'reviewTime': '04 9, 2013'}"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "productReviews[101718]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "productsReviewData = pd.DataFrame.from_dict(productReviews, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['reviewerID', 'asin', 'reviewerName', 'helpful', 'reviewText',\n",
       "       'overall', 'summary', 'unixReviewTime', 'reviewTime'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "productsReviewData.shape\n",
    "productsReviewData.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduceData = productsReviewData.loc[:, ['asin', 'reviewerName', 'reviewText', 'helpful', 'overall']]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = lambda x: 1 if x > 2.0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>helpful</th>\n",
       "      <th>overall</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>134322</th>\n",
       "      <td>Amazing that they designed this thing without ...</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55236</th>\n",
       "      <td>I was ready to pick up one of these at a woodw...</td>\n",
       "      <td>[30, 38]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55234</th>\n",
       "      <td>I bought this set from amazon but is not like ...</td>\n",
       "      <td>[8, 15]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105852</th>\n",
       "      <td>Horrible.Not one blade runs true.  Some are as...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55216</th>\n",
       "      <td>This product is almost a joke.  The case is to...</td>\n",
       "      <td>[4, 9]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55201</th>\n",
       "      <td>Well I came back to change my review of the pr...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55196</th>\n",
       "      <td>Supposedly, these bits slice thru stainless st...</td>\n",
       "      <td>[2, 5]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105862</th>\n",
       "      <td>I bought this because I need to cut a vent hol...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55144</th>\n",
       "      <td>I have had this on my door for quite a while a...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55268</th>\n",
       "      <td>Appeared to be a 'perfect' light bar to sit ab...</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55138</th>\n",
       "      <td>Check the Internet on these locks.... they spo...</td>\n",
       "      <td>[6, 12]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55070</th>\n",
       "      <td>These cheap little lights aren't worth the mon...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55067</th>\n",
       "      <td>Initially these worked and seems ok.  Now, mon...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105955</th>\n",
       "      <td>I can't believe others aren't complaining abou...</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55038</th>\n",
       "      <td>What kind of a schoolkid wrote this descriptio...</td>\n",
       "      <td>[3, 14]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105980</th>\n",
       "      <td>Got this half dried out in a in a little torn ...</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55032</th>\n",
       "      <td>well received in good time, installed, does no...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55023</th>\n",
       "      <td>After giving this a 5 stars, I have to take it...</td>\n",
       "      <td>[7, 7]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105981</th>\n",
       "      <td>It is like there was no flux in the container ...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55085</th>\n",
       "      <td>I put all three under my work station desk. I ...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55269</th>\n",
       "      <td>Purchased this for under some cabinets in an a...</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55291</th>\n",
       "      <td>Turned the crank and it would not charge my ba...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55293</th>\n",
       "      <td>this is a really good idea but it is very brit...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105467</th>\n",
       "      <td>First off, I am a flashlight fanatic. I own hu...</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105468</th>\n",
       "      <td>Just received this light.  It came with a chea...</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55710</th>\n",
       "      <td>I could not wear these over my prescription gl...</td>\n",
       "      <td>[18, 24]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105550</th>\n",
       "      <td>Don't know if this tape is old of just a bad b...</td>\n",
       "      <td>[1, 3]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55611</th>\n",
       "      <td>Item would would have been great if the fit th...</td>\n",
       "      <td>[0, 2]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105557</th>\n",
       "      <td>Not as sticky for the price. I sanded then wip...</td>\n",
       "      <td>[0, 4]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55564</th>\n",
       "      <td>I have a drill that does not have a speed sett...</td>\n",
       "      <td>[9, 11]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57277</th>\n",
       "      <td>I wouldn't waste your money on this 1 brush wh...</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57257</th>\n",
       "      <td>The seat is well made, but unfortunately my to...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57402</th>\n",
       "      <td>What I got was not as shown on the product pag...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57248</th>\n",
       "      <td>This toilet seat is VERY flimsy.  Everything a...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57744</th>\n",
       "      <td>The toilet paper roll holder was the same poor...</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57816</th>\n",
       "      <td>Three feet is a pretty handy length for a leve...</td>\n",
       "      <td>[4, 5]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58312</th>\n",
       "      <td>to the consensus rating.  YES it charges fast....</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58292</th>\n",
       "      <td>This is the 1.5 amp hour Makita battery sold w...</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58289</th>\n",
       "      <td>stinks of refurb.  I'd buy one straight from M...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58273</th>\n",
       "      <td>The basic idea for this set is excellent. You ...</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58199</th>\n",
       "      <td>The outside is made of recycled paper (which c...</td>\n",
       "      <td>[1, 3]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58196</th>\n",
       "      <td>don't know where this is intended for but it w...</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58193</th>\n",
       "      <td>The spray part broke off.  It's not a total wa...</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58172</th>\n",
       "      <td>I sharpen a lot of knives for everyone and as ...</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58145</th>\n",
       "      <td>For those who are not very handy and just need...</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58105</th>\n",
       "      <td>Had to return this item. Couldn't figure out h...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57782</th>\n",
       "      <td>This is the first toolkit we have ever brought...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58088</th>\n",
       "      <td>This is a nice pocket multi-tool with a pliers...</td>\n",
       "      <td>[1, 4]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58042</th>\n",
       "      <td>If these reviews pertained simply to build qua...</td>\n",
       "      <td>[13, 14]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58011</th>\n",
       "      <td>If you need a night light to dimly illuminate ...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57995</th>\n",
       "      <td>I ordered this quiet close seat to replace an ...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57965</th>\n",
       "      <td>The mounting jaw is not wide enough to mount t...</td>\n",
       "      <td>[4, 5]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57961</th>\n",
       "      <td>All joints, especially the screw jaw tightener...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57958</th>\n",
       "      <td>I bought this for the advertisement, dont buy ...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57942</th>\n",
       "      <td>I bought this some time ago (last summer) and ...</td>\n",
       "      <td>[0, 4]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57886</th>\n",
       "      <td>Gee whiz, I used to loved Moen fixtures. They ...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57867</th>\n",
       "      <td>Looked very well made and heavy. Wasn't expect...</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57853</th>\n",
       "      <td>I got the VPX system for two reasons, to get t...</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58087</th>\n",
       "      <td>This micro multi tool is about average for a l...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65231</th>\n",
       "      <td>'For a Maglite flashlight', it gives a pretty ...</td>\n",
       "      <td>[29, 36]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10105 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reviewText   helpful  overall  \\\n",
       "134322  Amazing that they designed this thing without ...    [2, 2]      1.0   \n",
       "55236   I was ready to pick up one of these at a woodw...  [30, 38]      1.0   \n",
       "55234   I bought this set from amazon but is not like ...   [8, 15]      1.0   \n",
       "105852  Horrible.Not one blade runs true.  Some are as...    [0, 0]      1.0   \n",
       "55216   This product is almost a joke.  The case is to...    [4, 9]      1.0   \n",
       "55201   Well I came back to change my review of the pr...    [0, 0]      1.0   \n",
       "55196   Supposedly, these bits slice thru stainless st...    [2, 5]      1.0   \n",
       "105862  I bought this because I need to cut a vent hol...    [0, 0]      1.0   \n",
       "55144   I have had this on my door for quite a while a...    [0, 0]      1.0   \n",
       "55268   Appeared to be a 'perfect' light bar to sit ab...    [0, 1]      1.0   \n",
       "55138   Check the Internet on these locks.... they spo...   [6, 12]      1.0   \n",
       "55070   These cheap little lights aren't worth the mon...    [0, 0]      1.0   \n",
       "55067   Initially these worked and seems ok.  Now, mon...    [0, 0]      1.0   \n",
       "105955  I can't believe others aren't complaining abou...    [2, 2]      1.0   \n",
       "55038   What kind of a schoolkid wrote this descriptio...   [3, 14]      1.0   \n",
       "105980  Got this half dried out in a in a little torn ...    [1, 1]      1.0   \n",
       "55032   well received in good time, installed, does no...    [0, 0]      1.0   \n",
       "55023   After giving this a 5 stars, I have to take it...    [7, 7]      1.0   \n",
       "105981  It is like there was no flux in the container ...    [0, 0]      1.0   \n",
       "55085   I put all three under my work station desk. I ...    [0, 0]      1.0   \n",
       "55269   Purchased this for under some cabinets in an a...    [0, 1]      1.0   \n",
       "55291   Turned the crank and it would not charge my ba...    [0, 0]      1.0   \n",
       "55293   this is a really good idea but it is very brit...    [0, 0]      1.0   \n",
       "105467  First off, I am a flashlight fanatic. I own hu...    [0, 1]      1.0   \n",
       "105468  Just received this light.  It came with a chea...    [1, 1]      1.0   \n",
       "55710   I could not wear these over my prescription gl...  [18, 24]      1.0   \n",
       "105550  Don't know if this tape is old of just a bad b...    [1, 3]      1.0   \n",
       "55611   Item would would have been great if the fit th...    [0, 2]      1.0   \n",
       "105557  Not as sticky for the price. I sanded then wip...    [0, 4]      1.0   \n",
       "55564   I have a drill that does not have a speed sett...   [9, 11]      1.0   \n",
       "...                                                   ...       ...      ...   \n",
       "57277   I wouldn't waste your money on this 1 brush wh...    [1, 1]      2.0   \n",
       "57257   The seat is well made, but unfortunately my to...    [0, 0]      2.0   \n",
       "57402   What I got was not as shown on the product pag...    [0, 0]      2.0   \n",
       "57248   This toilet seat is VERY flimsy.  Everything a...    [0, 0]      2.0   \n",
       "57744   The toilet paper roll holder was the same poor...    [2, 2]      2.0   \n",
       "57816   Three feet is a pretty handy length for a leve...    [4, 5]      2.0   \n",
       "58312   to the consensus rating.  YES it charges fast....    [0, 0]      2.0   \n",
       "58292   This is the 1.5 amp hour Makita battery sold w...    [1, 1]      2.0   \n",
       "58289   stinks of refurb.  I'd buy one straight from M...    [0, 0]      2.0   \n",
       "58273   The basic idea for this set is excellent. You ...    [1, 2]      2.0   \n",
       "58199   The outside is made of recycled paper (which c...    [1, 3]      2.0   \n",
       "58196   don't know where this is intended for but it w...    [1, 1]      2.0   \n",
       "58193   The spray part broke off.  It's not a total wa...    [1, 1]      2.0   \n",
       "58172   I sharpen a lot of knives for everyone and as ...    [1, 1]      2.0   \n",
       "58145   For those who are not very handy and just need...    [0, 1]      2.0   \n",
       "58105   Had to return this item. Couldn't figure out h...    [0, 0]      2.0   \n",
       "57782   This is the first toolkit we have ever brought...    [0, 0]      2.0   \n",
       "58088   This is a nice pocket multi-tool with a pliers...    [1, 4]      2.0   \n",
       "58042   If these reviews pertained simply to build qua...  [13, 14]      2.0   \n",
       "58011   If you need a night light to dimly illuminate ...    [0, 0]      2.0   \n",
       "57995   I ordered this quiet close seat to replace an ...    [0, 0]      2.0   \n",
       "57965   The mounting jaw is not wide enough to mount t...    [4, 5]      2.0   \n",
       "57961   All joints, especially the screw jaw tightener...    [0, 0]      2.0   \n",
       "57958   I bought this for the advertisement, dont buy ...    [0, 0]      2.0   \n",
       "57942   I bought this some time ago (last summer) and ...    [0, 4]      2.0   \n",
       "57886   Gee whiz, I used to loved Moen fixtures. They ...    [0, 0]      2.0   \n",
       "57867   Looked very well made and heavy. Wasn't expect...    [1, 1]      2.0   \n",
       "57853   I got the VPX system for two reasons, to get t...    [2, 2]      2.0   \n",
       "58087   This micro multi tool is about average for a l...    [0, 0]      2.0   \n",
       "65231   'For a Maglite flashlight', it gives a pretty ...  [29, 36]      2.0   \n",
       "\n",
       "        rating  \n",
       "134322       0  \n",
       "55236        0  \n",
       "55234        0  \n",
       "105852       0  \n",
       "55216        0  \n",
       "55201        0  \n",
       "55196        0  \n",
       "105862       0  \n",
       "55144        0  \n",
       "55268        0  \n",
       "55138        0  \n",
       "55070        0  \n",
       "55067        0  \n",
       "105955       0  \n",
       "55038        0  \n",
       "105980       0  \n",
       "55032        0  \n",
       "55023        0  \n",
       "105981       0  \n",
       "55085        0  \n",
       "55269        0  \n",
       "55291        0  \n",
       "55293        0  \n",
       "105467       0  \n",
       "105468       0  \n",
       "55710        0  \n",
       "105550       0  \n",
       "55611        0  \n",
       "105557       0  \n",
       "55564        0  \n",
       "...        ...  \n",
       "57277        0  \n",
       "57257        0  \n",
       "57402        0  \n",
       "57248        0  \n",
       "57744        0  \n",
       "57816        0  \n",
       "58312        0  \n",
       "58292        0  \n",
       "58289        0  \n",
       "58273        0  \n",
       "58199        0  \n",
       "58196        0  \n",
       "58193        0  \n",
       "58172        0  \n",
       "58145        0  \n",
       "58105        0  \n",
       "57782        0  \n",
       "58088        0  \n",
       "58042        0  \n",
       "58011        0  \n",
       "57995        0  \n",
       "57965        0  \n",
       "57961        0  \n",
       "57958        0  \n",
       "57942        0  \n",
       "57886        0  \n",
       "57867        0  \n",
       "57853        0  \n",
       "58087        0  \n",
       "65231        0  \n",
       "\n",
       "[10105 rows x 4 columns]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduceData['rating'] = reduceData['overall'].apply(rating)\n",
    "unfavorableReviews = list(reduceData.loc[ reduceData['rating'] == 0, \n",
    "                                         ['reviewText', 'helpful', 'overall', 'rating']].sort_values(by='overall').index)\n",
    "#unfavorableReviews\n",
    "reduceData.loc[ reduceData['rating'] == 0, ['reviewText', 'helpful', 'overall', 'rating']].sort_values(by='overall')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewTextProcessing = pd.DataFrame(reduceData.reviewText.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewTextProcessing['rating'] = reduceData['rating']\n",
    "reviewTextProcessing['overall'] = reduceData['overall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134476, 3)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "productsReviewData.dtypes\n",
    "len(productsReviewData)\n",
    "# reviewText, rating, overall\n",
    "reviewTextProcessing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reviewTextProcessing.loc[reviewTextProcessing['rating']==0, ['rating', 'overall', 'Processed', 'SentimentModel']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([\"ain't\", \"aren't\", \"can't\", \"can't've\", \"'cause\", \"could've\", \"couldn't\", \"couldn't've\", \"didn't\", \"doesn't\", \"don't\", \"hadn't\", \"hadn't've\", \"hasn't\", \"haven't\", \"he'd\", \"he'd've\", \"he'll\", \"he'll've\", \"he's\", \"how'd\", \"how'd'y\", \"how'll\", \"how's\", \"I'd\", \"I'd've\", \"I'll\", \"I'll've\", \"I'm\", \"I've\", \"isn't\", \"it'd\", \"it'd've\", \"it'll\", \"it'll've\", \"it's\", \"let's\", \"ma'am\", \"mayn't\", \"might've\", \"mightn't\", \"mightn't've\", \"must've\", \"mustn't\", \"mustn't've\", \"needn't\", \"needn't've\", \"o'clock\", \"oughtn't\", \"oughtn't've\", \"shan't\", \"sha'n't\", \"shan't've\", \"she'd\", \"she'd've\", \"she'll\", \"she'll've\", \"she's\", 's###', \"should've\", \"shouldn't\", \"shouldn't've\", \"so've\", \"so's\", \"that'd\", \"that'd've\", \"that's\", \"there'd\", \"there'd've\", \"there's\", \"they'd\", \"they'd've\", \"they'll\", \"they'll've\", \"they're\", \"they've\", \"to've\", \"wasn't\", \"we'd\", \"we'd've\", \"we'll\", \"we'll've\", \"we're\", \"we've\", \"weren't\", \"what'll\", \"what'll've\", \"what're\", \"what's\", \"what've\", \"when's\", \"when've\", \"where'd\", \"where's\", \"where've\", \"who'll\", \"who'll've\", \"who's\", \"who've\", \"why's\", \"why've\", \"will've\", \"won't\", \"won't've\", \"would've\", \"wouldn't\", \"wouldn't've\", \"y'all\", \"y'all'd\", \"y'all'd've\", \"y'all're\", \"y'all've\", \"you'd\", \"you'd've\", \"you'll\", \"you'll've\", \"you're\", \"you've\"])\n"
     ]
    }
   ],
   "source": [
    "#https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python\n",
    "import Contractions_Words as contractions\n",
    "import importlib\n",
    "importlib.reload(contractions)\n",
    "\n",
    "contractions_dict = contractions.contractions_dict\n",
    "\n",
    "print(contractions_dict.keys())\n",
    "#print(contractions_dict[\"s***\"])\n",
    "\n",
    "pattern = '%s' % '|'.join(contractions_dict.keys())\n",
    "#pattern = r\"%s\" % pattern\n",
    "#print(pattern)\n",
    "contractions_re = re.compile(pattern)\n",
    "def expand_contractions(s, contractions_dict=contractions_dict):\n",
    "    #edit for special case like s*** etc\n",
    "    s = re.sub(\"\\*\", \"#\", s)\n",
    "    def replace(match):\n",
    "        #print(type(match), match)\n",
    "        return contractions_dict[match.group(0)]\n",
    "    return contractions_re.sub(replace, s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s###\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'shit'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample1 = \"s***\"\n",
    "print(re.sub(\"\\*\", \"#\", sample1))\n",
    "\n",
    "sample = \"I don\\'t know what to say nay. I haven\\'t. s###\"\n",
    "expand_contractions(sample)\n",
    "expand_contractions(sample1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import string\n",
    "\n",
    "# return both wholeText, paragraph Text\n",
    "def singleReviewCleanUp(sample):\n",
    "    #print(sample)\n",
    "    #sample = sample.decode(\"utf-8\")\n",
    "    sample = expand_contractions(sample)\n",
    "    sample = sample.lower()\n",
    "    \n",
    "    #for word in sample:\n",
    "    #    print(lemmatizer.lemmatize(word, wordnet.VERB))\n",
    "    \n",
    "    review = sent_tokenize(sample)\n",
    "    #print(review)\n",
    "    for count, eachSent in enumerate(review):\n",
    "        #remove numbers\n",
    "        eachSent = re.sub(\"r'\\d+/\\d+|\\d+|\\$\\d+.\\d+\", \" \", eachSent)\n",
    "        #remove string\n",
    "        eachSent = re.sub('[%s]' % re.escape(string.punctuation), ' ', eachSent)\n",
    "        #word tokens\n",
    "        #print([lemmatizer.lemmatize(text, wordnet.VERB) for text in eachSent.split()])\n",
    "        eachSent = word_tokenize(eachSent)\n",
    "        review[count] = eachSent\n",
    "        # lemmatize and remove stopWords\n",
    "        #eachSent = [word for word in eachSent if not word in stopWords]\n",
    "        #eachSent = [lemmatizer.lemmatize(word, wordnet.VERB) for word in eachSent]\n",
    "        #eachSent = [lemmatizer.lemmatize(word, wordnet.VERB) for word in eachSent if not word in stopWords]\n",
    "        review[count] = \" \".join(eachSent)\n",
    "    wholeText = [\" \".join(review) ]\n",
    "    paragraphText = review\n",
    "    #return wholeText\n",
    "    #return paragraphText\n",
    "    return paragraphText, wholeText\n",
    "\n",
    "#paragraphText, wholeText = singleReviewCleanUp(sample)\n",
    "#wholeText, paragraphText\n",
    "#paragraphText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Give me back text in a paragraph sentence forms. They do have more values than a clobbed of text based on Polarity Check.\n",
    "cleanUpTextParagraph = lambda text: singleReviewCleanUp(text)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reviewTextProcessing['Processed'] = reviewTextProcessing.reviewText.apply(cleanUpTextParagraph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample = \" I don't know what to do. I need to test through tough. Do you have any suggestions\"\n",
    "#result = cleanUpTextParagraph(sample)\n",
    "#result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# need to do a data check first\n",
    "def getPolaritySubjectivity(data):\n",
    "    #print(data)\n",
    "    paragraphText = data\n",
    "    sumPolarity = []\n",
    "    sumSubjectivity = []\n",
    "    for each in paragraphText:\n",
    "        sumPolarity.append(TextBlob(each).sentiment.polarity)\n",
    "        sumSubjectivity.append(TextBlob(each).sentiment.subjectivity)\n",
    "    #print(\"sumPol\", sumPolarity)\n",
    "    return sumPolarity, sumSubjectivity\n",
    "    #return sum(sumPolarity), sum(sumSubjectivity)\n",
    "\n",
    "    #print(each, TextBlob(each).sentiment.polarity, TextBlob(each).sentiment.subjectivity)\n",
    "#(sample2, TextBlob(sample2).sentiment.polarity, TextBlob(sample2).sentiment.subjectivity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return the sume of polarity in a paragraph sentence when give a text in a list form of sentence\n",
    "\n",
    "getPolarityFromText = lambda text: getPolaritySubjectivity(text)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each in sampleText:\n",
    "#    sample = cleanUpTextParagraph(each)\n",
    "#    print(sample, getPolarityFromText(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentiment = lambda text: TextBlob(text).sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjustSentimentModel = lambda x: [sum(x), 0.0] if sum(x) < 0 else [sum(x), 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reviewTextProcessing['Sentiment']= reviewTextProcessing.Processed.apply(getPolarityFromText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 115 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reviewTextProcessing['SentimentModel']= reviewTextProcessing.Sentiment.apply(adjustSentimentModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reviewTextProcessing.loc[unfavorableReviews, ['Processed', 'Sentiment', 'SentimentModel']]\n",
    "#reviewTextProcessing.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewTextProcessing['CleanedJoin'] = reviewTextProcessing['Processed'].apply(', '.join)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['reviewText', 'rating', 'overall', 'Processed', 'Sentiment',\n",
       "       'SentimentModel', 'CleanedJoin'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewTextProcessing.shape\n",
    "reviewTextProcessing.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from gensim import corpora\n",
    "#dictionary = corpora.Dictionary(T)\n",
    "#print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    i hate it when my shirt collars not otherwise ...\n",
       "1    these little magnets are really powerful for t...\n",
       "2    i wanted something this small to mount on the ...\n",
       "3    i use these to magnetize my warhammer k miniat...\n",
       "4    they are soo freaking annoying, why, you spend...\n",
       "Name: CleanedJoin, dtype: object"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewTextProcessing['CleanedJoin'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134476"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import itertools\n",
    "\n",
    "largeText = reviewTextProcessing.CleanedJoin.to_list()\n",
    "#largeText = reviewTextProcessing.reviewText.to_list() # Not too good accuracy around 116 missed with %86.94\n",
    "\n",
    "len(largeText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = reviewTextProcessing['SentimentModel'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "num_words = 10000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=num_words)\n",
    "tokenizer.fit_on_texts(largeText)\n",
    "#tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "size = int(len(largeText)*.75)\n",
    "x_train_text = largeText[:size]\n",
    "x_test_text = largeText[size:]\n",
    "\n",
    "y_train =  reviewTextProcessing['rating'][:size]\n",
    "y_test = reviewTextProcessing['rating'][size:]\n",
    "x_train_tokens = tokenizer.texts_to_sequences(x_train_text)\n",
    "x_test_tokens = tokenizer.texts_to_sequences(x_test_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100857, 33619, 100857, 33619)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train), len(y_test), len(x_train_text), len(x_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train_tokens[1], x_train_text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_train_text[1]\n",
    "np.array(x_train_tokens[1])\n",
    "num_tokens = [len(tokens) for tokens in x_train_tokens + x_test_tokens]\n",
    "num_tokens = np.array(num_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110.80553407299443, 4838)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(num_tokens), np.max(num_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132.92503796578936"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "376"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "max_tokens = int(max_tokens) \n",
    "max_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.958706386269669"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(num_tokens < max_tokens) / len(num_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33619, 376)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad = 'pre'\n",
    "x_train_pad = pad_sequences(x_train_tokens, maxlen=max_tokens, padding=pad, truncating=pad)\n",
    "x_test_pad = pad_sequences(x_test_tokens, maxlen=max_tokens, padding=pad, truncating=pad)\n",
    "x_train_pad.shape\n",
    "x_test_pad.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    2 1558    4   39   18 3329 8531   11  722\n",
      " 2917   12  236   82 1219  220   41   12 2405  908 2048    1  225    2\n",
      "  212   68  424 2317  951    5   32   17   37 1753   19   27  120   64\n",
      " 1190    2  996   41   96    8   37 1753   25   12    1 2317   17    1\n",
      "  630    6    1   62  320   18 3329    5  247   18 2317   12  236   27\n",
      "   60 1524   27   20    1  211  171    6   61   20  615    8 1753   12\n",
      "  174   14 1232    5  388   55   38    1  220    8    1  225]\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 1):\n",
    "    print(x_train_pad[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_string(tokens):\n",
    "    # Map from tokens back to words.\n",
    "    words = [inverse_map[token] for token in tokens if token != 0]\n",
    "    \n",
    "    # Concatenate all words.\n",
    "    text = \" \".join(words)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = tokenizer.word_index\n",
    "inverse_map = dict(zip(idx.values(), idx.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'these little magnets are really powerful for there size, i am using them to make secret compartments in custom made boxes, each one hols about of a pound'"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_text[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'these little magnets are really powerful for there size i am using them to make secret compartments in custom made boxes each one about of a pound'"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_to_string(x_train_tokens[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense, Embedding, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.2'"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 376, 200)          2000000   \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 375, 100)          40100     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,066,213\n",
      "Trainable params: 2,066,213\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_cnn_02 = Sequential()\n",
    "e = Embedding(num_words, 200, input_length=max_tokens)\n",
    "model_cnn_02.add(e)\n",
    "model_cnn_02.add(Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
    "model_cnn_02.add(GlobalMaxPooling1D())\n",
    "model_cnn_02.add(Dense(256, activation='relu'))\n",
    "model_cnn_02.add(Dense(1, activation='sigmoid'))\n",
    "model_cnn_02.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "model_cnn_02.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100857"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = len(x_train_pad)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 95814 samples, validate on 5043 samples\n",
      "Epoch 1/3\n",
      "95814/95814 [==============================] - 384s 4ms/step - loss: 0.1907 - acc: 0.9335 - val_loss: 0.1572 - val_acc: 0.9431\n",
      "Epoch 2/3\n",
      "95814/95814 [==============================] - 382s 4ms/step - loss: 0.1278 - acc: 0.9507 - val_loss: 0.1603 - val_acc: 0.9467\n",
      "Epoch 3/3\n",
      "95814/95814 [==============================] - 379s 4ms/step - loss: 0.0902 - acc: 0.9653 - val_loss: 0.1738 - val_acc: 0.9435\n",
      "Wall time: 19min 5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11c16438>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_cnn_02.fit(x_train_pad, y_train, validation_split=0.05, epochs=3, batch_size=74)\n",
    "#model.fit(x_train_pad, y_train,validation_split=0.05, epochs=3, batch_size=74)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33619/33619 [==============================] - 49s 1ms/step\n",
      "Wall time: 48.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = model_cnn_02.evaluate(x_test_pad, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.01%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {0:.2%}\".format(result[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = model_cnn_02.predict(x=x_test_pad[0:1000])\n",
    "y_pred = y_pred.T[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.932637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.182945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.011366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.979855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.998276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.999831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "count  1000.000000\n",
       "mean      0.932637\n",
       "std       0.182945\n",
       "min       0.011366\n",
       "25%       0.979855\n",
       "50%       0.998276\n",
       "75%       0.999831\n",
       "max       1.000000"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_pred).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = y_pred.T[0]\n",
    "#list(np.where(y_pred.T[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_pred = np.array([1.0 if p>0.5 else 0.0 for p in y_pred])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_true = np.array(y_test[0:1000])\n",
    "#cls_true = np.where(y_test[0:1000])\n",
    "#cls_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 14,  39,  85, 133, 148, 155, 190, 191, 197, 204, 239, 365, 445,\n",
       "       459, 475, 518, 534, 537, 542, 588, 616, 641, 658, 661, 663, 675,\n",
       "       684, 723, 737, 758, 760, 762, 763, 790, 795, 877, 886, 914, 922,\n",
       "       935, 944, 949, 957, 965, 970, 979, 983, 992], dtype=int64)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect = np.where(cls_pred != cls_true)\n",
    "incorrect = incorrect[0]\n",
    "incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = np.where(cls_pred == cls_true)\n",
    "#correct[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(incorrect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.where(y_pred.T)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>rating</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentModel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100857</th>\n",
       "      <td>Hunter 90434 16-Inch Portable Stand Fan, Oil R...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.78, 0.0, 0.0, 0.13636363636363635, 0.0...</td>\n",
       "      <td>[1.8063636363636364, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100858</th>\n",
       "      <td>Needed these because I was refinishing a large...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.21428571428571427, 0.10571428571428572, 0.0...</td>\n",
       "      <td>[0.29833333333333334, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100859</th>\n",
       "      <td>These are large and long lasting tack cloths, ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.15285714285714286]</td>\n",
       "      <td>[0.15285714285714286, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100860</th>\n",
       "      <td>I need these all the time mfor my woodworking ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.65]</td>\n",
       "      <td>[0.65, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100861</th>\n",
       "      <td>Good quality.  They are packaged well and can ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.7, 0.0, 0.1]</td>\n",
       "      <td>[0.7999999999999999, 1.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reviewText  overall  rating  \\\n",
       "100857  Hunter 90434 16-Inch Portable Stand Fan, Oil R...      5.0       1   \n",
       "100858  Needed these because I was refinishing a large...      5.0       1   \n",
       "100859  These are large and long lasting tack cloths, ...      5.0       1   \n",
       "100860  I need these all the time mfor my woodworking ...      5.0       1   \n",
       "100861  Good quality.  They are packaged well and can ...      4.0       1   \n",
       "\n",
       "                                                Sentiment  \\\n",
       "100857  [0.0, 0.78, 0.0, 0.0, 0.13636363636363635, 0.0...   \n",
       "100858  [0.21428571428571427, 0.10571428571428572, 0.0...   \n",
       "100859                              [0.15285714285714286]   \n",
       "100860                                        [0.0, 0.65]   \n",
       "100861                                    [0.7, 0.0, 0.1]   \n",
       "\n",
       "                    SentimentModel  \n",
       "100857   [1.8063636363636364, 1.0]  \n",
       "100858  [0.29833333333333334, 1.0]  \n",
       "100859  [0.15285714285714286, 1.0]  \n",
       "100860                 [0.65, 1.0]  \n",
       "100861   [0.7999999999999999, 1.0]  "
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_location = np.where(y_pred.T)[0]  + index\n",
    "CNNresult = reviewTextProcessing.loc[list(result_location),  ['reviewText', 'overall', 'rating', 'Sentiment' , 'SentimentModel']]\n",
    "#CNNresult.head(2)\n",
    "#CNNresult.shape\n",
    "#result_location\n",
    "#result_location\n",
    "CNNresult.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNNresult['CNN_Sentiment'] = cls_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumSentiment = lambda x: x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNNresult.columns = ['TextBlobAnalysis' if x=='Sentiment' else x for x in CNNresult.columns]\n",
    "CNNresult.columns = ['TextBlob_Sentiment' if x=='SentimentModel' else x for x in CNNresult.columns]\n",
    "CNNresult['TextBlob_Sentiment'] = CNNresult['TextBlob_Sentiment'].apply(sumSentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNNresult.CNN_Sentiment = CNNresult.CNN_Sentiment.astype(int)\n",
    "CNNresult.TextBlob_Sentiment = CNNresult.TextBlob_Sentiment.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNNresult.loc[CNNresult.overall >= 3.0 , :].to_csv(\"Rating3.0above_CNN.csv\")\n",
    "CNNresult.loc[CNNresult.overall < 3.0 , :].to_csv(\"RatingBelow3.0_CNN.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = CNNresult.rating.to_list()\n",
    "cnn_pred = CNNresult.CNN_Sentiment.to_list()\n",
    "textBlob_pred = CNNresult.TextBlob_Sentiment.to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#textBlob_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 30, 18, 921)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_true, cnn_pred).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 40, 93, 846)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_true, textBlob_pred).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = incorrect[1]\n",
    "print(type(idx))\n",
    "for each in incorrect[:10]:\n",
    "    idx = each\n",
    "    text = x_test_text[idx]\n",
    "    print(idx, text, cls_pred[idx], cls_true[idx], \" BlobText \",\n",
    "         TextBlob(text).sentiment.polarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 500\n",
    "\n",
    "#productsReviewData.cleanedText.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
