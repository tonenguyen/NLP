{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "\n",
    "import gzip #for parsing gz files\n",
    "import pandas as pd\n",
    "import re \n",
    "#import inflect #numeric/cardinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirPath = r\"C:\\Study\\Projects\\NLP\\data\"\n",
    "reviewPath = r\"reviews_Tools_and_Home_Improvement_5.json.gz\"\n",
    "#reviewPath = r\"reviews_Musical_Instruments_5.json.gz\"\n",
    "qaPath = r\"C:\\Study\\Projects\\NLP\\data\" \n",
    "path = dirPath + \"\\\\\" + reviewPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFile = gzip.open(path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need this function because large amount of data we are going to load up\n",
    "\n",
    "# http://jmcauley.ucsd.edu/data/amazon/index.html\n",
    "# eval function allows text to be parsed as python code\n",
    "# parse function is a generator with yield\n",
    "# yield when we want to iterate over a sequence, but don't want to store the entire sequence in memory\n",
    "def parse(dataFile):\n",
    "    for each in dataFile:\n",
    "        yield eval(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each review for a product in dataFile maps dict[nth] = review (nth)\n",
    "# enumerate can't be used on a generator\n",
    "count = 0\n",
    "productReviews = {}\n",
    "for eachReview in parse(dataFile):\n",
    "    productReviews[count] = eachReview\n",
    "    count = count + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134476"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(productReviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "productsReviewData = pd.DataFrame.from_dict(productReviews, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A4IL0CLL27Q33</td>\n",
       "      <td>104800001X</td>\n",
       "      <td>D. Brennan</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>I hate it when my shirt collars, not otherwise secured in place by buttons, end up in weird places throughout the day. I purchased some steel collar stays to use with these magnets but they were only vaguely magnetic. I ended up using 2 of these magnets - one in the collar with the stay and the other inside my shirt, to lock my collar in place. They work flawlessly. They are the perfect size, and there are plenty of magnets in case you forget to remove them at the end of the day.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Perfect for collar stay management</td>\n",
       "      <td>1390953600</td>\n",
       "      <td>01 29, 2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      reviewerID        asin reviewerName helpful  \\\n",
       "0  A4IL0CLL27Q33  104800001X   D. Brennan  [0, 1]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             reviewText  \\\n",
       "0  I hate it when my shirt collars, not otherwise secured in place by buttons, end up in weird places throughout the day. I purchased some steel collar stays to use with these magnets but they were only vaguely magnetic. I ended up using 2 of these magnets - one in the collar with the stay and the other inside my shirt, to lock my collar in place. They work flawlessly. They are the perfect size, and there are plenty of magnets in case you forget to remove them at the end of the day.   \n",
       "\n",
       "   overall                             summary  unixReviewTime   reviewTime  \n",
       "0      5.0  Perfect for collar stay management      1390953600  01 29, 2014  "
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "productsReviewData.shape\n",
    "#productsReviewData.columns\n",
    "productsReviewData.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(134476, 5)\n"
     ]
    }
   ],
   "source": [
    "reduceData = productsReviewData.loc[:, ['asin', 'reviewerName', 'reviewText', 'helpful', 'overall']]\n",
    "print(reduceData.shape)\n",
    "#reduceData = reduceData.loc[reduceData.overall != 3.0, :] #Ignore rating at 3 \n",
    "#reduceData.index = range(0, len(reduceData), 1)  #very important if we drop or excluse certain items\n",
    "#print(reduceData.shape)\n",
    "#reduceData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rating = lambda x: 1 if x > 3.0 else 0 # %84 accuracy > (14, 121, 63, 802) and BlobText (33, 102, 34, 831)\n",
    "rating = lambda x: 1 if x > 2.0 else 0 #%  94% accuracy > (0, 46, 0, 954) and BlobText 14, 28, 57, 901"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduceData['rating'] = reduceData['overall'].apply(rating)\n",
    "#unfavorableReviews = (reduceData.loc[ reduceData['rating'] == 0, \n",
    "#                                         ['reviewText', 'helpful', 'overall', 'rating']].sort_values(by='overall'))\n",
    "#unfavorableReviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewTextProcessing = pd.DataFrame(reduceData.reviewText.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewTextProcessing['rating'] = reduceData['rating']\n",
    "reviewTextProcessing['overall'] = reduceData['overall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134476, 3)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "productsReviewData.dtypes\n",
    "len(productsReviewData)\n",
    "# reviewText, rating, overall\n",
    "reviewTextProcessing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reviewTextProcessing.loc[reviewTextProcessing['rating']==0, ['rating', 'overall', 'Processed', 'SentimentModel']].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python\n",
    "import Contractions_Words as contractions\n",
    "import importlib\n",
    "importlib.reload(contractions)\n",
    "\n",
    "contractions_dict = contractions.contractions_dict\n",
    "\n",
    "#print(contractions_dict.keys())\n",
    "#print(contractions_dict[\"s***\"])\n",
    "\n",
    "pattern = '%s' % '|'.join(contractions_dict.keys())\n",
    "#pattern = r\"%s\" % pattern\n",
    "#print(pattern)\n",
    "contractions_re = re.compile(pattern)\n",
    "def expand_contractions(s, contractions_dict=contractions_dict):\n",
    "    #edit for special case like s*** etc\n",
    "    s = re.sub(\"\\*\", \"#\", s)\n",
    "    def replace(match):\n",
    "        #print(type(match), match)\n",
    "        return contractions_dict[match.group(0)]\n",
    "    return contractions_re.sub(replace, s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s###\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'shit'"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample1 = \"s***\"\n",
    "print(re.sub(\"\\*\", \"#\", sample1))\n",
    "\n",
    "sample = \"I don\\'t know what to say nay. I haven\\'t. s###\"\n",
    "expand_contractions(sample)\n",
    "expand_contractions(sample1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['this is a test it is only a test'], ['this is a test', 'it is only a test'])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import string\n",
    "\n",
    "# return both wholeText, paragraph Text\n",
    "def singleReviewCleanUp(sample):\n",
    "    #print(sample)\n",
    "    #sample = sample.decode(\"utf-8\")\n",
    "    sample = expand_contractions(sample)\n",
    "    sample = sample.lower()\n",
    "    \n",
    "    #for word in sample:\n",
    "    #    print(lemmatizer.lemmatize(word, wordnet.VERB))\n",
    "    \n",
    "    review = sent_tokenize(sample)\n",
    "    #print(review)\n",
    "    for count, eachSent in enumerate(review):\n",
    "        #remove numbers\n",
    "        eachSent = re.sub(\"r'\\d+/\\d+|\\d+|\\$\\d+.\\d+\", \" \", eachSent)\n",
    "        #remove string\n",
    "        eachSent = re.sub('[%s]' % re.escape(string.punctuation), ' ', eachSent)\n",
    "        #word tokens\n",
    "        #print([lemmatizer.lemmatize(text, wordnet.VERB) for text in eachSent.split()])\n",
    "        eachSent = word_tokenize(eachSent)\n",
    "        review[count] = eachSent\n",
    "        # lemmatize and remove stopWords\n",
    "        #eachSent = [word for word in eachSent if not word in stopWords]\n",
    "        #eachSent = [lemmatizer.lemmatize(word, wordnet.VERB) for word in eachSent]\n",
    "        #eachSent = [lemmatizer.lemmatize(word, wordnet.VERB) for word in eachSent if not word in stopWords]\n",
    "        #reconstruct sentence\n",
    "        review[count] = \" \".join(eachSent)\n",
    "    #a clobbed together without pun\n",
    "    wholeText = [\" \".join(review) ]\n",
    "    #reconstruct paragraph of sentences\n",
    "\n",
    "    paragraphText = review\n",
    "    #return wholeText\n",
    "    #return paragraphText\n",
    "    return paragraphText, wholeText\n",
    "\n",
    "sample = \"This is a test. It is only a test!\"\n",
    "paragraphText, wholeText = singleReviewCleanUp(sample)\n",
    "wholeText, paragraphText\n",
    "#paragraphText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Give me back text in a paragraph sentence forms. They do have more values than a clobbed of text based on Polarity Check.\n",
    "cleanUpTextParagraph = lambda text: singleReviewCleanUp(text)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reviewTextProcessing['Processed'] = reviewTextProcessing.reviewText.apply(cleanUpTextParagraph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                          [i hate it when my shirt collars not otherwise secured in place by buttons end up in weird places throughout the day, i purchased some steel collar stays to use with these magnets but they were only vaguely magnetic, i ended up using of these magnets one in the collar with the stay and the other inside my shirt to lock my collar in place, they work flawlessly, they are the perfect size and there are plenty of magnets in case you forget to remove them at the end of the day]\n",
       "1                                                                                                                                                                                                                                                                                                                                                            [these little magnets are really powerful for there size, i am using them to make secret compartments in custom made boxes, each one hols about of a pound]\n",
       "2                                                                                                                                                                                                                                                                                    [i wanted something this small to mount on the back of filagree wood piece i cut, they could then be mounted on refrigerators, works well, should be able to remove the pieces from the refrig without breaking yet will hold well]\n",
       "3                                                                                                                                                                                                                                                                                                                 [i use these to magnetize my warhammer k miniatures together allowing me to swap out their various parts and weapons, they provide excellent holding power along with small size to fit in snug areas]\n",
       "4    [they are soo freaking annoying, why, you spend all this time da n near breaking off your fingernail trying to separate these li l buggers and when you do finally get them apart you accidentally hold your hand in a certain way or angle and they snap right back together again with reckless abandon, so yes annoying but that has that is only because they are soo good at what they do, you too will be happily annoyed with your purchase, i had i would stick my reputation on that statement with the...\n",
       "Name: Processed, dtype: object"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewTextProcessing.Processed.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample = \" I don't know what to do. I need to test through tough. Do you have any suggestions\"\n",
    "#result = cleanUpTextParagraph(sample)\n",
    "#result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# need to do a data check first\n",
    "def getPolaritySubjectivity(data):\n",
    "    #print(data)\n",
    "    paragraphText = data\n",
    "    sumPolarity = []\n",
    "    sumSubjectivity = []\n",
    "    for each in paragraphText:\n",
    "        sumPolarity.append(TextBlob(each).sentiment.polarity)\n",
    "        sumSubjectivity.append(TextBlob(each).sentiment.subjectivity)\n",
    "    #print(\"sumPol\", sumPolarity)\n",
    "    return sumPolarity, sumSubjectivity\n",
    "    #return sum(sumPolarity), sum(sumSubjectivity)\n",
    "\n",
    "    #print(each, TextBlob(each).sentiment.polarity, TextBlob(each).sentiment.subjectivity)\n",
    "#(sample2, TextBlob(sample2).sentiment.polarity, TextBlob(sample2).sentiment.subjectivity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return the sume of polarity in a paragraph sentence when give a text in a list form of sentence\n",
    "\n",
    "getPolarityFromText = lambda text: getPolaritySubjectivity(text)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each in sampleText:\n",
    "#    sample = cleanUpTextParagraph(each)\n",
    "#    print(sample, getPolarityFromText(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentiment = lambda text: TextBlob(text).sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjustSentimentModel = lambda x: [sum(x), 0.0] if sum(x) < 0 else [sum(x), 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reviewTextProcessing['Sentiment']= reviewTextProcessing.Processed.apply(getPolarityFromText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 255 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reviewTextProcessing['SentimentModel']= reviewTextProcessing.Sentiment.apply(adjustSentimentModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reviewTextProcessing.loc[unfavorableReviews, ['Processed', 'Sentiment', 'SentimentModel']].head(2)\n",
    "#reviewTextProcessing.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewTextProcessing['CleanedJoin'] = reviewTextProcessing['Processed'].apply(', '.join)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134476, 5)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewTextProcessing.shape\n",
    "#reviewTextProcessing.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from gensim import corpora\n",
    "#dictionary = corpora.Dictionary(T)\n",
    "#print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    i hate it when my shirt collars not otherwise secured in place by buttons end up in weird places throughout the day, i purchased some steel collar stays to use with these magnets but they were only vaguely magnetic, i ended up using of these magnets one in the collar with the stay and the other inside my shirt to lock my collar in place, they work flawlessly, they are the perfect size and there are plenty of magnets in case you forget to remove them at the end of the day\n",
       "1                                                                                                                                                                                                                                                                                                                                      these little magnets are really powerful for there size, i am using them to make secret compartments in custom made boxes, each one hols about of a pound\n",
       "Name: CleanedJoin, dtype: object"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewTextProcessing['CleanedJoin'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134476"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import itertools\n",
    "\n",
    "largeText = reviewTextProcessing.CleanedJoin.to_list()\n",
    "#largeText = reviewTextProcessing.reviewText.to_list() # Not too good accuracy around 116 missed with %86.94\n",
    "\n",
    "len(largeText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = reviewTextProcessing['SentimentModel'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "num_words = 10000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=num_words)\n",
    "tokenizer.fit_on_texts(largeText)\n",
    "#tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "size = int(len(largeText)*.75)\n",
    "x_train_text = largeText[:size]\n",
    "x_test_text = largeText[size:]\n",
    "\n",
    "y_train =  reviewTextProcessing['rating'][:size]\n",
    "y_test = reviewTextProcessing['rating'][size:]\n",
    "x_train_tokens = tokenizer.texts_to_sequences(x_train_text)\n",
    "x_test_tokens = tokenizer.texts_to_sequences(x_test_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100857, 33619, 100857, 33619)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train), len(y_test), len(x_train_text), len(x_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train_tokens[1], x_train_text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_train_text[1]\n",
    "np.array(x_train_tokens[1])\n",
    "num_tokens = [len(tokens) for tokens in x_train_tokens + x_test_tokens]\n",
    "num_tokens = np.array(num_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110.80553407299443, 4838)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(num_tokens), np.max(num_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## np.std(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "376"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "max_tokens = int(max_tokens) \n",
    "max_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.958706386269669"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(num_tokens < max_tokens) / len(num_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33619, 376)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad = 'pre'\n",
    "x_train_pad = pad_sequences(x_train_tokens, maxlen=max_tokens, padding=pad, truncating=pad)\n",
    "x_test_pad = pad_sequences(x_test_tokens, maxlen=max_tokens, padding=pad, truncating=pad)\n",
    "x_train_pad.shape\n",
    "x_test_pad.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100857"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = len(x_train_pad)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    2 1558    4   39   18 3329 8531   11  722\n",
      " 2917   12  236   82 1219  220   41   12 2405  908 2048    1  225    2\n",
      "  212   68  424 2317  951    5   32   17   37 1753   19   27  120   64\n",
      " 1190    2  996   41   96    8   37 1753   25   12    1 2317   17    1\n",
      "  630    6    1   62  320   18 3329    5  247   18 2317   12  236   27\n",
      "   60 1524   27   20    1  211  171    6   61   20  615    8 1753   12\n",
      "  174   14 1232    5  388   55   38    1  220    8    1  225]\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 1):\n",
    "    print(x_train_pad[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_string(tokens):\n",
    "    # Map from tokens back to words.\n",
    "    words = [inverse_map[token] for token in tokens if token != 0]\n",
    "    \n",
    "    # Concatenate all words.\n",
    "    text = \" \".join(words)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = tokenizer.word_index\n",
    "inverse_map = dict(zip(idx.values(), idx.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the product does exactly as it should and is quite affordable i did not realized it was double screened until it arrived so it was even better than i had expected as an added bonus one of the screens carries a small hint of the smell of an old grape candy i used to buy so for reminiscent s sake i can not stop putting the pop filter next to my nose and smelling it after recording, dif you needed a pop filter this will work just as well as the expensive ones and it may even come with a pleasing aroma like mine did buy this product, '"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_text[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the product does exactly as it should and is quite affordable i did not realized it was double screened until it arrived so it was even better than i had expected as an added bonus one of the screens carries a small hint of the smell of an old grape candy i used to buy so for reminiscent s sake i can not stop putting the pop filter next to my nose and it after recording dif you needed a pop filter this will work just as well as the expensive ones and it may even come with a pleasing like mine did buy this product'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_to_string(x_train_tokens[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, GRU, Embedding\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#embedding_size = 8 > 0.8694\n",
    "embedding_size = 8*3\n",
    "optimizer = Adam(lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Embedding(input_dim=num_words,output_dim=embedding_size, input_length=max_tokens, name='layer_embedding'))\n",
    "model.add(GRU(units=16, return_sequences=True))\n",
    "model.add(GRU(units=8, return_sequences=True))\n",
    "model.add(GRU(units=4))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer2_embedding (Embedding) (None, 376, 24)           240000    \n",
      "_________________________________________________________________\n",
      "gru_9 (GRU)                  (None, 376, 16)           1968      \n",
      "_________________________________________________________________\n",
      "gru_10 (GRU)                 (None, 376, 8)            600       \n",
      "_________________________________________________________________\n",
      "gru_11 (GRU)                 (None, 4)                 156       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 242,729\n",
      "Trainable params: 242,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 95814 samples, validate on 5043 samples\n",
      "Epoch 1/3\n",
      "95814/95814 [==============================] - 747s 8ms/sample - loss: 0.2247 - acc: 0.9282 - val_loss: 0.1851 - val_acc: 0.9334\n",
      "Epoch 2/3\n",
      "95814/95814 [==============================] - 734s 8ms/sample - loss: 0.1559 - acc: 0.9424 - val_loss: 0.1717 - val_acc: 0.9377\n",
      "Epoch 3/3\n",
      "95814/95814 [==============================] - 758s 8ms/sample - loss: 0.1313 - acc: 0.9513 - val_loss: 0.1747 - val_acc: 0.9328\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x49815668>"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%time\n",
    "#model.fit(x_train_pad, y_train,validation_split=0.05, epochs=5, batch_size=64)\n",
    "\n",
    "model.fit(x_train_pad, y_train,validation_split=0.05, epochs=3, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33619/33619 [==============================] - 106s 3ms/sample - loss: 0.1655 - acc: 0.9394\n",
      "Wall time: 1min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = model.evaluate(x_test_pad, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.94%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {0:.2%}\".format(result[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = model.predict(x=x_test_pad[0:1000])\n",
    "y_pred = y_pred.T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99408984, 0.9936342 , 0.9957746 , 0.99258053, 0.9948828 ,\n",
       "       0.9936437 , 0.9960873 , 0.99284875, 0.9952526 , 0.99552345,\n",
       "       0.11372644, 0.9964645 , 0.98891956, 0.9962717 , 0.898716  ,\n",
       "       0.9728962 , 0.9957236 , 0.80997586, 0.99564236, 0.9959892 ,\n",
       "       0.98257905, 0.3086452 , 0.9891758 , 0.75045896, 0.99194795,\n",
       "       0.98051167, 0.9957129 , 0.9612137 , 0.99216163, 0.98338556,\n",
       "       0.99241745, 0.99624395, 0.99366236, 0.99508166, 0.99245584,\n",
       "       0.99513936, 0.9939476 , 0.31506366, 0.995342  , 0.92726564,\n",
       "       0.9898269 , 0.99468434, 0.9953711 , 0.9949105 , 0.9503124 ,\n",
       "       0.9897896 , 0.9937831 , 0.98829925, 0.41269282, 0.98115206,\n",
       "       0.99628985, 0.9960763 , 0.98378086, 0.9809071 , 0.99067473,\n",
       "       0.9660648 , 0.99605197, 0.9942354 , 0.8798444 , 0.9962816 ,\n",
       "       0.9963231 , 0.9945872 , 0.99569094, 0.9782295 , 0.9950129 ,\n",
       "       0.99038684, 0.9958422 , 0.9870006 , 0.9956392 , 0.99580896,\n",
       "       0.9931312 , 0.9958078 , 0.99489236, 0.99514717, 0.99649096,\n",
       "       0.99556786, 0.9947512 , 0.9951385 , 0.9341102 , 0.9962467 ,\n",
       "       0.99619603, 0.99224395, 0.9956047 , 0.9924834 , 0.99279356,\n",
       "       0.21216956, 0.84674346, 0.9945897 , 0.99360085, 0.99492216,\n",
       "       0.98693824, 0.9961642 , 0.9947038 , 0.9958024 , 0.996253  ,\n",
       "       0.9958246 , 0.9901259 , 0.9909883 , 0.97779775, 0.994159  ,\n",
       "       0.99480116, 0.99528193, 0.99635005, 0.9952242 , 0.99231374,\n",
       "       0.9958509 , 0.99334335, 0.70922697, 0.9948765 , 0.9947704 ,\n",
       "       0.9957752 , 0.9948005 , 0.99501336, 0.9943468 , 0.94824445,\n",
       "       0.99572486, 0.667936  , 0.99601626, 0.9955857 , 0.99606204,\n",
       "       0.9949279 , 0.9935291 , 0.99580157, 0.9938671 , 0.99336576,\n",
       "       0.99365425, 0.99631804, 0.9944253 , 0.99569035, 0.9897965 ,\n",
       "       0.99600947, 0.41177097, 0.99135387, 0.7170479 , 0.9951196 ,\n",
       "       0.99635226, 0.99574137, 0.99211615, 0.9957411 , 0.9920949 ,\n",
       "       0.9950999 , 0.9958303 , 0.9950355 , 0.9937774 , 0.99618757,\n",
       "       0.9959341 , 0.3562011 , 0.8978367 , 0.43085915, 0.9964044 ,\n",
       "       0.9871005 , 0.9740658 , 0.9962497 , 0.9415466 , 0.9789572 ,\n",
       "       0.49964866, 0.99488556, 0.9694309 , 0.733904  , 0.60792285,\n",
       "       0.99334365, 0.99652624, 0.99528795, 0.9965429 , 0.9964994 ,\n",
       "       0.9959452 , 0.99515975, 0.9959023 , 0.9951877 , 0.9947825 ,\n",
       "       0.9962213 , 0.9963986 , 0.99204063, 0.9961966 , 0.9960392 ,\n",
       "       0.71594745, 0.91606605, 0.9842095 , 0.94463897, 0.83441186,\n",
       "       0.9837446 , 0.99459386, 0.99585   , 0.99346393, 0.99535847,\n",
       "       0.99608815, 0.9480443 , 0.9961636 , 0.99090505, 0.996405  ,\n",
       "       0.13291809, 0.69299257, 0.99612284, 0.9846618 , 0.99636966,\n",
       "       0.99629164, 0.96203697, 0.1700978 , 0.99621093, 0.995506  ,\n",
       "       0.37993228, 0.99583656, 0.9949213 , 0.99536264, 0.9359031 ,\n",
       "       0.98575544, 0.99534297, 0.99118596, 0.99026144, 0.99591535,\n",
       "       0.9941716 , 0.946579  , 0.9777453 , 0.99482465, 0.99576294,\n",
       "       0.99576706, 0.99610066, 0.9943931 , 0.995098  , 0.9926033 ,\n",
       "       0.9960771 , 0.9485414 , 0.95431834, 0.9952545 , 0.99208665,\n",
       "       0.98960876, 0.9209656 , 0.96947104, 0.9938787 , 0.98559713,\n",
       "       0.9959743 , 0.9959481 , 0.9956435 , 0.9947501 , 0.9930128 ,\n",
       "       0.97150695, 0.99590945, 0.99582636, 0.99496126, 0.48848504,\n",
       "       0.97631717, 0.9918884 , 0.9955739 , 0.9960182 , 0.9876972 ,\n",
       "       0.9963379 , 0.99480736, 0.99485403, 0.6823073 , 0.9939523 ,\n",
       "       0.99071944, 0.99547076, 0.9930866 , 0.9915705 , 0.85197866,\n",
       "       0.99225736, 0.91657245, 0.9896883 , 0.9856873 , 0.9772277 ,\n",
       "       0.99351966, 0.99630964, 0.99576795, 0.9563992 , 0.991557  ,\n",
       "       0.9959807 , 0.9491822 , 0.99427104, 0.99559426, 0.97481275,\n",
       "       0.99275196, 0.99548626, 0.996173  , 0.995582  , 0.93615127,\n",
       "       0.9914249 , 0.89174616, 0.97926676, 0.99287844, 0.8289852 ,\n",
       "       0.98638034, 0.25005037, 0.9909922 , 0.88107014, 0.9949307 ,\n",
       "       0.9861902 , 0.97945356, 0.9578662 , 0.959153  , 0.9910159 ,\n",
       "       0.99467486, 0.98819864, 0.9206012 , 0.9943522 , 0.97726107,\n",
       "       0.9806993 , 0.9949136 , 0.6986782 , 0.9949609 , 0.99350446,\n",
       "       0.99586046, 0.9956473 , 0.99624187, 0.996181  , 0.9962152 ,\n",
       "       0.98731184, 0.83009946, 0.99610114, 0.9848274 , 0.98733175,\n",
       "       0.99493086, 0.9928819 , 0.9950367 , 0.9956602 , 0.99597216,\n",
       "       0.9927824 , 0.9940653 , 0.98964477, 0.99596906, 0.9964149 ,\n",
       "       0.9784014 , 0.98121285, 0.9955664 , 0.99620914, 0.9959141 ,\n",
       "       0.99093455, 0.99093586, 0.9764488 , 0.9818476 , 0.920921  ,\n",
       "       0.04447326, 0.9879788 , 0.9952173 , 0.99548244, 0.995386  ,\n",
       "       0.99474275, 0.99622315, 0.99476874, 0.9954034 , 0.9907768 ,\n",
       "       0.9960159 , 0.9800856 , 0.99450874, 0.99155045, 0.99492157,\n",
       "       0.9905023 , 0.9958068 , 0.970622  , 0.99575645, 0.9940068 ,\n",
       "       0.98135066, 0.9928888 , 0.99620676, 0.98818004, 0.987579  ,\n",
       "       0.99644554, 0.9936371 , 0.99491656, 0.9669652 , 0.9841315 ,\n",
       "       0.97208595, 0.9957293 , 0.9804955 , 0.9964206 , 0.99597085,\n",
       "       0.99472535, 0.995722  , 0.99094844, 0.99011517, 0.9957818 ,\n",
       "       0.9934727 , 0.9936214 , 0.99382496, 0.99562407, 0.9960625 ,\n",
       "       0.98409057, 0.994125  , 0.99326277, 0.99633425, 0.9941915 ,\n",
       "       0.9916048 , 0.9961848 , 0.9953854 , 0.99471307, 0.1959016 ,\n",
       "       0.99598324, 0.995796  , 0.96472895, 0.99180734, 0.99552023,\n",
       "       0.9940885 , 0.9960941 , 0.9964355 , 0.9942397 , 0.13065171,\n",
       "       0.9948115 , 0.9961657 , 0.99588394, 0.9927824 , 0.9960792 ,\n",
       "       0.97713804, 0.9722695 , 0.9755501 , 0.9933359 , 0.97681034,\n",
       "       0.98465806, 0.8941751 , 0.992262  , 0.44159725, 0.97902584,\n",
       "       0.99417037, 0.99579763, 0.9960427 , 0.9955173 , 0.98569095,\n",
       "       0.6398721 , 0.9953758 , 0.9932469 , 0.7646078 , 0.95138395,\n",
       "       0.6044843 , 0.9872103 , 0.99596184, 0.9948647 , 0.9938751 ,\n",
       "       0.9958445 , 0.9918779 , 0.9801372 , 0.9957527 , 0.99636006,\n",
       "       0.9949313 , 0.9958639 , 0.95723647, 0.9042164 , 0.995069  ,\n",
       "       0.9846595 , 0.9671603 , 0.97082984, 0.99376464, 0.996156  ,\n",
       "       0.9915316 , 0.9953517 , 0.88955903, 0.99555707, 0.9945923 ,\n",
       "       0.98233783, 0.99598587, 0.99289083, 0.99629366, 0.99378335,\n",
       "       0.9533689 , 0.9681659 , 0.99169   , 0.97764003, 0.49715874,\n",
       "       0.9964057 , 0.9895675 , 0.996302  , 0.7663375 , 0.9738332 ,\n",
       "       0.91368866, 0.93797   , 0.6802614 , 0.9939565 , 0.99535   ,\n",
       "       0.9946636 , 0.9485879 , 0.9958792 , 0.99512327, 0.99607897,\n",
       "       0.9939337 , 0.99116576, 0.99376976, 0.99230915, 0.92784274,\n",
       "       0.63119024, 0.9951891 , 0.9843272 , 0.99323416, 0.99556386,\n",
       "       0.99616736, 0.99489605, 0.9923898 , 0.9956466 , 0.94587815,\n",
       "       0.99604154, 0.9735458 , 0.99587   , 0.99603724, 0.70696366,\n",
       "       0.9766419 , 0.98823917, 0.7390654 , 0.9897795 , 0.9867567 ,\n",
       "       0.76921797, 0.9341414 , 0.635666  , 0.99410504, 0.9656863 ,\n",
       "       0.9959383 , 0.99393713, 0.9928535 , 0.99611574, 0.9962526 ,\n",
       "       0.5165927 , 0.988019  , 0.983971  , 0.9960562 , 0.9955706 ,\n",
       "       0.99305505, 0.9956158 , 0.99478596, 0.9759351 , 0.985908  ,\n",
       "       0.9955001 , 0.9925575 , 0.987333  , 0.39232296, 0.9922622 ,\n",
       "       0.99648285, 0.940719  , 0.99263656, 0.9921105 , 0.98323303,\n",
       "       0.98908114, 0.99627376, 0.9939392 , 0.9945707 , 0.99025977,\n",
       "       0.9958645 , 0.99615705, 0.9417264 , 0.9135124 , 0.5631267 ,\n",
       "       0.9958051 , 0.99622643, 0.40063712, 0.05860406, 0.11732557,\n",
       "       0.6661451 , 0.9917781 , 0.80959296, 0.9957255 , 0.9956952 ,\n",
       "       0.95433426, 0.6894965 , 0.99144536, 0.9877838 , 0.98971057,\n",
       "       0.9961989 , 0.99459684, 0.99461013, 0.99168545, 0.89231336,\n",
       "       0.9964187 , 0.99596167, 0.99634993, 0.99445283, 0.9958235 ,\n",
       "       0.9933516 , 0.99231243, 0.99610496, 0.99504673, 0.9781827 ,\n",
       "       0.99639547, 0.9960543 , 0.9964012 , 0.99344933, 0.9916043 ,\n",
       "       0.94368804, 0.9942397 , 0.9957745 , 0.98294896, 0.40458766,\n",
       "       0.99493206, 0.9902444 , 0.9958738 , 0.9925339 , 0.99598706,\n",
       "       0.9918171 , 0.994784  , 0.9958747 , 0.99349284, 0.99500215,\n",
       "       0.9830184 , 0.99073184, 0.5933552 , 0.9949815 , 0.995619  ,\n",
       "       0.9957064 , 0.99495745, 0.9953052 , 0.9963809 , 0.99579   ,\n",
       "       0.99596924, 0.9953367 , 0.99566174, 0.99628484, 0.9960798 ,\n",
       "       0.9748622 , 0.99435234, 0.9944663 , 0.9956332 , 0.99636424,\n",
       "       0.9746072 , 0.99572337, 0.99583566, 0.983197  , 0.9939822 ,\n",
       "       0.8086103 , 0.9949405 , 0.9481    , 0.9909153 , 0.98124623,\n",
       "       0.92387944, 0.1301575 , 0.9291049 , 0.99491   , 0.99569213,\n",
       "       0.9900531 , 0.9857095 , 0.77926356, 0.9954628 , 0.9940215 ,\n",
       "       0.99612784, 0.9953859 , 0.9943878 , 0.9811039 , 0.99385357,\n",
       "       0.9616138 , 0.9938014 , 0.99250007, 0.96679986, 0.8934245 ,\n",
       "       0.9944825 , 0.17828453, 0.10029507, 0.8394873 , 0.3394319 ,\n",
       "       0.95852923, 0.19062236, 0.9957793 , 0.9936763 , 0.98771894,\n",
       "       0.8487505 , 0.98898244, 0.98750776, 0.9950576 , 0.9679948 ,\n",
       "       0.9941263 , 0.99570954, 0.9941989 , 0.9834682 , 0.9964806 ,\n",
       "       0.9938332 , 0.9919283 , 0.9810065 , 0.7331508 , 0.9839472 ,\n",
       "       0.05552456, 0.9479468 , 0.9948262 , 0.17810857, 0.992347  ,\n",
       "       0.85904   , 0.9946538 , 0.9934484 , 0.9805899 , 0.9046894 ,\n",
       "       0.99384075, 0.900408  , 0.96291256, 0.98903847, 0.9854332 ,\n",
       "       0.99450195, 0.19358766, 0.4119373 , 0.9860109 , 0.88458556,\n",
       "       0.9895983 , 0.9961866 , 0.9946326 , 0.99449515, 0.17866784,\n",
       "       0.988318  , 0.98560107, 0.99194455, 0.99581707, 0.99280465,\n",
       "       0.5386494 , 0.97272503, 0.9951993 , 0.99550116, 0.9880394 ,\n",
       "       0.78203595, 0.99516433, 0.98723954, 0.9941257 , 0.99636376,\n",
       "       0.9792209 , 0.9955532 , 0.99470794, 0.9962457 , 0.94221497,\n",
       "       0.9944444 , 0.9960716 , 0.994881  , 0.9959472 , 0.99357903,\n",
       "       0.995935  , 0.9946681 , 0.8989124 , 0.9941792 , 0.94001603,\n",
       "       0.995967  , 0.9889126 , 0.98747724, 0.770243  , 0.9959619 ,\n",
       "       0.1858682 , 0.9884324 , 0.99612534, 0.27592444, 0.9957442 ,\n",
       "       0.99411875, 0.9959419 , 0.991233  , 0.99195826, 0.98389465,\n",
       "       0.9961791 , 0.9672776 , 0.9951093 , 0.9904313 , 0.9891527 ,\n",
       "       0.41856214, 0.99448776, 0.9810319 , 0.42977417, 0.9954204 ,\n",
       "       0.99615   , 0.994907  , 0.99236155, 0.99467784, 0.9757819 ,\n",
       "       0.99516165, 0.98493207, 0.9951246 , 0.99613297, 0.72692525,\n",
       "       0.9961707 , 0.97196823, 0.9929737 , 0.9834798 , 0.9909672 ,\n",
       "       0.9898195 , 0.99555373, 0.20666888, 0.4849802 , 0.9399828 ,\n",
       "       0.9743548 , 0.91217726, 0.787923  , 0.9869106 , 0.8061662 ,\n",
       "       0.13175967, 0.9956766 , 0.5112575 , 0.99540687, 0.9905643 ,\n",
       "       0.99094915, 0.9845133 , 0.98546314, 0.5827104 , 0.7138995 ,\n",
       "       0.9935708 , 0.93236744, 0.9924247 , 0.99588907, 0.99333274,\n",
       "       0.97516704, 0.9960909 , 0.94202125, 0.99162686, 0.989413  ,\n",
       "       0.9941236 , 0.9832022 , 0.99509805, 0.42532995, 0.99437475,\n",
       "       0.26934373, 0.9931059 , 0.9551453 , 0.847302  , 0.61175704,\n",
       "       0.6233607 , 0.9949839 , 0.97005945, 0.9932438 , 0.99333656,\n",
       "       0.93263113, 0.9957993 , 0.801975  , 0.9641787 , 0.9958214 ,\n",
       "       0.9944464 , 0.99236554, 0.77654123, 0.9863977 , 0.9950938 ,\n",
       "       0.9958442 , 0.99420714, 0.99487346, 0.9957993 , 0.98154634,\n",
       "       0.9902137 , 0.95293534, 0.9703381 , 0.9953052 , 0.9841891 ,\n",
       "       0.9686179 , 0.9835276 , 0.99208236, 0.94147885, 0.9952421 ,\n",
       "       0.69224495, 0.9963042 , 0.9956676 , 0.99559593, 0.98244303,\n",
       "       0.9904257 , 0.91855466, 0.993858  , 0.9669541 , 0.99439263,\n",
       "       0.9958639 , 0.99434566, 0.99523   , 0.9927077 , 0.9890206 ,\n",
       "       0.98492587, 0.99622685, 0.99587595, 0.97878337, 0.994512  ,\n",
       "       0.9944282 , 0.99629223, 0.4824909 , 0.18468338, 0.9961742 ,\n",
       "       0.9945893 , 0.99521804, 0.94833386, 0.9954679 , 0.80254287,\n",
       "       0.9867561 , 0.99076784, 0.9259733 , 0.9962134 , 0.9689849 ,\n",
       "       0.9947269 , 0.11243141, 0.7725369 , 0.9835611 , 0.36774346,\n",
       "       0.9941877 , 0.99574566, 0.996171  , 0.9963751 , 0.9763475 ,\n",
       "       0.9958197 , 0.6275104 , 0.9296763 , 0.9924556 , 0.9910402 ,\n",
       "       0.9955847 , 0.9956969 , 0.78188676, 0.9918072 , 0.99324113,\n",
       "       0.9953928 , 0.9505452 , 0.99141777, 0.9945388 , 0.99346954,\n",
       "       0.9962099 , 0.98555773, 0.15287974, 0.99379706, 0.9954262 ,\n",
       "       0.98775935, 0.9932786 , 0.99474275, 0.99143744, 0.28446314,\n",
       "       0.98187864, 0.86954796, 0.9961765 , 0.9935504 , 0.96808505,\n",
       "       0.9954721 , 0.9949362 , 0.9885484 , 0.9830075 , 0.976938  ,\n",
       "       0.992867  , 0.9923847 , 0.99604726, 0.99596775, 0.15163559,\n",
       "       0.7621772 , 0.9290445 , 0.99038696, 0.9318478 , 0.8678904 ,\n",
       "       0.9725596 , 0.9951688 , 0.9121028 , 0.9901991 , 0.9172916 ,\n",
       "       0.9942436 , 0.99584186, 0.16734311, 0.9260464 , 0.9889823 ,\n",
       "       0.9961295 , 0.9949998 , 0.9397434 , 0.97284424, 0.77738416,\n",
       "       0.9955529 , 0.27025557, 0.9943173 , 0.9866456 , 0.98599565,\n",
       "       0.93096936, 0.32855397, 0.9926026 , 0.9759259 , 0.6218617 ,\n",
       "       0.23343495, 0.99466765, 0.7782382 , 0.9962609 , 0.18246445,\n",
       "       0.44927898, 0.99493825, 0.995004  , 0.9950615 , 0.749327  ,\n",
       "       0.99169016, 0.9961932 , 0.93431026, 0.99489975, 0.99166405,\n",
       "       0.72273463, 0.9962243 , 0.98461837, 0.9773638 , 0.99598336,\n",
       "       0.9952853 , 0.9695672 , 0.9928224 , 0.9775146 , 0.9937744 ,\n",
       "       0.96237373, 0.98770237, 0.9960482 , 0.9891859 , 0.99395055,\n",
       "       0.20721826, 0.99599886, 0.9923663 , 0.9123453 , 0.99521446,\n",
       "       0.9810698 , 0.98646677, 0.9914733 , 0.995747  , 0.33968413,\n",
       "       0.9960431 , 0.99053717, 0.99517906, 0.2566089 , 0.98561275,\n",
       "       0.993966  , 0.9952086 , 0.9944862 , 0.2728935 , 0.98293304,\n",
       "       0.99171793, 0.9941    , 0.9897045 , 0.9897897 , 0.99410826,\n",
       "       0.98220396, 0.99343467, 0.84552956, 0.81629217, 0.9950527 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>rating</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentModel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100857</th>\n",
       "      <td>Hunter 90434 16-Inch Portable Stand Fan, Oil Rubbed BronzeThis review is about the Hunter 90434 16-Inch Portable Stand Fan, Oil Rubbed Bronze Fan. It's a very nice oscillating 3 speed adjustable height fan. You assemble it your self. When attempting to assemble the fan I found out I had a striped screw. So I contacted Hunter Fan company and they shipped me a new fan. Which assembled with no problems. I set my fan in my sliding glass windows when it cools off at night,it does a very nice job ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.78, 0.0, 0.0, 0.13636363636363635, 0.0, 0.89, 0.0]</td>\n",
       "      <td>[1.8063636363636364, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100858</th>\n",
       "      <td>Needed these because I was refinishing a large dining table. Worked as expected, good tack, needed only about 1/4 of a single cloth, using it for several stages. Seems like a quality product made in the USA - not Chinese c**p. Each cloth individually wrapped, so he package should last a very long time.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.21428571428571427, 0.10571428571428572, 0.0, -0.021666666666666667]</td>\n",
       "      <td>[0.29833333333333334, 1.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 reviewText  \\\n",
       "100857  Hunter 90434 16-Inch Portable Stand Fan, Oil Rubbed BronzeThis review is about the Hunter 90434 16-Inch Portable Stand Fan, Oil Rubbed Bronze Fan. It's a very nice oscillating 3 speed adjustable height fan. You assemble it your self. When attempting to assemble the fan I found out I had a striped screw. So I contacted Hunter Fan company and they shipped me a new fan. Which assembled with no problems. I set my fan in my sliding glass windows when it cools off at night,it does a very nice job ...   \n",
       "100858                                                                                                                                                                                                      Needed these because I was refinishing a large dining table. Worked as expected, good tack, needed only about 1/4 of a single cloth, using it for several stages. Seems like a quality product made in the USA - not Chinese c**p. Each cloth individually wrapped, so he package should last a very long time.   \n",
       "\n",
       "        overall  rating  \\\n",
       "100857      5.0       1   \n",
       "100858      5.0       1   \n",
       "\n",
       "                                                                     Sentiment  \\\n",
       "100857              [0.0, 0.78, 0.0, 0.0, 0.13636363636363635, 0.0, 0.89, 0.0]   \n",
       "100858  [0.21428571428571427, 0.10571428571428572, 0.0, -0.021666666666666667]   \n",
       "\n",
       "                    SentimentModel  \n",
       "100857   [1.8063636363636364, 1.0]  \n",
       "100858  [0.29833333333333334, 1.0]  "
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(y_pred)\n",
    "result_location = np.where(y_pred.T)[0]  + index\n",
    "RNNresult = reviewTextProcessing.loc[list(result_location),  ['reviewText', 'overall', 'rating', 'Sentiment' , 'SentimentModel']]\n",
    "RNNresult.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.925989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.182131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.044473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.975933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.992860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.995464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.996543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "count  1000.000000\n",
       "mean      0.925989\n",
       "std       0.182131\n",
       "min       0.044473\n",
       "25%       0.975933\n",
       "50%       0.992860\n",
       "75%       0.995464\n",
       "max       0.996543"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_pred).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_pred = np.array([1.0 if p>0.5 else 0.0 for p in y_pred])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNNresult['RNN_Sentiment'] = cls_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumSentiment = lambda x: x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 6)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNNresult.columns = ['TextBlobAnalysis' if x=='Sentiment' else x for x in RNNresult.columns]\n",
    "RNNresult.columns = ['TextBlob_Sentiment' if x=='SentimentModel' else x for x in RNNresult.columns]\n",
    "RNNresult['TextBlob_Sentiment'] = RNNresult['TextBlob_Sentiment'].apply(sumSentiment)\n",
    "RNNresult.head(3)\n",
    "RNNresult.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = np.array(RNNresult.rating)\n",
    "RNN = np.array(RNNresult.RNN_Sentiment)\n",
    "TextBlob = np.array(RNNresult.TextBlob_Sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RNNresult.loc[RNNresult.RNN_Sentiment < 1, :]\n",
    "RNNresult.loc[RNNresult.overall >= 3.0 , :].to_csv(\"Rating3.0above_RNN.csv\")\n",
    "RNNresult.loc[RNNresult.overall < 3.0 , :].to_csv(\"RatingBelow3.0_RNN.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNNresult.RNN_Sentiment = RNNresult.RNN_Sentiment.astype(int)\n",
    "RNNresult.TextBlob_Sentiment = RNNresult.TextBlob_Sentiment.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = TextBlob + rating + RNN\n",
    "details = np.array([True if (x == 3.0 or x == 0) else False for x in comparison])\n",
    "mismatch = np.where(details == False)\n",
    "#confusionMaxtrix = RNNresult.loc[list(index + (mismatch[0])), :]\n",
    "#confusionMaxtrix.loc[RNNresult.overall > 2.0 ,  :]\n",
    "#confusionMaxtrix.RNN_Sentiment = confusionMaxtrix.RNN_Sentiment.astype(int)\n",
    "#confusionMaxtrix.TextBlob_Sentiment = confusionMaxtrix.TextBlob_Sentiment.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = RNNresult.rating.to_list()\n",
    "rnn_pred = RNNresult.RNN_Sentiment.to_list()\n",
    "textBlob_pred = RNNresult.TextBlob_Sentiment.to_list()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "rrn_compare = confusion_matrix(y_true, rnn_pred)\n",
    "textBlob_compare =  confusion_matrix(y_true, textBlob_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, 26, 25, 914)"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = rrn_compare.ravel()\n",
    "tn, fp, fn, tp   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 40, 93, 846)"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#result tn, fp, fn, tp = textBlob_compare.ravel()\n",
    "#textBlobResult = np.array(tn, fp, fn, tp)\n",
    "result = textBlob_compare.ravel()\n",
    "tn, fp, fn, tp = result\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNNresult.loc[[7736, 7750, 7911], :].to_csv(\"NegativeReviews_RNN.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "array = [[13,1,1,0,2,0],\n",
    "     [3,9,6,0,1,0],\n",
    "     [0,0,16,2,0,0],\n",
    "     [0,0,0,13,0,0],\n",
    "     [0,0,0,0,15,0],\n",
    "     [0,0,1,0,0,15]]        \n",
    "\n",
    "classNames = ['Negative','Positive']\n",
    "plt.title('Confusion Maxtrix')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "#tick_marks = np.arange(len(classNames))\n",
    "plt.xticks(tick_marks, classNames, rotation=45)\n",
    "plt.yticks(tick_marks, classNames)\n",
    "s = [['TN','FP'], ['FN', 'TP']]\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j,i, str(s[i][j])+\" = \"+str(cm[i][j]))\n",
    "df_cm = pd.DataFrame(result, range(2),\n",
    "                  range(2))\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.set(font_scale=1.40)#for label size\n",
    "sn.heatmap(df_cm, annot=True,annot_kws={\"size\": 16})# \n",
    "df_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = result\n",
    "#plt.clf()\n",
    "#plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Wistia)\n",
    "classNames = ['Negative','Positive']\n",
    "plt.title('Confusion Maxtrix')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "#tick_marks = np.arange(len(classNames))\n",
    "plt.xticks(tick_marks, classNames, rotation=45)\n",
    "plt.yticks(tick_marks, classNames)\n",
    "s = [['TN','FP'], ['FN', 'TP']]\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j,i, str(s[i][j])+\" = \"+str(cm[i][j]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_true = np.array(y_test[0:1000])\n",
    "\n",
    "#y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect = np.where(cls_pred != cls_true)\n",
    "incorrect = incorrect[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(incorrect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduceData.loc[7695+40, ['reviewText', 'overall', 'rating']]\n",
    "reviewTextProcessing.loc[7695+40, ['CleanedJoin', 'overall', 'rating', 'SentimentModel']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = incorrect[1]\n",
    "print(type(idx))\n",
    "for each in incorrect[:10]:\n",
    "    idx = each\n",
    "    text = x_test_text[idx]\n",
    "    print(idx, text, cls_pred[idx], cls_true[idx], \" BlobText \",\n",
    "         TextBlob(text).sentiment.polarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewTextProcessing.loc[list(incorrect + 7695), ['CleanedJoin', 'overall', 'rating', 'SentimentModel']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "top_dict = {}\n",
    "#for c in data_dtm.columns:\n",
    "#    top = data_dtm[c].sort_values(ascending=False).head(30)\n",
    "#    top_dict[c]= list(zip(top.index, top.values))\n",
    "\n",
    "top_dict['cable'] = 3\n",
    "top_dict['not happy'] = 4\n",
    "top_dict['disappoint'] = 7\n",
    "\n",
    "regeneration = \"\"\n",
    "\n",
    "for key, value in top_dict.items():\n",
    "    space = ((key) + \" \")\n",
    "    details = (space) * value\n",
    "    regeneration = regeneration + details\n",
    "    \n",
    "review = \" \".join(top_dict.keys())\n",
    "top_dict.values()\n",
    "regeneration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "#stopwords=stopWords,\n",
    "wc = WordCloud(background_color=\"white\", colormap=\"Dark2\",\n",
    "               max_font_size=150, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#handling money\n",
    "#>>> a = re.findall(r\"\\$\\d+.\\d+\", text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numeric and fraction handling\n",
    "#domain specific if applies to tool/measurement?\n",
    "pattern = re.compile(r'^\\d+/\\d+$')\n",
    "\n",
    "def evaluateFraction(data, pattern=pattern):\n",
    "    try:\n",
    "        re.match(pattern, data)\n",
    "        return eval(data)  \n",
    "    except:\n",
    "        print(f\"Not fraction related input {data}\")\n",
    "        return False      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 500\n",
    "\n",
    "#productsReviewData.cleanedText.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleData = productsReviewData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewTextProcessing.loc[[100867, 101061, 101054, 101047, 101163\n",
    "                         ], ['reviewText', 'overall', 'rating', 'SentimentModel']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
